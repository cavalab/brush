{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementing D-MAB, as described in DaCosta et al. - 2008 - Adaptive operator selection with dynamic multi-arm**\n",
    "\n",
    ">  (hybrid between UCB1 and Page-Hinkley (PH) test)\n",
    "\n",
    "D-MAB maintains four indicators for each arm $i$:\n",
    "1. number $n_{i, t}$ of times $i$-th arm has been played up to time $t$;\n",
    "2. the average empirical reward $\\widehat{p}_{j, t}$ at time $t$;\n",
    "3. the average and maximum deviation $m_i$ and $M_i$ involved in the PH test, initialized to $0$ and updated as detailed below. At each time step $t$:\n",
    "\n",
    "D-MAB selects the arm $i$ that maximizes equation 1:\n",
    "\n",
    "$$\\widehat{p}_{i, t} + \\sqrt{\\frac{2 \\log \\sum_{k}n_{k, t}}{n_{i, t}}}$$\n",
    "\n",
    "> Notice that the sum of the number of times each arm was pulled is equal to the time $\\sum_{k}n_{k, t} = t$, but since their algorithm resets the number of picks, we need to go with the summation. \n",
    "\n",
    "and receives some reward $r_t$, drawn after reward distribution $p_{i, t}$.\n",
    "\n",
    "> I think there is a typo in the eq. 1 on the paper. I replaced $j$ with $i$ in the lower indexes.\n",
    "\n",
    "The four indicators are updated accordingly:\n",
    "\n",
    "- $\\widehat{p}_{i, t} :=\\frac{1}{n_{i, t} + 1}(n_{i, t}\\widehat{p}_{i, t} + r_t)$\n",
    "- $n_{i, t} := n_{i, t}+1$\n",
    "- $m_i := m_i + (\\widehat{p}_{i, t} - r_t + \\delta)$\n",
    "- $M_i:= \\text{max}(M_i, m_i)$\n",
    "\n",
    "And if the PH test is triggered ($M_i - m_i > \\lambda$), the bandit is restarted, i.e., for all arms, all indicators are set to zero (the authors argue that, empirically, resetting the values is more robust than decreasing them with some mechanism such as probability matching).\n",
    "\n",
    "> I will reset to 1 instead of 0 (as the original paper does) to avoid divide by zero when calculating UCB1.\n",
    "\n",
    "The PH test is a standard test for the change hypothesis. It works by monitoring the difference between $M_i$ and $m_i$, and when the difference is greater than some uuser-specified threshold $\\lambda$, the PH test is triggered, i.e., it is considered that the Change hypothesis holds.\n",
    "\n",
    "Parameter $\\lambda$ controls the trade-off between false alarms and un-noticed changes. Parameter $\\delta$ enforces the robustness of the test when dealing with slowly varying environments.\n",
    "\n",
    "We also need a scaling mechanism to control the Exploration _versus_ Exploitation balance. They proposed two, from which I will focus on the first: Multiplicative Scaling (cUCB). **It consists on multiplying all rewards by a fixed user-defined parameter $C_{M-\\text{scale}}$.\n",
    "\n",
    "This way, we need to give to our D-MAB 3 parameters: $\\lambda$, $\\delta$, and $C_{M - \\text{scale}}$. In the paper they did a sensitivity analysis of the parameters, but I think they should be fine tuned for each specific data set.\n",
    "\n",
    "> Besides the problem of having to adjust the parameters of the `D_MAB`, I think this is not suited for Symbolic Regression as it is! In symbolic regression we normally have a population with high diversity to explore the search space --- so the mutation that maximizes the reward can be different depending on the expression being mutated. In opposition, if the mutations could be applied regardless of the expression format, then the population would be made of a few set of expressions.\n",
    ">\n",
    "> We should use something like Contextual Bandits to address this problem. An improvement to the algorithm would be including `context_f` that returns an proper context to use when determining which arm to pull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D_MAB:\n",
    "    def __init__(self, num_bandits, verbose=False, *, policy='max_ucb', delta, lmbda, scaling, pull_f, reward_f):\n",
    "        self.num_bandits = num_bandits\n",
    "        self.verbose     = verbose\n",
    "        self.policy      = policy #['max_ucb', 'prob_ucb']\n",
    "        self.delta       = delta\n",
    "        self.lmbda       = lmbda\n",
    "        self.scaling     = scaling\n",
    "        self.pull_f      = pull_f\n",
    "        self.reward_f    = reward_f\n",
    "\n",
    "        # History of choices and time instant t (just to track the behavior)\n",
    "        self.history = {i:[] for i in range(self.num_bandits)}\n",
    "\n",
    "        self._reset_indicators()\n",
    "\n",
    "    def _reset_indicators(self):\n",
    "        self.avg_reward    = np.zeros(self.num_bandits)\n",
    "        self.num_played    = np.zeros(self.num_bandits)\n",
    "        self.avg_deviation = np.zeros(self.num_bandits)\n",
    "        self.max_deviation = np.zeros(self.num_bandits)\n",
    "\n",
    "    def _calc_UCB1s(self):\n",
    "        # We need that avg_reward \\in [0, 1] else we must scale it\n",
    "        rewards = self._normalize(self.avg_reward)\n",
    "\n",
    "        # log1p and +1 on denominator fixes some numeric problems in the original eq.\n",
    "        #scores = np.array([rewards[i] + np.sqrt(2*np.log1p(sum(self.num_played))/(self.num_played[i]+1))\n",
    "        #    for i in range(self.num_bandits)])\n",
    "\n",
    "        scores = rewards + np.sqrt(2*np.log1p(sum(self.num_played))/(self.num_played+1))\n",
    "        \n",
    "        return np.nan_to_num(scores, nan=0.0)\n",
    "\n",
    "    def _scale_reward(self, reward):\n",
    "        # We need to scale if the reward is not in [0, 1].\n",
    "        return reward*self.scaling\n",
    "    \n",
    "    def  _normalize(self, p):\n",
    "        values = np.nan_to_num(p, nan=0)\n",
    "\n",
    "        if np.sum(p)==0.0:\n",
    "            return np.ones(len(p))/len(p)\n",
    "        \n",
    "        return values / (values.sum())\n",
    "    \n",
    "    def playAndOptimize(self, **kwargs):\n",
    "        # For convenience, this takes kwargs that are passed to both pull and reward functions\n",
    "\n",
    "        # It will pick the bandit that maximizes eq.1. \n",
    "        UCB1s  = self._calc_UCB1s()\n",
    "\n",
    "        # We need to know which arm we picked, what it returned, and how to calculate the reward given what the arm returned\n",
    "        picked = (\n",
    "            np.nanargmax(UCB1s) if self.policy=='max_ucb' else\n",
    "            np.random.choice(self.num_bandits, p=self._normalize(UCB1s))\n",
    "        )\n",
    "        \n",
    "        pulled = self.pull_f(picked, **kwargs)\n",
    "        reward = self.reward_f(pulled, **kwargs)\n",
    "        \n",
    "        self.history[picked].append(reward)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Avg. Rewards: {self.avg_reward}\\nUCB1 scores : {UCB1s}\\nPicked      : {picked}\\nReward      : {reward}\")\n",
    "\n",
    "        # After choosing, it will implicitly update the parameters based on the return\n",
    "        if np.isfinite(reward):\n",
    "            self.avg_reward[picked]    = (self.num_played[picked]*self.avg_reward[picked] + self._scale_reward(reward))/(self.num_played[picked]+1)\n",
    "            self.avg_deviation[picked] = self.avg_deviation[picked] + (self.avg_reward[picked] - self._scale_reward(reward) + self.delta)\n",
    "            \n",
    "        self.num_played[picked]    = self.num_played[picked] +1\n",
    "        self.max_deviation[picked] = np.maximum(self.max_deviation[picked], self.avg_deviation[picked])\n",
    "\n",
    "        if (self.max_deviation[picked] - self.avg_deviation[picked] > self.lmbda):\n",
    "            self._reset_indicators()\n",
    "            if self.verbose:\n",
    "                print(\"Reseted indicators ----------------------------------------\")\n",
    "\n",
    "        return picked, pulled, reward"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I'll create a simple bandit configuration so we can do a sanity check of our `D_MAB` implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================================\n",
      "All bandits with same probs\n",
      "------------- Uniformly Distributed Random pulls -------------\n",
      "Probabilities for each arm:  [1. 1. 1. 1.] (the smaller the better)\n",
      "cum. reward for each arm  :  [395.0, 395.0, 396.0, 368.0]\n",
      "pulls for each arm        :  [2466, 2514, 2500, 2520]\n",
      "------------------------ optimizing ------------------------\n",
      "cum. reward for each arm:  {0: 414.0, 1: 412.0, 2: 384.0, 3: 398.0}\n",
      "pulls for each arm      :  {0: 2625, 1: 2557, 2: 2406, 3: 2412}\n",
      "(it was expected: similar amount of pulls for each arm)\n",
      "\n",
      "==============================================================\n",
      "One bandit with higher prob\n",
      "------------- Uniformly Distributed Random pulls -------------\n",
      "Probabilities for each arm:  [-1.   0.2  0.   1. ] (the smaller the better)\n",
      "cum. reward for each arm  :  [2157.0, 1097.0, 1217.0, 384.0]\n",
      "pulls for each arm        :  [2525, 2558, 2483, 2434]\n",
      "------------------------ optimizing ------------------------\n",
      "cum. reward for each arm:  {0: 3968.0, 1: 781.0, 2: 1031.0, 3: 202.0}\n",
      "pulls for each arm      :  {0: 4760, 1: 1873, 2: 2076, 3: 1291}\n",
      "(it was expected: more pulls for first arm, less pulls for last)\n",
      "\n",
      "==============================================================\n",
      "Two bandits with higher probs\n",
      "------------- Uniformly Distributed Random pulls -------------\n",
      "Probabilities for each arm:  [-0.2 -1.   0.  -1. ] (the smaller the better)\n",
      "cum. reward for each arm  :  [1444.0, 2083.0, 1278.0, 2093.0]\n",
      "pulls for each arm        :  [2470, 2480, 2571, 2479]\n",
      "------------------------ optimizing ------------------------\n",
      "cum. reward for each arm:  {0: 1358.0, 1: 2552.0, 2: 967.0, 3: 2275.0}\n",
      "pulls for each arm      :  {0: 2352, 1: 2981, 2: 1922, 3: 2745}\n",
      "(it was expected: 2nd approx 4th > 1st > 3rd)\n"
     ]
    }
   ],
   "source": [
    "# Sanity checks\n",
    "import numpy as np\n",
    "\n",
    "for bandits, descr, expec in [\n",
    "    (np.array([1.0, 1.0,  1.0,  1.0]), 'All bandits with same probs', 'similar amount of pulls for each arm'),\n",
    "    (np.array([-1.0, 0.2,  0.0,  1.0]), 'One bandit with higher prob', 'more pulls for first arm, less pulls for last'),\n",
    "    (np.array([-0.2, -1.0,  0.0,  -1.0]), 'Two bandits with higher probs', '2nd approx 4th > 1st > 3rd'),\n",
    "]:\n",
    "    # Implementing simple bandits.\n",
    "    def pullBandit(bandit, **kwargs):\n",
    "        # Needs to have kwargs to work with my D_MAB implementation\n",
    "\n",
    "        #Get a random number based on a normal dist with mean 0 and var 1\n",
    "        result = np.random.randn()\n",
    "        \n",
    "        # bandits: This is the true reward probabilities, which we shoudn't have access (in the optimizer)\n",
    "        # return a positive or negative reward based on bandit prob.\n",
    "        return 1.0 if result > bandits[bandit] else 0.0\n",
    "\n",
    "    \n",
    "    print(\"\\n==============================================================\")\n",
    "    print(descr)\n",
    "\n",
    "    print(\"------------- Uniformly Distributed Random pulls -------------\")\n",
    "    picks   = [0, 0, 0, 0]\n",
    "    rewards = [0, 0, 0, 0]\n",
    "\n",
    "    for _ in range(10000):\n",
    "        index  = np.random.randint(len(bandits))\n",
    "        reward = pullBandit(index)\n",
    "\n",
    "        picks[index]   = picks[index]+1\n",
    "        rewards[index] = rewards[index]+reward\n",
    "\n",
    "    print(\"Probabilities for each arm: \", bandits, \"(the smaller the better)\")\n",
    "    print(\"cum. reward for each arm  : \", rewards)\n",
    "    print(\"pulls for each arm        : \", picks)\n",
    "\n",
    "    print(\"------------------------ optimizing ------------------------\")\n",
    "\n",
    "    # We have the problem that we need to determine delta and lambda values previously.\n",
    "    # This needs domain knowledge (in SR context, I think we need to know if data is homogenic or\n",
    "    # if it changes a lot through time).\n",
    "    optimizer = D_MAB(4, verbose=False, policy='max_ucb',\n",
    "                      delta=0.15, lmbda=0.5, scaling=1, # Lambda seems to control how strong will be the exploitation\n",
    "                      pull_f=pullBandit, reward_f=lambda r, **kwargs:r)\n",
    "\n",
    "    # Let's optimize\n",
    "    for i in range(10000):\n",
    "        optimizer.playAndOptimize()\n",
    "\n",
    "    total_rewards = {k : sum(v) for (k, v) in optimizer.history.items()}\n",
    "    total_played  = {k : len(v) for (k, v) in optimizer.history.items()}\n",
    "\n",
    "    print(\"cum. reward for each arm: \", total_rewards)\n",
    "    print(\"pulls for each arm      : \", total_played)\n",
    "    print(f\"(it was expected: {expec})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Rewards: [0. 0. 0. 0.]\n",
      "UCB1 scores : [0.25 0.25 0.25 0.25]\n",
      "Picked      : 0\n",
      "Reward      : 1.0\n",
      "Avg. Rewards: [1. 0. 0. 0.]\n",
      "UCB1 scores : [1.83255461 1.17741002 1.17741002 1.17741002]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.5 0.  0.  0. ]\n",
      "UCB1 scores : [1.8558085  1.48230381 1.48230381 1.48230381]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.33333333 0.         0.         0.        ]\n",
      "UCB1 scores : [1.83255461 1.66510922 1.66510922 1.66510922]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.25 0.   0.   0.  ]\n",
      "UCB1 scores : [1.80235601 1.79412258 1.79412258 1.79412258]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.2 0.  0.  0. ]\n",
      "UCB1 scores : [1.77282156 1.89301847 1.89301847 1.89301847]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.2 0.  0.  0. ]\n",
      "UCB1 scores : [1.80537986 1.39495883 1.9727697  1.9727697 ]\n",
      "Picked      : 2\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.2 0.  0.  0. ]\n",
      "UCB1 scores : [1.83255461 1.44202689 1.44202689 2.03933398]\n",
      "Picked      : 3\n",
      "Reward      : 1.0\n",
      "Avg. Rewards: [0.2 0.  0.  1. ]\n",
      "UCB1 scores : [1.02247517 1.48230381 1.48230381 2.31563714]\n",
      "Picked      : 3\n",
      "Reward      : 1.0\n",
      "Avg. Rewards: [0.2 0.  0.  1. ]\n",
      "UCB1 scores : [1.04275363 1.51742713 1.51742713 2.0723074 ]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.2        0.         0.         0.66666667]\n",
      "UCB1 scores : [1.12480414 1.54851389 1.54851389 1.86419544]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.2 0.  0.  0.5]\n",
      "UCB1 scores : [1.19582539 1.57635867 1.57635867 1.71126247]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.2 0.  0.  0.4]\n",
      "UCB1 scores : [1.25798631 1.60154593 1.60154593 1.59131964]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.2 0.  0.  0.4]\n",
      "UCB1 scores : [1.27124899 1.32641304 1.62451757 1.60458232]\n",
      "Picked      : 2\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.2 0.  0.  0.4]\n",
      "UCB1 scores : [1.28342985 1.34363939 1.34363939 1.61676319]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.2        0.         0.         0.33333333]\n",
      "UCB1 scores : [1.33635126 1.35955599 1.35955599 1.51503832]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.2        0.         0.         0.28571429]\n",
      "UCB1 scores : [1.38356944 1.37433944 1.37433944 1.42984288]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.2  0.   0.   0.25]\n",
      "UCB1 scores : [1.42600303 1.38813346 1.38813346 1.35699478]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16666667 0.         0.         0.25      ]\n",
      "UCB1 scores : [1.31720678 1.4010565  1.4010565  1.40890035]\n",
      "Picked      : 3\n",
      "Reward      : 1.0\n",
      "Avg. Rewards: [0.16666667 0.         0.         0.33333333]\n",
      "UCB1 scores : [1.25849467 1.41320729 1.41320729 1.44071218]\n",
      "Picked      : 3\n",
      "Reward      : 1.0\n",
      "Avg. Rewards: [0.16666667 0.         0.         0.4       ]\n",
      "UCB1 scores : [1.22678241 1.42466895 1.42466895 1.44989145]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16666667 0.         0.         0.36363636]\n",
      "UCB1 scores : [1.25404898 1.43551209 1.43551209 1.40347033]\n",
      "Picked      : 1\n",
      "Reward      : 1.0\n",
      "Avg. Rewards: [0.16666667 0.33333333 0.         0.36363636]\n",
      "UCB1 scores : [1.13947889 1.638062   1.44579718 1.14395122]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16666667 0.25       0.         0.36363636]\n",
      "UCB1 scores : [1.16649064 1.44787295 1.45557636 1.1938076 ]\n",
      "Picked      : 2\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16666667 0.25       0.         0.36363636]\n",
      "UCB1 scores : [1.17259109 1.4550911  1.26863624 1.19846689]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16666667 0.2        0.         0.36363636]\n",
      "UCB1 scores : [1.19303944 1.3159876  1.27634175 1.23482157]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16666667 0.16666667 0.         0.36363636]\n",
      "UCB1 scores : [1.20952606 1.20952606 1.28371275 1.26289103]\n",
      "Picked      : 2\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16666667 0.16666667 0.         0.36363636]\n",
      "UCB1 scores : [1.21486525 1.21486525 1.154505   1.26696891]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16666667 0.16666667 0.         0.33333333]\n",
      "UCB1 scores : [1.23085907 1.23085907 1.16056811 1.21975379]\n",
      "Picked      : 0\n",
      "Reward      : 1.0\n",
      "Avg. Rewards: [0.28571429 0.16666667 0.         0.33333333]\n",
      "UCB1 scores : [1.28575314 1.19790551 1.16639571 1.14761034]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.25       0.16666667 0.         0.33333333]\n",
      "UCB1 scores : [1.20689402 1.21274693 1.17200464 1.17129087]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.25       0.14285714 0.         0.33333333]\n",
      "UCB1 scores : [1.22185191 1.12754566 1.17741002 1.18921509]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.22222222 0.14285714 0.         0.33333333]\n",
      "UCB1 scores : [1.15442431 1.13949299 1.18262548 1.21070591]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.22222222 0.14285714 0.         0.30769231]\n",
      "UCB1 scores : [1.17011333 1.15127151 1.18766334 1.16711487]\n",
      "Picked      : 2\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.22222222 0.14285714 0.         0.30769231]\n",
      "UCB1 scores : [1.17355797 1.15512273 1.08863034 1.17002612]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.2        0.14285714 0.         0.30769231]\n",
      "UCB1 scores : [1.11461822 1.16610383 1.09293472 1.1884667 ]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.2        0.14285714 0.         0.28571429]\n",
      "UCB1 scores : [1.12844753 1.1773935  1.09710496 1.14841556]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.2        0.125      0.         0.28571429]\n",
      "UCB1 scores : [1.14073768 1.10376261 1.10114882 1.16426392]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.2        0.125      0.         0.26666667]\n",
      "UCB1 scores : [1.15417896 1.11355626 1.1050734  1.12742071]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.18181818 0.125      0.         0.26666667]\n",
      "UCB1 scores : [1.10114123 1.12336666 1.10888524 1.14404415]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.18181818 0.125      0.         0.25      ]\n",
      "UCB1 scores : [1.11325082 1.13291604 1.11259038 1.10995677]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.18181818 0.11111111 0.         0.25      ]\n",
      "UCB1 scores : [1.12415233 1.0692516  1.11619437 1.12358338]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16666667 0.11111111 0.         0.25      ]\n",
      "UCB1 scores : [1.07647743 1.07784403 1.11970236 1.13888653]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16666667 0.11111111 0.         0.23529412]\n",
      "UCB1 scores : [1.08784995 1.08652483 1.12311911 1.10703185]\n",
      "Picked      : 2\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16666667 0.11111111 0.         0.23529412]\n",
      "UCB1 scores : [1.09011221 1.0891042  1.04288919 1.1089544 ]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16666667 0.11111111 0.         0.22222222]\n",
      "UCB1 scores : [1.10081086 1.09728124 1.04589557 1.07927898]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.15384615 0.11111111 0.         0.22222222]\n",
      "UCB1 scores : [1.05742354 1.10558343 1.04882895 1.09275538]\n",
      "Picked      : 1\n",
      "Reward      : 1.0\n",
      "Avg. Rewards: [0.15384615 0.2        0.         0.22222222]\n",
      "UCB1 scores : [1.01072132 1.18614151 1.05169265 1.0241099 ]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.15384615 0.18181818 0.         0.22222222]\n",
      "UCB1 scores : [1.02140288 1.13128515 1.05448976 1.0383797 ]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.15384615 0.16666667 0.         0.22222222]\n",
      "UCB1 scores : [1.03103425 1.08287634 1.05722318 1.05115895]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.15384615 0.15384615 0.         0.22222222]\n",
      "UCB1 scores : [1.03978197 1.03978197 1.05989563 1.06268709]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.15384615 0.15384615 0.         0.21052632]\n",
      "UCB1 scores : [1.04818279 1.04818279 1.06250966 1.03483919]\n",
      "Picked      : 2\n",
      "Reward      : 1.0\n",
      "Avg. Rewards: [0.15384615 0.15384615 0.14285714 0.21052632]\n",
      "UCB1 scores : [0.98583747 0.98583747 1.21237756 0.94856272]\n",
      "Picked      : 2\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.15384615 0.15384615 0.125      0.21052632]\n",
      "UCB1 scores : [0.99406907 0.99406907 1.13584507 0.95888538]\n",
      "Picked      : 2\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.15384615 0.15384615 0.11111111 0.21052632]\n",
      "UCB1 scores : [1.00108188 1.00108188 1.07180137 0.96755967]\n",
      "Picked      : 2\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.15384615 0.15384615 0.1        0.21052632]\n",
      "UCB1 scores : [1.00717463 1.00717463 1.01725617 0.97499359]\n",
      "Picked      : 2\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.15384615 0.15384615 0.09090909 0.21052632]\n",
      "UCB1 scores : [1.012554   1.012554   0.97012344 0.98146926]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.14285714 0.15384615 0.09090909 0.21052632]\n",
      "UCB1 scores : [0.97462987 1.01882702 0.97462903 0.98918511]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.14285714 0.14285714 0.09090909 0.21052632]\n",
      "UCB1 scores : [0.98064711 0.98064711 0.97920343 0.99711244]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.14285714 0.14285714 0.09090909 0.2       ]\n",
      "UCB1 scores : [0.98660674 0.98660674 0.98372712 0.97129667]\n",
      "Picked      : 0\n",
      "Reward      : 1.0\n",
      "Avg. Rewards: [0.2        0.14285714 0.09090909 0.2       ]\n",
      "UCB1 scores : [1.03241352 0.96575875 0.97117787 0.94128281]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.1875     0.14285714 0.09090909 0.2       ]\n",
      "UCB1 scores : [0.99861373 0.97175682 0.9756994  0.94886848]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.17647059 0.14285714 0.09090909 0.2       ]\n",
      "UCB1 scores : [0.9676735  0.9773494  0.97995027 0.95590103]\n",
      "Picked      : 2\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.17647059 0.14285714 0.08333333 0.2       ]\n",
      "UCB1 scores : [0.97259696 0.98170341 0.93816822 0.96121362]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.17647059 0.13333333 0.08333333 0.2       ]\n",
      "UCB1 scores : [0.97856457 0.94714954 0.94187807 0.96771422]\n",
      "Picked      : 0\n",
      "Reward      : 1.0\n",
      "Avg. Rewards: [0.22222222 0.13333333 0.08333333 0.2       ]\n",
      "UCB1 scores : [1.01191666 0.93237158 0.93328114 0.94471961]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.21052632 0.13333333 0.08333333 0.2       ]\n",
      "UCB1 scores : [0.98410035 0.93756091 0.93715302 0.95168987]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.2        0.13333333 0.08333333 0.2       ]\n",
      "UCB1 scores : [0.95824694 0.9424658  0.94083671 0.95824694]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.19047619 0.13333333 0.08333333 0.2       ]\n",
      "UCB1 scores : [0.93414371 0.9471127  0.94434907 0.96443006]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.19047619 0.13333333 0.08333333 0.19047619]\n",
      "UCB1 scores : [0.94019661 0.95184751 0.94790661 0.94019661]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.19047619 0.125      0.08333333 0.19047619]\n",
      "UCB1 scores : [0.94574044 0.92028203 0.95122702 0.94574044]\n",
      "Picked      : 2\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.19047619 0.125      0.07692308 0.19047619]\n",
      "UCB1 scores : [0.95031565 0.92377569 0.9136061  0.95031565]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.18181818 0.125      0.07692308 0.19047619]\n",
      "UCB1 scores : [0.92744202 0.92815216 0.91685543 0.95624763]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.18181818 0.125      0.07692308 0.18181818]\n",
      "UCB1 scores : [0.93325704 0.93261028 0.92014656 0.93325704]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.17391304 0.125      0.07692308 0.18181818]\n",
      "UCB1 scores : [0.91169087 0.93685215 0.92329642 0.93876752]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.17391304 0.125      0.07692308 0.17391304]\n",
      "UCB1 scores : [0.91709472 0.94116774 0.92648367 0.91709472]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.17391304 0.11764706 0.07692308 0.17391304]\n",
      "UCB1 scores : [0.92228926 0.91162903 0.92956674 0.92228926]\n",
      "Picked      : 2\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.17391304 0.11764706 0.07142857 0.17391304]\n",
      "UCB1 scores : [0.92646353 0.91487984 0.89520281 0.92646353]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16666667 0.11764706 0.07142857 0.17391304]\n",
      "UCB1 scores : [0.9059025  0.91889417 0.89813642 0.93177545]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16666667 0.11764706 0.07142857 0.16666667]\n",
      "UCB1 scores : [0.91111773 0.92297743 0.90110493 0.91111773]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16666667 0.11111111 0.07142857 0.16666667]\n",
      "UCB1 scores : [0.91599845 0.89551225 0.90391993 0.91599845]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16       0.11111111 0.07142857 0.16666667]\n",
      "UCB1 scores : [0.89643298 0.89928098 0.90680061 0.92105545]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16       0.11111111 0.07142857 0.16      ]\n",
      "UCB1 scores : [0.90140153 0.90311173 0.90971499 0.90140153]\n",
      "Picked      : 2\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16       0.11111111 0.06666667 0.16      ]\n",
      "UCB1 scores : [0.90523681 0.90615042 0.87814097 0.90523681]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.16       0.10526316 0.06666667 0.16      ]\n",
      "UCB1 scores : [0.90983702 0.88051219 0.8807263  0.90983702]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.15384615 0.10526316 0.06666667 0.16      ]\n",
      "UCB1 scores : [0.89111604 0.88409971 0.88342338 0.91472632]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.15384615 0.10526316 0.06666667 0.15384615]\n",
      "UCB1 scores : [0.89592445 0.88774552 0.88615192 0.89592445]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.14814815 0.10526316 0.06666667 0.15384615]\n",
      "UCB1 scores : [0.87811613 0.89123877 0.88877851 0.9005165 ]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.14814815 0.10526316 0.06666667 0.14814815]\n",
      "UCB1 scores : [0.88263341 0.89478552 0.89143378 0.88263341]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.14814815 0.1        0.06666667 0.14814815]\n",
      "UCB1 scores : [0.88693472 0.87063983 0.89398414 0.88693472]\n",
      "Picked      : 2\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.14814815 0.1        0.0625     0.14814815]\n",
      "UCB1 scores : [0.89053654 0.87340476 0.86471032 0.89053654]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.14285714 0.1        0.0625     0.14814815]\n",
      "UCB1 scores : [0.87343963 0.87674124 0.86718162 0.89499108]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.14285714 0.1        0.0625     0.14285714]\n",
      "UCB1 scores : [0.87782533 0.88012823 0.86967986 0.87782533]\n",
      "Picked      : 1\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.14285714 0.0952381  0.0625     0.14285714]\n",
      "UCB1 scores : [0.88190713 0.85743671 0.87203827 0.88190713]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.13793103 0.0952381  0.0625     0.14285714]\n",
      "UCB1 scores : [0.86552476 0.86059725 0.87447242 0.88617743]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.13793103 0.0952381  0.0625     0.13793103]\n",
      "UCB1 scores : [0.86973127 0.86380391 0.87693266 0.86973127]\n",
      "Picked      : 2\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.13793103 0.0952381  0.05882353 0.13793103]\n",
      "UCB1 scores : [0.87307739 0.86641302 0.84977565 0.87307739]\n",
      "Picked      : 0\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.13333333 0.0952381  0.05882353 0.13793103]\n",
      "UCB1 scores : [0.85736402 0.86953017 0.85205346 0.8771642 ]\n",
      "Picked      : 3\n",
      "Reward      : 1.0\n",
      "Avg. Rewards: [0.13333333 0.0952381  0.05882353 0.16666667]\n",
      "UCB1 scores : [0.8381267  0.85607374 0.84409068 0.91153818]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "Avg. Rewards: [0.13333333 0.0952381  0.05882353 0.16129032]\n",
      "UCB1 scores : [0.84224041 0.85929345 0.84642399 0.89596468]\n",
      "Picked      : 3\n",
      "Reward      : 0.0\n",
      "cum. reward for each arm:  {0: 4.0, 1: 2.0, 2: 1.0, 3: 5.0}\n",
      "pulls for each arm      :  {0: 30, 1: 21, 2: 17, 3: 32}\n",
      "(it was expected: similar amount of pulls for each arm)\n"
     ]
    }
   ],
   "source": [
    "# Simple test with verbose\n",
    "bandits, descr, expec = (np.array([1.0, 1.0,  1.0,  1.0]), 'All bandits with same probs', 'similar amount of pulls for each arm')\n",
    "\n",
    "def pullBandit(bandit, **kwargs):\n",
    "    result = np.random.randn()\n",
    "    return 1.0 if result > bandits[bandit] else 0.0\n",
    "\n",
    "optimizer = D_MAB(4, verbose=True, policy='max_ucb',\n",
    "                    delta=0.25, lmbda=10, scaling=1,\n",
    "                    pull_f=pullBandit, reward_f=lambda r, **kwargs:r)\n",
    "\n",
    "# Let's optimize\n",
    "for i in range(100):\n",
    "    optimizer.playAndOptimize()\n",
    "\n",
    "total_rewards = {k : sum(v) for (k, v) in optimizer.history.items()}\n",
    "total_played  = {k : len(v) for (k, v) in optimizer.history.items()}\n",
    "\n",
    "print(\"cum. reward for each arm: \", total_rewards)\n",
    "print(\"pulls for each arm      : \", total_played)\n",
    "print(f\"(it was expected: {expec})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so the D-MAB seems to work. Now let's add this MAB inside mutation to update PARAMS option and control dinamically the mutaiton probabilities during evolution.\n",
    "\n",
    "We can import the brush estimator and replace the `_mutation` by a custom function. Ideally, to use this python MAB optimizer, we need to have an object created to keep track of the variables, and the object needs to wrap the _pull_ action, as well as evaluating the reward based on the result.\n",
    "\n",
    "> we'll need to do a _gambiarra_ to know which mutation is used so we can correctly update `D_MAB`. All MAB logic is implemented in python, and we chose the mutation in python as well. To make sure a specific mutation was used, we force it to happen by setting others' weights to zero. this way we know exactly what happened in the C++ code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brush import BrushRegressor\n",
    "from deap import creator\n",
    "import _brush\n",
    "from deap_api import nsga2, DeapIndividual \n",
    "\n",
    "#prg.mutate is a convenient interface that uses the current search space to sample mutations\n",
    "\n",
    "class BrushRegressorMod(BrushRegressor):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def _mutate(self, ind1):\n",
    "        # Overriding the mutation so it is wrapped with D_MAB\n",
    "        \n",
    "        mutation, offspring, reward = self.D_MAB_.playAndOptimize(ind1=ind1)\n",
    "        \n",
    "        #print(mutation, ind1.prg.get_model(), offspring.prg.get_model(), reward)\n",
    "        return offspring\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        _brush.set_params(self.get_params())\n",
    "\n",
    "        self.data_ = self._make_data(X,y)\n",
    "\n",
    "        # Creating a wrapper for mutation to be able to control what is happening in the C++\n",
    "        # code (this should be prettier in a future implementation)\n",
    "        def _pull_mutation(mutation_idx, ind1, **kwargs):\n",
    "            mutations = ['point', 'insert', 'delete', 'toggle_weight']\n",
    "            params = self.get_params()\n",
    "\n",
    "            for i, m in enumerate(mutations):\n",
    "                params['mutation_options'][m] = 0 if i != mutation_idx else 1.0\n",
    "\n",
    "            _brush.set_params(params)\n",
    "        \n",
    "            offspring = creator.Individual(ind1.prg.mutate())\n",
    "\n",
    "            return offspring\n",
    "        \n",
    "        # Given the result of a pull (the mutated offspring), how do I evaluate it?\n",
    "        # I need to return if the reward was positive or negative. We make use of\n",
    "        # kwargs here.\n",
    "        # (here I am manually writing the multi-optimization problem nsga2 is\n",
    "        # designed to solve)\n",
    "        def _evaluate_reward(pulled, ind1, **kwargs):\n",
    "            if True: #not ind1.fitness.valid:\n",
    "                ind1.prg.fit(self.data_)\n",
    "                fit = (\n",
    "                    np.sum((self.data_.y- ind1.prg.predict(self.data_))**2),\n",
    "                    ind1.prg.size()\n",
    "                )\n",
    "            \n",
    "                ind1.fitness.setValues(fit)\n",
    "                # ind1.fitness = fit\n",
    "\n",
    "            # in deap, a negative weight means a minimization problem, while a \n",
    "            # positive weight is a maximization problem.\n",
    "\n",
    "            # ind1_error, ind1_size = ind1.fitness.values\n",
    "            # ind1_fitness = -1.0*ind1_error + -1.0*ind1_size\n",
    "\n",
    "            if True: #not pulled.fitness.valid:\n",
    "                pulled.prg.fit(self.data_)\n",
    "                fit = (\n",
    "                    np.sum((self.data_.y- pulled.prg.predict(self.data_))**2),\n",
    "                    pulled.prg.size()\n",
    "                )\n",
    "            \n",
    "                pulled.fitness.setValues(fit)\n",
    "                # pulled.fitness = fit\n",
    "            \n",
    "            # pulled_error, pulled_size = pulled.fitness.values\n",
    "            # pulled_fitness = -1.0*pulled_error + -1.0*pulled_size\n",
    "\n",
    "            # We compare fitnesses using the deap overloaded operators\n",
    "            # from the docs: When comparing fitness values that are **minimized**, ``a > b`` will\n",
    "            # return :data:`True` if *a* is **smaller** than *b*.\n",
    "            return 1.0 if pulled.fitness.dominates(ind1.fitness) else 0.0\n",
    "\n",
    "            # return 0.0 if pulled.fitness.values <= ind1.fitness.values else 1.0\n",
    "            \n",
    "        # We have 4 different mutations\n",
    "        self.D_MAB_ = D_MAB(4, verbose=False, policy='max_ucb', \n",
    "                            delta=0.15, lmbda=5, scaling=1,\n",
    "                            pull_f=_pull_mutation, reward_f=_evaluate_reward)\n",
    "\n",
    "        if isinstance(self.functions, list):\n",
    "            self.functions_ = {k:1.0 for k in self.functions}\n",
    "        else:\n",
    "            self.functions_ = self.functions\n",
    "\n",
    "        self.search_space_ = _brush.SearchSpace(self.data_, self.functions_)\n",
    "        self.toolbox_ = self._setup_toolbox(data=self.data_)\n",
    "\n",
    "        archive, logbook = nsga2(self.toolbox_, self.max_gen, self.pop_size, 0.9, self.verbosity)\n",
    "\n",
    "        self.archive_ = archive\n",
    "        self.best_estimator_ = self.archive_[0].prg\n",
    "        total_played  = {k : len(v) for (k, v) in self.D_MAB_.history.items()}\n",
    "\n",
    "        print(total_played)\n",
    "        print(self.D_MAB_.avg_reward)\n",
    "        print('best model:',self.best_estimator_.get_model())\n",
    "        return self\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets use this new mutation into an ES algorithm (because this is only based on mutation) and see if it improves the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# I am getting tons of unharmful warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# df = pd.read_csv('../../docs/examples/datasets/d_enc.csv')\n",
    "# X = df.drop(columns='label')\n",
    "# y = df['label']\n",
    "\n",
    "df = pd.read_csv('../../docs/examples/datasets/d_2x1_subtract_3x2.csv')\n",
    "X = df.drop(columns='target')\n",
    "y = df['target']\n",
    "\n",
    "# df = pd.read_csv('../../docs/examples/datasets/d_square_x1_plus_2_x1_x2_plus_square_x2.csv')\n",
    "# X = df.drop(columns='target')\n",
    "# y = df['target']\n",
    "\n",
    "kwargs = {\n",
    "    'pop_size'  : 160,\n",
    "    'max_gen'   : 160,\n",
    "    'verbosity' : 0,\n",
    "    'max_depth' : 10,\n",
    "    'max_size'  : 20,\n",
    "    'mutation_options' : {\"point\":0.25, \"insert\": 0.25, \"delete\":  0.25, \"toggle_weight\": 0.25}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------- Run 0 --------------------------------------\n",
      "{0: 2171, 1: 478, 2: 21518, 3: 1273}\n",
      "[0.0105942  0.00627615 0.01319825 0.00942655]\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 1 --------------------------------------\n",
      "{0: 2849, 1: 1088, 2: 19959, 3: 1544}\n",
      "[0.00807301 0.00643382 0.00971993 0.00712435]\n",
      "best model: 3.68*Sin(2.74*x1)\n",
      "score: 0.8675268611694\n",
      "-------------------------------------- Run 2 --------------------------------------\n",
      "{0: 1899, 1: 1038, 2: 18860, 3: 3643}\n",
      "[0.00684571 0.00578035 0.00890774 0.00768597]\n",
      "best model: Sub(-3.00*x2,-2.00*x1)\n",
      "score: 0.999999999999994\n",
      "-------------------------------------- Run 3 --------------------------------------\n",
      "{0: 22499, 1: 198, 2: 2073, 3: 670}\n",
      "[0.00634495 0.         0.00455322 0.00350263]\n",
      "best model: If(x2>-0.46,-4.09*x2,3.18)\n",
      "score: 0.6802750800991533\n",
      "-------------------------------------- Run 4 --------------------------------------\n",
      "{0: 2204, 1: 1989, 2: 17573, 3: 3674}\n",
      "[0.00771325 0.00754148 0.00978774 0.00843767]\n",
      "best model: Mean(-7.49*x2,-2.26*x2,-2.25*x2,8.00*x1)\n",
      "score: 0.9999999963496158\n",
      "-------------------------------------- Run 5 --------------------------------------\n",
      "{0: 3365, 1: 987, 2: 18741, 3: 2347}\n",
      "[0.00950966 0.0070922  0.01115202 0.00894759]\n",
      "best model: Sum(-3.00*x2,1.00*x1,1.00*x1)\n",
      "score: 0.9999999999999972\n",
      "-------------------------------------- Run 6 --------------------------------------\n",
      "{0: 2970, 1: 1621, 2: 16380, 3: 4469}\n",
      "[0.00841751 0.00740284 0.01007326 0.00895055]\n",
      "best model: Sum(-3.00*x2,-0.00,2.00*x1)\n",
      "score: 0.999999999999994\n",
      "-------------------------------------- Run 7 --------------------------------------\n",
      "{0: 2134, 1: 1638, 2: 18855, 3: 2813}\n",
      "[0.00843486 0.00793651 0.01076637 0.00888731]\n",
      "best model: Sum(-3.00*x2,2.00*x1,-0.00)\n",
      "score: 0.999999999999994\n",
      "-------------------------------------- Run 8 --------------------------------------\n",
      "{0: 2168, 1: 1352, 2: 18865, 3: 3055}\n",
      "[0.00830258 0.00739645 0.01054864 0.00883797]\n",
      "best model: 3.68*Sin(2.74*x1)\n",
      "score: 0.8675268611694\n",
      "-------------------------------------- Run 9 --------------------------------------\n",
      "{0: 1893, 1: 1446, 2: 19446, 3: 2655}\n",
      "[0.00739567 0.00691563 0.0096678  0.0079096 ]\n",
      "best model: 1.77*Atan(44784.27*x1)\n",
      "score: 0.7629047704797927\n",
      "-------------------------------------- Run 10 --------------------------------------\n",
      "{0: 1994, 1: 1249, 2: 19042, 3: 3155}\n",
      "[0.00902708 0.00800641 0.01165844 0.00982567]\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 11 --------------------------------------\n",
      "{0: 2065, 1: 977, 2: 21216, 3: 1182}\n",
      "[0.00871671 0.00716479 0.01107655 0.00761421]\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 12 --------------------------------------\n",
      "{0: 3056, 1: 2241, 2: 17696, 3: 2447}\n",
      "[0.00850785 0.00803213 0.01017179 0.00817327]\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 13 --------------------------------------\n",
      "{0: 5531, 1: 1556, 2: 15699, 3: 2654}\n",
      "[0.01048635 0.00835476 0.0114657  0.00941974]\n",
      "best model: Min(-4.21*x2,-3.65*x2,2.50*x1,2.20*x1)\n",
      "score: 0.7673079213877327\n",
      "-------------------------------------- Run 14 --------------------------------------\n",
      "{0: 2756, 1: 1309, 2: 18339, 3: 3036}\n",
      "[0.00907112 0.00763942 0.01101478 0.00922266]\n",
      "best model: 1.77*Atan(27369.91*x1)\n",
      "score: 0.7629018280064254\n",
      "-------------------------------------- Run 15 --------------------------------------\n",
      "{0: 4296, 1: 2202, 2: 17734, 3: 1208}\n",
      "[0.00861266 0.00772025 0.00975527 0.00662252]\n",
      "best model: Sum(-3.00*x2,2.00*x1)\n",
      "score: 0.9999999999999978\n",
      "-------------------------------------- Run 16 --------------------------------------\n",
      "{0: 2827, 1: 1358, 2: 18698, 3: 2557}\n",
      "[0.00955076 0.00810015 0.01155204 0.009386  ]\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 17 --------------------------------------\n",
      "{0: 1108, 1: 513, 2: 20827, 3: 2992}\n",
      "[0.00812274 0.00584795 0.01185961 0.01002674]\n",
      "best model: 2.79*Tanh(469.33*x1)\n",
      "score: 0.7629093888079747\n",
      "-------------------------------------- Run 18 --------------------------------------\n",
      "{0: 2647, 1: 1243, 2: 16900, 3: 4650}\n",
      "[0.00868908 0.00724055 0.01059172 0.00946237]\n",
      "best model: Mean(0.00,6.00*x1,-9.00*x2)\n",
      "score: 0.999999999999994\n",
      "-------------------------------------- Run 19 --------------------------------------\n",
      "{0: 1370, 1: 2894, 2: 17912, 3: 3264}\n",
      "[0.00583942 0.00691085 0.00831845 0.00704657]\n",
      "best model: 1.77*Atan(44784.27*x1)\n",
      "score: 0.7629047704797927\n",
      "-------------------------------------- Run 20 --------------------------------------\n",
      "{0: 2724, 1: 2819, 2: 15853, 3: 4044}\n",
      "[0.00881057 0.00886839 0.01072352 0.00939664]\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 21 --------------------------------------\n",
      "{0: 3662, 1: 2350, 2: 16771, 3: 2657}\n",
      "[0.00873839 0.00808511 0.01013655 0.00828002]\n",
      "best model: 2.79*Tanh(469.33*x1)\n",
      "score: 0.7629093888079747\n",
      "-------------------------------------- Run 22 --------------------------------------\n",
      "{0: 2518, 1: 1610, 2: 18130, 3: 3182}\n",
      "[0.00754567 0.0068323  0.00932157 0.00785669]\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 23 --------------------------------------\n",
      "{0: 1732, 1: 2975, 2: 18429, 3: 2304}\n",
      "[0.00692841 0.00773109 0.00927885 0.00737847]\n",
      "best model: Sum(-3.00*x2,2.00*x1)\n",
      "score: 0.9999999999999978\n",
      "-------------------------------------- Run 24 --------------------------------------\n",
      "{0: 4058, 1: 991, 2: 17180, 3: 3211}\n",
      "[0.00837851 0.00605449 0.00954598 0.00809717]\n",
      "best model: 2.79*Tanh(26112.86*x1)\n",
      "score: 0.7629093888079747\n",
      "-------------------------------------- Run 25 --------------------------------------\n",
      "{0: 2044, 1: 1596, 2: 18542, 3: 3258}\n",
      "[0.0092955  0.00877193 0.01197282 0.01012891]\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 26 --------------------------------------\n",
      "{0: 3997, 1: 2511, 2: 14823, 3: 4109}\n",
      "[0.00775582 0.00716846 0.00883762 0.00778778]\n",
      "best model: Min(-4.17*x2,3.18,2.22*x1)\n",
      "score: 0.7859226715696217\n",
      "-------------------------------------- Run 27 --------------------------------------\n",
      "{0: 1594, 1: 1594, 2: 19724, 3: 2528}\n",
      "[0.00752823 0.00752823 0.01024133 0.00830696]\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 28 --------------------------------------\n",
      "{0: 4727, 1: 2388, 2: 15729, 3: 2596}\n",
      "[0.00888513 0.00795645 0.00991799 0.00808937]\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 29 --------------------------------------\n",
      "{0: 4119, 1: 2164, 2: 17104, 3: 2053}\n",
      "[0.00825443 0.00739372 0.009413   0.00730638]\n",
      "best model: Median(-22.36*x2,-6.00*x2,11.75*x2,4.00*x1)\n",
      "score: 0.9999999999995968\n",
      "Score mean (30 runs): 0.8019754956000301\n",
      "Score std (30 runs) : 0.14304976030314429\n",
      "gen\tevals\tave              \tstd                    \tmin      \n",
      "0  \t160  \t[    nan 20.7375]\t[       nan 0.89782724]\t[nan 20.]\n",
      "1  \t0    \t[     nan 13.75625]\t[       nan 6.53141148]\t[nan  1.]\n",
      "2  \t0    \t[    nan 4.43125]  \t[       nan 3.67529229]\t[nan  1.]\n",
      "3  \t0    \t[ nan 1.05]        \t[       nan 0.21794495]\t[nan  1.]\n",
      "4  \t0    \t[20.78805373  1.0125    ]\t[4.21350124 0.11110243]\t[17.82939148  1.        ]\n",
      "5  \t0    \t[18.41994362  1.0125    ]\t[2.18973088 0.11110243]\t[17.82939148  1.        ]\n",
      "6  \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]\n",
      "7  \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]\n",
      "8  \t0    \t[17.71795778  1.0125    ]\t[1.40512545 0.157619  ]\t[4.01456646e-13 1.00000000e+00]\n",
      "9  \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "10 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "11 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "12 \t0    \t[17.77717035  1.05625   ]\t[0.54768345 0.4220023 ]\t[10.98111534  1.        ]      \n",
      "13 \t0    \t[17.71795778  1.0125    ]\t[1.40512545 0.157619  ]\t[1.59872116e-13 1.00000000e+00]\n",
      "14 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "15 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "16 \t0    \t[17.71795778  1.0125    ]\t[1.40512544 0.157619  ]\t[1.35152462e-07 1.00000000e+00]\n",
      "17 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "18 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "19 \t0    \t[17.71795778  1.0125    ]\t[1.40512545 0.157619  ]\t[1.59872116e-13 1.00000000e+00]\n",
      "20 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "21 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "22 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "23 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "24 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "25 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "26 \t0    \t[17.61736346  1.05625   ]\t[1.82697719 0.4220023 ]\t[2.03570494e-11 1.00000000e+00]\n",
      "27 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "28 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "29 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "30 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "31 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "32 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "33 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "34 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "35 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "36 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "37 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "38 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "39 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "40 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "41 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "42 \t0    \t[17.82013974  1.0125    ]\t[0.11665997 0.157619  ]\t[16.34911346  1.        ]      \n",
      "43 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "44 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "45 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "46 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "47 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "48 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "49 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "50 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "51 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "52 \t0    \t[17.71795778  1.0125    ]\t[1.40512545 0.157619  ]\t[4.01456646e-13 1.00000000e+00]\n",
      "53 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "54 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "55 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "56 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "57 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "58 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "59 \t0    \t[17.81441762  1.025     ]\t[0.13309053 0.22220486]\t[16.63148308  1.        ]      \n",
      "60 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "61 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "62 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "63 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "64 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "65 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "66 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "67 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "68 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "69 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "70 \t0    \t[17.71795778  1.0125    ]\t[1.40512544 0.157619  ]\t[1.35152462e-07 1.00000000e+00]\n",
      "71 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "72 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "73 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "74 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "75 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "76 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "77 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "78 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "79 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "80 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "81 \t0    \t[17.82013974  1.0125    ]\t[0.11665997 0.157619  ]\t[16.34911346  1.        ]      \n",
      "82 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "83 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "84 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "85 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "86 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "87 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "88 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "89 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "90 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "91 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "92 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "93 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "94 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "95 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "96 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "97 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "98 \t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "99 \t0    \t[17.71602528  1.05625   ]\t[1.40518347 0.4220023 ]\t[1.8656408e-07 1.0000000e+00]  \n",
      "100\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "101\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "102\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "103\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "104\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "105\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "106\t0    \t[17.70870605  1.03125   ]\t[1.40922857 0.28332567]\t[8.93509622e-08 1.00000000e+00]\n",
      "107\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "108\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "109\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "110\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "111\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "112\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "113\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "114\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "115\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "116\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "117\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "118\t0    \t[17.71795778  1.0125    ]\t[1.40512544 0.157619  ]\t[1.35152462e-07 1.00000000e+00]\n",
      "119\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "120\t0    \t[17.82939148  1.        ]\t[0. 0.]                \t[17.82939148  1.        ]      \n",
      "121\t0    \t[17.71795778  1.0125    ]\t[1.40512545 0.157619  ]\t[4.01456646e-13 1.00000000e+00]\n",
      "122\t0    \t[17.82584144  1.00625   ]\t[0.04476431 0.0788095 ]\t[17.26138496  1.        ]      \n",
      "123\t0    \t[17.71440774  1.01875   ]\t[1.4055569  0.17577951]\t[1.59872116e-13 1.00000000e+00]\n",
      "124\t0    \t[17.60297405  1.03125   ]\t[1.9809951  0.23510304]\t[1.59872116e-13 1.00000000e+00]\n",
      "125\t0    \t[17.58337359  1.03125   ]\t[1.99970409 0.23510304]\t[1.59872116e-13 1.00000000e+00]\n",
      "126\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "127\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "128\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "129\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "130\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "131\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "132\t0    \t[17.76311749  1.01875   ]\t[0.6155492  0.17577951]\t[10.92963123  1.        ]      \n",
      "133\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "134\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "135\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "136\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "137\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "138\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "139\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "140\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "141\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "142\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "143\t0    \t[17.76917413  1.03125   ]\t[0.54950648 0.32445868]\t[11.89869499  1.        ]      \n",
      "144\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "145\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "146\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "147\t0    \t[17.69480729  1.01875   ]\t[1.43332946 0.17577951]\t[1.59872116e-13 1.00000000e+00]\n",
      "148\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "149\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "150\t0    \t[17.76311749  1.01875   ]\t[0.6155492  0.17577951]\t[10.92963123  1.        ]      \n",
      "151\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "152\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "153\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "154\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "155\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "156\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "157\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "158\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "159\t0    \t[17.80624099  1.00625   ]\t[0.29191659 0.0788095 ]\t[14.12531281  1.        ]      \n",
      "Final population hypervolume is 48304.155594\n",
      "{0: 2340, 1: 2455, 2: 19495, 3: 1150}\n",
      "[0.00726496 0.00733198 0.00907925 0.00608696]\n",
      "best model: 1.26*Floor(-3.00*x2)\n",
      "score: 0.7237639565420584\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 30 executions just to compare avg score\n",
    "scores = []\n",
    "for i in range(30):\n",
    "    print(f\"-------------------------------------- Run {i} --------------------------------------\")\n",
    "    est_mab = BrushRegressorMod(**kwargs)\n",
    "\n",
    "    # use like you would a sklearn regressor\n",
    "    est_mab.fit(X,y)\n",
    "    y_pred = est_mab.predict(X)\n",
    "\n",
    "    scores.append(est_mab.score(X,y))\n",
    "    print('score:', scores[-1])\n",
    "print(f\"Score mean (30 runs): {np.mean(scores)}\")\n",
    "print(f\"Score std (30 runs) : {np.std(scores)}\")\n",
    "\n",
    "# Single run with verbosity\n",
    "kwargs['verbosity'] = 1\n",
    "est_mab = BrushRegressorMod(**kwargs)\n",
    "\n",
    "# use like you would a sklearn regressor\n",
    "est_mab.fit(X,y)\n",
    "y_pred = est_mab.predict(X)\n",
    "\n",
    "print('score:', est_mab.score(X,y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing with the original implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------- Run 0 --------------------------------------\n",
      "best model: Floor(-2.98*x2)\n",
      "score: 0.6624346086007631\n",
      "-------------------------------------- Run 1 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 2 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 3 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 4 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 5 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 6 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 7 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 8 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 9 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 10 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 11 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 12 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 13 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 14 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 15 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 16 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 17 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 18 --------------------------------------\n",
      "best model: Floor(-4.43*x2)\n",
      "score: 0.6828901196699741\n",
      "-------------------------------------- Run 19 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 20 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 21 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 22 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 23 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 24 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 25 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 26 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 27 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 28 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "-------------------------------------- Run 29 --------------------------------------\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n",
      "Score mean (30 runs): 0.6527489787565626\n",
      "Score std (30 runs) : 0.005941236653589971\n",
      "gen\tevals\tave            \tstd                  \tmin      \n",
      "0  \t160  \t[   nan 20.625]\t[      nan 0.8042854]\t[nan 20.]\n",
      "1  \t160  \t[     nan 16.53125]\t[       nan 5.41516606]\t[nan  1.]\n",
      "2  \t160  \t[     nan 10.26875]\t[       nan 5.81992469]\t[nan  1.]\n",
      "3  \t160  \t[    nan 4.34375]  \t[       nan 2.71350068]\t[nan  1.]\n",
      "4  \t160  \t[    nan 1.78125]  \t[      nan 0.8190839]  \t[nan  1.]\n",
      "5  \t160  \t[30.36090877  1.0125    ]\t[13.72482068  0.11110243]\t[17.82939148  1.        ]\n",
      "6  \t160  \t[20.26475508  1.00625   ]\t[3.9950179 0.0788095]    \t[17.82939148  1.        ]\n",
      "7  \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "8  \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "9  \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "10 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "11 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "12 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "13 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "14 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "15 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "16 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "17 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "18 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "19 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "20 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "21 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "22 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "23 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "24 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "25 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "26 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "27 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "28 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "29 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "30 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "31 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "32 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "33 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "34 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "35 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "36 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "37 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "38 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "39 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "40 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "41 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "42 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "43 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "44 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "45 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "46 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "47 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "48 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "49 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "50 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "51 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "52 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "53 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "54 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "55 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "56 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "57 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "58 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "59 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "60 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "61 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "62 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "63 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "64 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "65 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "66 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "67 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "68 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "69 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "70 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "71 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "72 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "73 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "74 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "75 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "76 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "77 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "78 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "79 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "80 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "81 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "82 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "83 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "84 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "85 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "86 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "87 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "88 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "89 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "90 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "91 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "92 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "93 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "94 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "95 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "96 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "97 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "98 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "99 \t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "100\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "101\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "102\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "103\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "104\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "105\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "106\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "107\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "108\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "109\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "110\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "111\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "112\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "113\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "114\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "115\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "116\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "117\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "118\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "119\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "120\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "121\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "122\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "123\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "124\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "125\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "126\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "127\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "128\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "129\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "130\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "131\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "132\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "133\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "134\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "135\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "136\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "137\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "138\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "139\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "140\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "141\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "142\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "143\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "144\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "145\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "146\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "147\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "148\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "149\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "150\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "151\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "152\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "153\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "154\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "155\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "156\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "157\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "158\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "159\t160  \t[17.82939148  1.        ]\t[0. 0.]                  \t[17.82939148  1.        ]\n",
      "Final population hypervolume is 48126.359818\n",
      "best model: -4.24*x2\n",
      "score: 0.651326594086648\n"
     ]
    }
   ],
   "source": [
    "# 30 executions just to compare avg score\n",
    "\n",
    "kwargs['verbosity'] = 0\n",
    "\n",
    "scores = []\n",
    "for i in range(30):\n",
    "\n",
    "    print(f\"-------------------------------------- Run {i} --------------------------------------\")\n",
    "    est_mab = BrushRegressor(**kwargs)\n",
    "\n",
    "    # use like you would a sklearn regressor\n",
    "    est_mab.fit(X,y)\n",
    "    y_pred = est_mab.predict(X)\n",
    "\n",
    "    scores.append(est_mab.score(X,y))\n",
    "    print('score:', scores[-1])\n",
    "print(f\"Score mean (30 runs): {np.mean(scores)}\")\n",
    "print(f\"Score std (30 runs) : {np.std(scores)}\")\n",
    "\n",
    "# Single run with verbosity\n",
    "kwargs['verbosity'] = 1\n",
    "est = BrushRegressor(**kwargs)\n",
    "\n",
    "# use like you would a sklearn regressor\n",
    "est.fit(X,y)\n",
    "y_pred = est.predict(X)\n",
    "\n",
    "print('score:', est.score(X,y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brush",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
