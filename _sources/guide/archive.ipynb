{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The archive\n",
    "\n",
    "When you fit a brush estimator, two new attributes are created: `best_estimator_` and `archive_`.\n",
    "\n",
    "If you set `use_arch` to `True` when instantiating the estimator, then it will store the pareto front as a list in `archive_`. This pareto front is always created with individuals from the final population that are not dominated in objectives **scorer** and **complexity**. Setting `scorer` as an objective means optimizing the metric set as `scorer: str`.\n",
    "\n",
    "In case you need more flexibility, the archive will contain the entire final population if `use_arch` is `False`, and you can iterate through this list to select individuals with different criteria. It is also good to remind that Brush supports different optimization objectives using the argument `objectives`.\n",
    "\n",
    "Each element from the archive is a serialized individual (JSON object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pybrush import BrushClassifier\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('../examples/datasets/d_analcatdata_aids.csv')\n",
    "X = df.drop(columns='target')\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1/100 [/                                                 ]\n",
      "Best model on Val:Logistic(Sum(-0.00,0.19*Cos(1.26*Logabs(0.71*Mul(0.71,0.71*AIDS)))))\n",
      "Train Loss (Med): 0.72000 (0.50000)\n",
      "Val Loss (Med): 0.72000 (0.50000)\n",
      "Median Size (Max): 7 (95)\n",
      "Median complexity (Max): 992 (2037174688)\n",
      "Time (s): 0.09034\n",
      "\n",
      "Generation 2/100 [//                                                ]\n",
      "Best model on Val:Logistic(Sum(-0.00,0.19*Cos(1.26*Logabs(0.71*Mul(0.71,0.71*AIDS)))))\n",
      "Train Loss (Med): 0.72000 (0.56000)\n",
      "Val Loss (Med): 0.72000 (0.56000)\n",
      "Median Size (Max): 7 (68)\n",
      "Median complexity (Max): 992 (994658720)\n",
      "Time (s): 0.13514\n",
      "\n",
      "Generation 3/100 [//                                                ]\n",
      "Best model on Val:Logistic(Sum(-0.00,0.19*Cos(1.26*Logabs(0.71*Mul(0.71,0.71*AIDS)))))\n",
      "Train Loss (Med): 0.72000 (0.56000)\n",
      "Val Loss (Med): 0.72000 (0.56000)\n",
      "Median Size (Max): 8 (36)\n",
      "Median complexity (Max): 2096 (66394208)\n",
      "Time (s): 0.17748\n",
      "\n",
      "Generation 4/100 [///                                               ]\n",
      "Best model on Val:Logistic(Sum(-0.00,0.19*Cos(1.26*Logabs(0.71*Mul(0.71,0.71*AIDS)))))\n",
      "Train Loss (Med): 0.72000 (0.56000)\n",
      "Val Loss (Med): 0.72000 (0.56000)\n",
      "Median Size (Max): 7 (23)\n",
      "Median complexity (Max): 992 (66394208)\n",
      "Time (s): 0.20919\n",
      "\n",
      "Generation 5/100 [///                                               ]\n",
      "Best model on Val:Logistic(Sum(0.03,1.02*Cos(1.49*Logabs(-5.86*Mul(-8.20*Add(45.60*AIDS,-21.96*Add(-13.93*AIDS,563.93)),-8.20*Logabs(632.82*Add(1.24*Cos(-1733.10*AIDS),632.82*Total)))))))\n",
      "Train Loss (Med): 0.74000 (0.56000)\n",
      "Val Loss (Med): 0.74000 (0.56000)\n",
      "Median Size (Max): 6 (41)\n",
      "Median complexity (Max): 176 (66394208)\n",
      "Time (s): 0.24115\n",
      "\n",
      "Generation 6/100 [////                                              ]\n",
      "Best model on Val:Logistic(Sum(0.11,Cos(1.37*Logabs(-10.28*Mul(-14.38*Add(70.37*AIDS,-27.39*Add(-15.03*AIDS,538.57)),-14.38*Logabs(815.05*Add(1.24*Cos(-1736.49*AIDS),815.05*Total)))))))\n",
      "Train Loss (Med): 0.78000 (0.56000)\n",
      "Val Loss (Med): 0.78000 (0.56000)\n",
      "Median Size (Max): 5 (41)\n",
      "Median complexity (Max): 176 (66394208)\n",
      "Time (s): 0.27174\n",
      "\n",
      "Generation 7/100 [////                                              ]\n",
      "Best model on Val:Logistic(Sum(0.11,Cos(1.37*Logabs(-10.28*Mul(-14.38*Add(70.35*AIDS,-27.39*Add(-15.02*AIDS,538.61)),-14.38*Logabs(815.05*Add(Cos(-1736.49*AIDS),815.05*Total)))))))\n",
      "Train Loss (Med): 0.78000 (0.50000)\n",
      "Val Loss (Med): 0.78000 (0.50000)\n",
      "Median Size (Max): 5 (37)\n",
      "Median complexity (Max): 128 (66394208)\n",
      "Time (s): 0.30204\n",
      "\n",
      "Generation 8/100 [/////                                             ]\n",
      "Best model on Val:Logistic(Sum(0.11,Cos(1.37*Logabs(-10.28*Mul(-14.38*Add(70.35*AIDS,-27.39*Add(-15.02*AIDS,538.61)),-14.38*Logabs(815.05*Add(Cos(-1736.49*AIDS),815.05*Total)))))))\n",
      "Train Loss (Med): 0.78000 (0.56000)\n",
      "Val Loss (Med): 0.78000 (0.56000)\n",
      "Median Size (Max): 5 (37)\n",
      "Median complexity (Max): 128 (16598432)\n",
      "Time (s): 0.32891\n",
      "\n",
      "Generation 9/100 [/////                                             ]\n",
      "Best model on Val:Logistic(Sum(0.11,Cos(1.37*Logabs(-10.28*Mul(-14.38*Add(70.33*AIDS,-27.39*Add(-15.02*AIDS,538.64)),-14.38*Logabs(815.05*Add(AIDS,815.05*Total)))))))\n",
      "Train Loss (Med): 0.78000 (0.56000)\n",
      "Val Loss (Med): 0.78000 (0.56000)\n",
      "Median Size (Max): 5 (34)\n",
      "Median complexity (Max): 176 (647794976)\n",
      "Time (s): 0.35818\n",
      "\n",
      "Generation 10/100 [//////                                            ]\n",
      "Best model on Val:Logistic(Sum(0.11,Cos(1.37*Logabs(-10.28*Mul(-14.38*Add(70.33*AIDS,-27.39*Add(-15.02*AIDS,538.64)),-14.38*Logabs(815.05*Add(AIDS,815.05*Total)))))))\n",
      "Train Loss (Med): 0.78000 (0.56000)\n",
      "Val Loss (Med): 0.78000 (0.56000)\n",
      "Median Size (Max): 5 (34)\n",
      "Median complexity (Max): 152 (610592)\n",
      "Time (s): 0.38339\n",
      "\n",
      "Generation 11/100 [//////                                            ]\n",
      "Best model on Val:Logistic(Sum(-0.46,Cos(15892.06*Sin(15890.50*Cos(If(AIDS>15890.50,1.00,Total))))))\n",
      "Train Loss (Med): 0.78000 (0.56000)\n",
      "Val Loss (Med): 0.78000 (0.56000)\n",
      "Median Size (Max): 5 (21)\n",
      "Median complexity (Max): 176 (14655776)\n",
      "Time (s): 0.41340\n",
      "\n",
      "Generation 12/100 [///////                                           ]\n",
      "Best model on Val:Logistic(Sum(-0.46,Cos(15892.06*Sin(15890.50*Cos(If(AIDS>15890.50,1.00,Total))))))\n",
      "Train Loss (Med): 0.78000 (0.56000)\n",
      "Val Loss (Med): 0.78000 (0.56000)\n",
      "Median Size (Max): 5 (21)\n",
      "Median complexity (Max): 176 (14655776)\n",
      "Time (s): 0.43893\n",
      "\n",
      "Generation 13/100 [///////                                           ]\n",
      "Best model on Val:Logistic(Sum(-0.46,Cos(15892.06*Sin(15890.50*Cos(If(AIDS>15890.50,1.00,Total))))))\n",
      "Train Loss (Med): 0.78000 (0.56000)\n",
      "Val Loss (Med): 0.78000 (0.56000)\n",
      "Median Size (Max): 5 (21)\n",
      "Median complexity (Max): 176 (14655776)\n",
      "Time (s): 0.46480\n",
      "\n",
      "Generation 14/100 [////////                                          ]\n",
      "Best model on Val:Logistic(Sum(-0.46,Cos(15892.06*Sin(15890.50*Cos(If(AIDS>15890.50,1.00,Total))))))\n",
      "Train Loss (Med): 0.78000 (0.56000)\n",
      "Val Loss (Med): 0.78000 (0.56000)\n",
      "Median Size (Max): 5 (21)\n",
      "Median complexity (Max): 176 (14655776)\n",
      "Time (s): 0.49182\n",
      "\n",
      "Generation 15/100 [////////                                          ]\n",
      "Best model on Val:Logistic(Sum(-0.31,Cos(15890.72*Logabs(15889.52*Cos(If(AIDS>15890.50,1.00,Total))))))\n",
      "Train Loss (Med): 0.80000 (0.56000)\n",
      "Val Loss (Med): 0.80000 (0.56000)\n",
      "Median Size (Max): 5 (21)\n",
      "Median complexity (Max): 176 (24424736)\n",
      "Time (s): 0.52267\n",
      "\n",
      "Generation 16/100 [/////////                                         ]\n",
      "Best model on Val:Logistic(Sum(-0.31,Cos(15890.72*Logabs(15889.52*Cos(If(AIDS>15890.50,1.00,Total))))))\n",
      "Train Loss (Med): 0.80000 (0.56000)\n",
      "Val Loss (Med): 0.80000 (0.56000)\n",
      "Median Size (Max): 5 (21)\n",
      "Median complexity (Max): 176 (24424736)\n",
      "Time (s): 0.55711\n",
      "\n",
      "Generation 17/100 [/////////                                         ]\n",
      "Best model on Val:Logistic(Sum(-0.31,Cos(15890.72*Logabs(15889.52*Cos(If(AIDS>15890.50,1.00,Total))))))\n",
      "Train Loss (Med): 0.80000 (0.56000)\n",
      "Val Loss (Med): 0.80000 (0.56000)\n",
      "Median Size (Max): 5 (21)\n",
      "Median complexity (Max): 176 (24424736)\n",
      "Time (s): 0.59104\n",
      "\n",
      "Generation 18/100 [//////////                                        ]\n",
      "Best model on Val:Logistic(Sum(-0.31,Cos(15890.72*Logabs(15889.52*Cos(If(AIDS>15890.50,1.00,Total))))))\n",
      "Train Loss (Med): 0.78000 (0.56000)\n",
      "Val Loss (Med): 0.80000 (0.56000)\n",
      "Median Size (Max): 5 (18)\n",
      "Median complexity (Max): 176 (6084896)\n",
      "Time (s): 0.61868\n",
      "\n",
      "Generation 19/100 [//////////                                        ]\n",
      "Best model on Val:Logistic(Sum(-0.25,Cos(15889.85*Logabs(15891.46*Cos(If(AIDS>15890.50,1.00,Total))))))\n",
      "Train Loss (Med): 0.82000 (0.56000)\n",
      "Val Loss (Med): 0.82000 (0.56000)\n",
      "Median Size (Max): 5 (21)\n",
      "Median complexity (Max): 176 (24424736)\n",
      "Time (s): 0.64722\n",
      "\n",
      "Generation 20/100 [///////////                                       ]\n",
      "Best model on Val:Logistic(Sum(-0.25,Cos(15889.85*Logabs(15891.46*Cos(If(AIDS>15890.50,1.00,Total))))))\n",
      "Train Loss (Med): 0.82000 (0.56000)\n",
      "Val Loss (Med): 0.82000 (0.56000)\n",
      "Median Size (Max): 5 (21)\n",
      "Median complexity (Max): 176 (24424736)\n",
      "Time (s): 0.67421\n",
      "\n",
      "Generation 21/100 [///////////                                       ]\n",
      "Best model on Val:Logistic(Sum(-0.25,Cos(15889.85*Logabs(15891.46*Cos(If(AIDS>15890.50,1.00,Total))))))\n",
      "Train Loss (Med): 0.82000 (0.56000)\n",
      "Val Loss (Med): 0.82000 (0.56000)\n",
      "Median Size (Max): 5 (21)\n",
      "Median complexity (Max): 176 (24424736)\n",
      "Time (s): 0.70172\n",
      "\n",
      "Generation 22/100 [////////////                                      ]\n",
      "Best model on Val:Logistic(Sum(-0.25,Cos(15889.85*Logabs(15891.46*Cos(If(AIDS>15890.50,1.00,Total))))))\n",
      "Train Loss (Med): 0.82000 (0.56000)\n",
      "Val Loss (Med): 0.82000 (0.56000)\n",
      "Median Size (Max): 5 (21)\n",
      "Median complexity (Max): 176 (24424736)\n",
      "Time (s): 0.72860\n",
      "\n",
      "Generation 23/100 [////////////                                      ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 0.75815\n",
      "\n",
      "Generation 24/100 [/////////////                                     ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 0.78237\n",
      "\n",
      "Generation 25/100 [/////////////                                     ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 0.81251\n",
      "\n",
      "Generation 26/100 [//////////////                                    ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 0.84055\n",
      "\n",
      "Generation 27/100 [//////////////                                    ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 0.86887\n",
      "\n",
      "Generation 28/100 [///////////////                                   ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 0.89418\n",
      "\n",
      "Generation 29/100 [///////////////                                   ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 0.92037\n",
      "\n",
      "Generation 30/100 [////////////////                                  ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 0.94615\n",
      "\n",
      "Generation 31/100 [////////////////                                  ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 0.97294\n",
      "\n",
      "Generation 32/100 [/////////////////                                 ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 0.99962\n",
      "\n",
      "Generation 33/100 [/////////////////                                 ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.02738\n",
      "\n",
      "Generation 34/100 [//////////////////                                ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.05278\n",
      "\n",
      "Generation 35/100 [//////////////////                                ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.08377\n",
      "\n",
      "Generation 36/100 [///////////////////                               ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.11236\n",
      "\n",
      "Generation 37/100 [///////////////////                               ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.14049\n",
      "\n",
      "Generation 38/100 [////////////////////                              ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.16807\n",
      "\n",
      "Generation 39/100 [////////////////////                              ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.19582\n",
      "\n",
      "Generation 40/100 [/////////////////////                             ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.22336\n",
      "\n",
      "Generation 41/100 [/////////////////////                             ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.25322\n",
      "\n",
      "Generation 42/100 [//////////////////////                            ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.28226\n",
      "\n",
      "Generation 43/100 [//////////////////////                            ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.31133\n",
      "\n",
      "Generation 44/100 [///////////////////////                           ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.33764\n",
      "\n",
      "Generation 45/100 [///////////////////////                           ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.36832\n",
      "\n",
      "Generation 46/100 [////////////////////////                          ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.39687\n",
      "\n",
      "Generation 47/100 [////////////////////////                          ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.42940\n",
      "\n",
      "Generation 48/100 [/////////////////////////                         ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.45752\n",
      "\n",
      "Generation 49/100 [/////////////////////////                         ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.48766\n",
      "\n",
      "Generation 50/100 [//////////////////////////                        ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.51614\n",
      "\n",
      "Generation 51/100 [//////////////////////////                        ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.54636\n",
      "\n",
      "Generation 52/100 [///////////////////////////                       ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.57235\n",
      "\n",
      "Generation 53/100 [///////////////////////////                       ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.60119\n",
      "\n",
      "Generation 54/100 [////////////////////////////                      ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.62778\n",
      "\n",
      "Generation 55/100 [////////////////////////////                      ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.65519\n",
      "\n",
      "Generation 56/100 [/////////////////////////////                     ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.68204\n",
      "\n",
      "Generation 57/100 [/////////////////////////////                     ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.71467\n",
      "\n",
      "Generation 58/100 [//////////////////////////////                    ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.74329\n",
      "\n",
      "Generation 59/100 [//////////////////////////////                    ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.77434\n",
      "\n",
      "Generation 60/100 [///////////////////////////////                   ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.80464\n",
      "\n",
      "Generation 61/100 [///////////////////////////////                   ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.83167\n",
      "\n",
      "Generation 62/100 [////////////////////////////////                  ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.85955\n",
      "\n",
      "Generation 63/100 [////////////////////////////////                  ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.89051\n",
      "\n",
      "Generation 64/100 [/////////////////////////////////                 ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.91921\n",
      "\n",
      "Generation 65/100 [/////////////////////////////////                 ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.94931\n",
      "\n",
      "Generation 66/100 [//////////////////////////////////                ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 1.97718\n",
      "\n",
      "Generation 67/100 [//////////////////////////////////                ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 2.00729\n",
      "\n",
      "Generation 68/100 [///////////////////////////////////               ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 2.03720\n",
      "\n",
      "Generation 69/100 [///////////////////////////////////               ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 2.06682\n",
      "\n",
      "Generation 70/100 [////////////////////////////////////              ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 2.09509\n",
      "\n",
      "Generation 71/100 [////////////////////////////////////              ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 2.12635\n",
      "\n",
      "Generation 72/100 [/////////////////////////////////////             ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 2.15420\n",
      "\n",
      "Generation 73/100 [/////////////////////////////////////             ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.68000)\n",
      "Val Loss (Med): 0.88000 (0.68000)\n",
      "Median Size (Max): 7 (13)\n",
      "Median complexity (Max): 992 (931232)\n",
      "Time (s): 2.18700\n",
      "\n",
      "Generation 74/100 [//////////////////////////////////////            ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.68000)\n",
      "Val Loss (Med): 0.88000 (0.68000)\n",
      "Median Size (Max): 7 (13)\n",
      "Median complexity (Max): 992 (931232)\n",
      "Time (s): 2.21621\n",
      "\n",
      "Generation 75/100 [//////////////////////////////////////            ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.68000)\n",
      "Val Loss (Med): 0.88000 (0.68000)\n",
      "Median Size (Max): 7 (13)\n",
      "Median complexity (Max): 992 (931232)\n",
      "Time (s): 2.25164\n",
      "\n",
      "Generation 76/100 [///////////////////////////////////////           ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.68000)\n",
      "Val Loss (Med): 0.88000 (0.68000)\n",
      "Median Size (Max): 7 (13)\n",
      "Median complexity (Max): 992 (931232)\n",
      "Time (s): 2.28261\n",
      "\n",
      "Generation 77/100 [///////////////////////////////////////           ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.68000)\n",
      "Val Loss (Med): 0.88000 (0.68000)\n",
      "Median Size (Max): 7 (13)\n",
      "Median complexity (Max): 992 (931232)\n",
      "Time (s): 2.31099\n",
      "\n",
      "Generation 78/100 [////////////////////////////////////////          ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.68000)\n",
      "Val Loss (Med): 0.88000 (0.68000)\n",
      "Median Size (Max): 7 (13)\n",
      "Median complexity (Max): 992 (931232)\n",
      "Time (s): 2.33836\n",
      "\n",
      "Generation 79/100 [////////////////////////////////////////          ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.68000)\n",
      "Val Loss (Med): 0.88000 (0.68000)\n",
      "Median Size (Max): 7 (13)\n",
      "Median complexity (Max): 992 (931232)\n",
      "Time (s): 2.36721\n",
      "\n",
      "Generation 80/100 [/////////////////////////////////////////         ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.68000)\n",
      "Val Loss (Med): 0.88000 (0.68000)\n",
      "Median Size (Max): 7 (13)\n",
      "Median complexity (Max): 992 (931232)\n",
      "Time (s): 2.39715\n",
      "\n",
      "Generation 81/100 [/////////////////////////////////////////         ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.68000)\n",
      "Val Loss (Med): 0.88000 (0.68000)\n",
      "Median Size (Max): 7 (13)\n",
      "Median complexity (Max): 992 (931232)\n",
      "Time (s): 2.42767\n",
      "\n",
      "Generation 82/100 [//////////////////////////////////////////        ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.68000)\n",
      "Val Loss (Med): 0.88000 (0.68000)\n",
      "Median Size (Max): 7 (13)\n",
      "Median complexity (Max): 992 (931232)\n",
      "Time (s): 2.45420\n",
      "\n",
      "Generation 83/100 [//////////////////////////////////////////        ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.56000)\n",
      "Val Loss (Med): 0.88000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 2.48424\n",
      "\n",
      "Generation 84/100 [///////////////////////////////////////////       ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.68000)\n",
      "Val Loss (Med): 0.88000 (0.68000)\n",
      "Median Size (Max): 7 (13)\n",
      "Median complexity (Max): 992 (931232)\n",
      "Time (s): 2.51400\n",
      "\n",
      "Generation 85/100 [///////////////////////////////////////////       ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.68000)\n",
      "Val Loss (Med): 0.88000 (0.68000)\n",
      "Median Size (Max): 7 (13)\n",
      "Median complexity (Max): 992 (931232)\n",
      "Time (s): 2.54317\n",
      "\n",
      "Generation 86/100 [////////////////////////////////////////////      ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.68000)\n",
      "Val Loss (Med): 0.88000 (0.68000)\n",
      "Median Size (Max): 7 (13)\n",
      "Median complexity (Max): 992 (931232)\n",
      "Time (s): 2.57084\n",
      "\n",
      "Generation 87/100 [////////////////////////////////////////////      ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.84000)\n",
      "Val Loss (Med): 0.88000 (0.84000)\n",
      "Median Size (Max): 11 (13)\n",
      "Median complexity (Max): 232736 (931232)\n",
      "Time (s): 2.59900\n",
      "\n",
      "Generation 88/100 [/////////////////////////////////////////////     ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.68000)\n",
      "Val Loss (Med): 0.88000 (0.68000)\n",
      "Median Size (Max): 7 (13)\n",
      "Median complexity (Max): 992 (931232)\n",
      "Time (s): 2.62827\n",
      "\n",
      "Generation 89/100 [/////////////////////////////////////////////     ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.68000)\n",
      "Val Loss (Med): 0.88000 (0.68000)\n",
      "Median Size (Max): 7 (13)\n",
      "Median complexity (Max): 992 (931232)\n",
      "Time (s): 2.66117\n",
      "\n",
      "Generation 90/100 [//////////////////////////////////////////////    ]\n",
      "Best model on Val:Logistic(Sum(-0.36,7.88*Cos(15888.04*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.88000 (0.68000)\n",
      "Val Loss (Med): 0.88000 (0.68000)\n",
      "Median Size (Max): 7 (13)\n",
      "Median complexity (Max): 992 (931232)\n",
      "Time (s): 2.68957\n",
      "\n",
      "Generation 91/100 [//////////////////////////////////////////////    ]\n",
      "Best model on Val:Logistic(Sum(-0.01,-2.90*Sin(15885.29*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.92000 (0.56000)\n",
      "Val Loss (Med): 0.92000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 2.72037\n",
      "\n",
      "Generation 92/100 [///////////////////////////////////////////////   ]\n",
      "Best model on Val:Logistic(Sum(-0.01,-2.90*Sin(15885.29*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.92000 (0.56000)\n",
      "Val Loss (Med): 0.92000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 2.74752\n",
      "\n",
      "Generation 93/100 [///////////////////////////////////////////////   ]\n",
      "Best model on Val:Logistic(Sum(-0.01,-2.90*Sin(15885.29*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.92000 (0.56000)\n",
      "Val Loss (Med): 0.92000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 2.77632\n",
      "\n",
      "Generation 94/100 [////////////////////////////////////////////////  ]\n",
      "Best model on Val:Logistic(Sum(-0.01,-2.90*Sin(15885.29*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.92000 (0.56000)\n",
      "Val Loss (Med): 0.92000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 2.80778\n",
      "\n",
      "Generation 95/100 [////////////////////////////////////////////////  ]\n",
      "Best model on Val:Logistic(Sum(-0.01,-2.90*Sin(15885.29*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.92000 (0.56000)\n",
      "Val Loss (Med): 0.92000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 2.83592\n",
      "\n",
      "Generation 96/100 [///////////////////////////////////////////////// ]\n",
      "Best model on Val:Logistic(Sum(-0.01,-2.90*Sin(15885.29*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.92000 (0.56000)\n",
      "Val Loss (Med): 0.92000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 2.86338\n",
      "\n",
      "Generation 97/100 [///////////////////////////////////////////////// ]\n",
      "Best model on Val:Logistic(Sum(-0.01,-2.90*Sin(15885.29*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.92000 (0.56000)\n",
      "Val Loss (Med): 0.92000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 2.89187\n",
      "\n",
      "Generation 98/100 [//////////////////////////////////////////////////]\n",
      "Best model on Val:Logistic(Sum(-0.01,-2.90*Sin(15885.29*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.92000 (0.56000)\n",
      "Val Loss (Med): 0.92000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 2.92152\n",
      "\n",
      "Generation 99/100 [//////////////////////////////////////////////////]\n",
      "Best model on Val:Logistic(Sum(-0.01,-2.90*Sin(15885.29*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.92000 (0.56000)\n",
      "Val Loss (Med): 0.92000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 2.95104\n",
      "\n",
      "Generation 100/100 [//////////////////////////////////////////////////]\n",
      "Best model on Val:Logistic(Sum(-0.01,-2.90*Sin(15885.29*Logabs(1.00*Total))))\n",
      "Train Loss (Med): 0.92000 (0.56000)\n",
      "Val Loss (Med): 0.92000 (0.56000)\n",
      "Median Size (Max): 5 (13)\n",
      "Median complexity (Max): 176 (931232)\n",
      "Time (s): 2.97776\n",
      "\n",
      "Best model: Logistic(Sum(-0.01,-2.90*Sin(15885.29*Logabs(1.00*Total))))\n",
      "score: 0.92\n"
     ]
    }
   ],
   "source": [
    "est = BrushClassifier(\n",
    "    # functions=['Logistic', 'OffsetSum', 'SplitBest','Add','Mul','Sin','Cos','Exp','Logabs'],\n",
    "    functions=['SplitBest','Add','Mul','Sin','Cos','Exp','Logabs'],\n",
    "    use_arch=True,\n",
    "    objectives=[\"scorer\", \"linear_complexity\"],\n",
    "    scorer='balanced_accuracy', # brush implements several metrics for clf and reg!\n",
    "    max_gens=100,\n",
    "    pop_size=100,\n",
    "    max_depth=10,\n",
    "    max_size=100,\n",
    "    verbosity=2,\n",
    ")\n",
    "\n",
    "est.fit(X, y)\n",
    "\n",
    "print(\"Best model:\", est.best_estimator_.get_model())\n",
    "print('score:', est.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see individuals from archive using the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fitness': {'complexity': 128,\n",
       "  'crowding_dist': 0.0,\n",
       "  'dcounter': 0,\n",
       "  'depth': 3,\n",
       "  'dominated': [],\n",
       "  'linear_complexity': 15,\n",
       "  'loss': 0.5,\n",
       "  'loss_v': 0.5,\n",
       "  'prev_complexity': 128,\n",
       "  'prev_depth': 3,\n",
       "  'prev_linear_complexity': 15,\n",
       "  'prev_loss': 0.5,\n",
       "  'prev_loss_v': 0.5,\n",
       "  'prev_size': 5,\n",
       "  'rank': 1,\n",
       "  'size': 5,\n",
       "  'values': [0.5, 15.0],\n",
       "  'weights': [1.0, -1.0],\n",
       "  'wvalues': [0.5, -15.0]},\n",
       " 'id': 221,\n",
       " 'is_fitted_': False,\n",
       " 'objectives': ['balanced_accuracy', 'linear_complexity'],\n",
       " 'parent_id': [212],\n",
       " 'program': {'Tree': [{'W': 1.0,\n",
       "    'arg_types': ['ArrayF'],\n",
       "    'center_op': True,\n",
       "    'feature': '',\n",
       "    'feature_type': 'ArrayF',\n",
       "    'fixed': True,\n",
       "    'is_weighted': False,\n",
       "    'name': 'Logistic',\n",
       "    'node_type': 'Logistic',\n",
       "    'prob_change': 0.0,\n",
       "    'ret_type': 'ArrayF',\n",
       "    'sig_dual_hash': 13056393536346412951,\n",
       "    'sig_hash': 14128685871577087634},\n",
       "   {'W': -0.791301429271698,\n",
       "    'arg_types': ['ArrayF'],\n",
       "    'center_op': True,\n",
       "    'feature': '',\n",
       "    'feature_type': 'ArrayF',\n",
       "    'fixed': True,\n",
       "    'is_weighted': True,\n",
       "    'name': 'OffsetSum',\n",
       "    'node_type': 'OffsetSum',\n",
       "    'prob_change': 0.0,\n",
       "    'ret_type': 'ArrayF',\n",
       "    'sig_dual_hash': 13056393536346412951,\n",
       "    'sig_hash': 14128685871577087634},\n",
       "   {'W': 0.7913016080856323,\n",
       "    'arg_types': [],\n",
       "    'center_op': True,\n",
       "    'feature': 'constF',\n",
       "    'feature_type': 'ArrayF',\n",
       "    'fixed': False,\n",
       "    'is_weighted': True,\n",
       "    'name': 'Constant',\n",
       "    'node_type': 'Constant',\n",
       "    'prob_change': 0.19857122004032135,\n",
       "    'ret_type': 'ArrayF',\n",
       "    'sig_dual_hash': 7018942542468397869,\n",
       "    'sig_hash': 14162902253047951597}],\n",
       "  'is_fitted_': True},\n",
       " 'variation': 'delete'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(est.archive_[0]))\n",
    "\n",
    "est.archive_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can call `predict` (or `predict_proba`, if your `est` is an instance of `BrushClassifier`) with the entire archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 221,\n",
       "  'y_pred': array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True])},\n",
       " {'id': 293,\n",
       "  'y_pred': array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         False,  True,  True,  True, False])},\n",
       " {'id': 248,\n",
       "  'y_pred': array([False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "          True, False,  True,  True,  True, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True,  True, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False])},\n",
       " {'id': 219,\n",
       "  'y_pred': array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          True,  True,  True,  True, False,  True, False,  True,  True,\n",
       "         False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "         False, False, False, False, False, False,  True, False, False,\n",
       "         False, False,  True, False,  True, False, False,  True, False,\n",
       "         False, False, False, False, False])},\n",
       " {'id': 211,\n",
       "  'y_pred': array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "          True,  True,  True,  True, False,  True, False,  True,  True,\n",
       "         False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True, False, False,  True, False,\n",
       "         False, False, False, False, False])},\n",
       " {'id': 264,\n",
       "  'y_pred': array([ True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "         False, False, False,  True, False, False,  True, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False])}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.predict_archive(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 221,\n",
       "  'y_pred': array([0.50000006, 0.50000006, 0.50000006, 0.50000006, 0.50000006,\n",
       "         0.50000006, 0.50000006, 0.50000006, 0.50000006, 0.50000006,\n",
       "         0.50000006, 0.50000006, 0.50000006, 0.50000006, 0.50000006,\n",
       "         0.50000006, 0.50000006, 0.50000006, 0.50000006, 0.50000006,\n",
       "         0.50000006, 0.50000006, 0.50000006, 0.50000006, 0.50000006,\n",
       "         0.50000006, 0.50000006, 0.50000006, 0.50000006, 0.50000006,\n",
       "         0.50000006, 0.50000006, 0.50000006, 0.50000006, 0.50000006,\n",
       "         0.50000006, 0.50000006, 0.50000006, 0.50000006, 0.50000006,\n",
       "         0.50000006, 0.50000006, 0.50000006, 0.50000006, 0.50000006,\n",
       "         0.50000006, 0.50000006, 0.50000006, 0.50000006, 0.50000006],\n",
       "        dtype=float32)},\n",
       " {'id': 293,\n",
       "  'y_pred': array([1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "         1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "         1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "         1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "         1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "         9.9257833e-01, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "         1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "         1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "         1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "         1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "         2.7566156e-07, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "         1.0000000e+00, 1.3724385e-08, 1.0000000e+00, 1.0000000e+00,\n",
       "         9.9994957e-01, 8.2106108e-04], dtype=float32)},\n",
       " {'id': 248,\n",
       "  'y_pred': array([0.40833503, 0.98202515, 0.9980563 , 0.92872834, 0.67898285,\n",
       "         0.4070141 , 0.9048409 , 0.976074  , 0.8018479 , 0.5646839 ,\n",
       "         0.3847002 , 0.7565754 , 0.84180486, 0.586586  , 0.45134684,\n",
       "         0.35905665, 0.37237877, 0.3807646 , 0.36907253, 0.36326355,\n",
       "         0.3588278 , 0.3657978 , 0.36631706, 0.36100444, 0.35924742,\n",
       "         0.36772263, 0.45368758, 0.46581194, 0.40029088, 0.39311057,\n",
       "         0.38719472, 0.60710347, 0.6725364 , 0.47429708, 0.40791455,\n",
       "         0.36778042, 0.4510595 , 0.46119544, 0.39615974, 0.37585256,\n",
       "         0.35844654, 0.3599154 , 0.36035466, 0.35964814, 0.35938093,\n",
       "         0.35838932, 0.35981992, 0.35980085, 0.35892314, 0.35859904],\n",
       "        dtype=float32)},\n",
       " {'id': 219,\n",
       "  'y_pred': array([0.6864201 , 0.62320006, 0.59923023, 0.56793886, 0.5824001 ,\n",
       "         0.5721623 , 0.71364987, 0.70274574, 0.41704366, 0.6941184 ,\n",
       "         0.5835392 , 0.70923126, 0.6972106 , 0.43207327, 0.6878464 ,\n",
       "         0.2699413 , 0.546583  , 0.57360303, 0.3045069 , 0.59427977,\n",
       "         0.68194443, 0.63278586, 0.609651  , 0.5713467 , 0.5897826 ,\n",
       "         0.29801217, 0.4025196 , 0.4356033 , 0.40474552, 0.45357585,\n",
       "         0.40078697, 0.3005697 , 0.31442082, 0.5511301 , 0.3249881 ,\n",
       "         0.39019045, 0.30818477, 0.32123098, 0.53915846, 0.3350185 ,\n",
       "         0.72893566, 0.42496505, 0.39604115, 0.7106083 , 0.38027793,\n",
       "         0.29813585, 0.395445  , 0.43163544, 0.40848818, 0.43824142],\n",
       "        dtype=float32)},\n",
       " {'id': 211,\n",
       "  'y_pred': array([9.99756992e-01, 9.21415389e-01, 7.50565529e-01, 9.86214936e-01,\n",
       "         5.94436049e-01, 9.84587669e-01, 9.99429643e-01, 9.98750210e-01,\n",
       "         1.39690459e-01, 9.97672498e-01, 9.88340616e-01, 9.99241948e-01,\n",
       "         9.98260319e-01, 2.06604719e-01, 9.97030616e-01, 5.14819149e-05,\n",
       "         9.56043661e-01, 9.83307600e-01, 8.66552728e-05, 9.92092907e-01,\n",
       "         9.99594748e-01, 9.69664693e-01, 9.08371747e-01, 9.76374924e-01,\n",
       "         8.08928192e-01, 6.39469072e-05, 1.20460846e-01, 2.89271295e-01,\n",
       "         2.04852759e-03, 4.56543356e-01, 2.27350392e-03, 5.16894157e-04,\n",
       "         1.27286999e-03, 3.90714079e-01, 2.55049020e-03, 1.75322441e-03,\n",
       "         8.02178401e-04, 1.84543116e-03, 3.16811889e-01, 3.78971826e-03,\n",
       "         9.99822438e-01, 6.18866598e-03, 2.16634548e-03, 9.99862075e-01,\n",
       "         1.22594810e-03, 7.88759353e-05, 3.99214551e-02, 1.80326357e-01,\n",
       "         4.39522974e-03, 2.23556280e-01], dtype=float32)},\n",
       " {'id': 264,\n",
       "  'y_pred': array([1.0000000e+00, 9.9988294e-01, 9.9999988e-01, 1.0000000e+00,\n",
       "         1.0000000e+00, 2.4966138e-09, 1.0000000e+00, 1.0000000e+00,\n",
       "         1.5822124e-15, 9.9979264e-01, 1.0000000e+00, 1.0000000e+00,\n",
       "         1.0000000e+00, 9.9988341e-01, 1.0000000e+00, 1.0000000e+00,\n",
       "         9.9999893e-01, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "         1.0000000e+00, 9.9982423e-01, 1.0000000e+00, 1.0000000e+00,\n",
       "         1.0000000e+00, 2.6599127e-17, 5.1820837e-04, 8.8313186e-08,\n",
       "         1.1011731e-12, 2.7481830e-16, 1.0000000e+00, 1.4913140e-16,\n",
       "         1.4125823e-14, 1.0000000e+00, 3.6946167e-05, 6.5860484e-13,\n",
       "         5.0766158e-12, 1.5568159e-14, 3.7854254e-05, 6.2157230e-18,\n",
       "         1.3829807e-16, 2.4564454e-06, 6.6555383e-10, 4.7116561e-11,\n",
       "         3.5990334e-17, 2.0255630e-17, 1.2753754e-04, 1.2954929e-07,\n",
       "         5.2649058e-13, 1.9475200e-16], dtype=float32)}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.predict_proba_archive(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a specific model from archive\n",
    "\n",
    "We have a static class method called `from_json` which let's you easily the string representation of the json from the archive to load an individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybrush import individual\n",
    "\n",
    "loaded_from_arch = individual.ClassifierIndividual.from_json(est.archive_[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic(Sum(-0.21,-39.49*Sin(15885.22*Logabs(1.00*Total))))\n",
      "Fitness(0.920000 50.000000 )\n"
     ]
    }
   ],
   "source": [
    "print(loaded_from_arch.get_model())\n",
    "print(loaded_from_arch.fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this loaded model to do predictions, you need to wrap the data into a Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pybrush import Dataset\n",
    "\n",
    "loaded_from_arch.predict(Dataset(X=X, ref_dataset=est.data_, \n",
    "                              feature_names=est.feature_names_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Pareto front of the archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Complexity (smaller is better)')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAGwCAYAAACJjDBkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPdlJREFUeJzt3Qd0VNXWwPENoYQaQAgQQCKdSK/SqyJYQCwgIkhVREAQAcUnzwJ2RBRBfSKgD+GjiL4HCoogiCC9RkF6JxCQEkog3G/tkzXzZpJJyFwySWbm/1srhFtm5tx7Z+bunLPPOdksy7IEAAAAXsnu3e4AAABQBFEAAAA2EEQBAADYQBAFAABgA0EUAACADQRRAAAANhBEAQAA2JDDzoOQNtevX5ejR49KgQIFJFu2bJldHAAAkAY6hOb58+clIiJCsmdPub6JIMqHNIAqU6ZMZhcDAADYcOjQISldunSK2wmifEhroBwXoWDBgpldHAAAkAbnzp0zlSCO+3hKCKJ8yNGEpwEUQRQAAP7lRqk4JJYDAADYQBAFAABgA0EUAACADQRRAAAANhBEAQAA2EAQBQAAYANBFAAAgA0EUQAAADYQRAEAANjAiOUAAMCvWJbI2bMi8fEiuXKJhIXp6OIZXw6CKAAA4DdOnhSJjhY5elTkyhWR3LlFIiJEoqJEihXL2LIQRAEAAL8JoFauTKyFCg8XCQ0VuXxZZO9ekdhYkWbNMjaQIicKAAD4RRNedHRiABUZKZIvn0hISOJvXdb1ul33yygEUQAAIMs7ezaxCU9roJLmP+myrtftul9GIYjygUmTJklUVJTUr18/s4sCAEBAiI9PzIHSJjxPdL1u1/0yCkGUDwwcOFCio6Nl3bp1mV0UAAACQq5ciUnkmgPlia7X7bpfRiGIAgAAWV5YWGIvvJiY5HlPuqzrdbvul1EIogAAQJaXLVviMAYaJO3fLxIXJ5KQkPhbl3W9bs/I8aIY4gAAAPiFYsUShzFwjBOlQx5oE165cowTBQAAkCoNlJo3Z8RyAAAAr2nAVKiQZDpyogAAAGwgiAIAALCBIAoAAMAGgigAAAAbCKIAAABsIIgCAACwgSAKAADABoIoAAAAGwiiAAAAbCCIAgAAsIEgCgAAwAaCKAAAABsIogAAAGwgiAIAALCBIAoAAMAGgigAAAAbCKIAAABsIIgCAACwgSAKAADABoIoAAAAGwiiAAAAbCCIAgAAsIEgCgAAwAaCKAAAABty2HkQAAAILJYlcvasSHy8SK5cImFhItmyZXapsjaCKAAAgtzJkyLR0SJHj4pcuSKSO7dIRIRIVJRIsWKZXbqsiyAKAIAgD6BWrkyshQoPFwkNFbl8WWTvXpHYWJFmzQikUkJOFAAAQdyEpzVQGkBFRorkyycSEpL4W5d1vW7X/ZAcQRQAAEFKgyRtwtMaqKT5T7qs63W77ofkCKIAAAhSmkSuOVDahOeJrtftuh+SI4gCACBIaS88TSLXHChPdL1u1/2QHEEUAABBSocx0F54MTHJ8550Wdfrdt0PyRFEAQAQpDTvSYcx0CBp/36RuDiRhITE37qs63U740V5xhAHAAAEMR2+QIcxcIwTpUMeaBNeuXKME3UjBFEAAAQ5DZSaN2fEcm8RRAEAABMwFSqU2aXwL+REAQAA2EAQBQAAYANBFAAAgA0EUQAAADYQRAEAANhAEAUAAGADQRQAAIANBFEAAAA2EEQBAADYQBAFAABgA0EUAACADQRRAAAANhBEAQAA2EAQBQAAYANBlBceeOABKVy4sDz00EOZXRQAAJDJCKK8MGTIEJkxY0ZmFwMAAGQBBFFeaNmypRQoUCCziwEAALKALBVEvfnmm5ItWzZ59tln0/V5V6xYIffdd59ERESY51+wYIHH/SZNmiSRkZESGhoqDRs2lLVr16ZrOQAAQODIMkHUunXr5JNPPpEaNWqkut+qVavk6tWrydZHR0fLiRMnPD4mLi5OatasaYKklMyePVuGDRsmY8aMkY0bN5r927VrJzExMTaOBgAABLosEURduHBBHnvsMfnss89M4nZKrl+/LgMHDpRu3bpJQkKCc/3OnTuldevWMn36dI+Pa9++vbz++usmMTwl48ePl379+kmvXr0kKipKpkyZInnz5pWpU6d6fTwarOlz1K9f3+vHAgAA/5AlgigNjO655x5p27Ztqvtlz55dFi1aJJs2bZIePXqYoGrPnj0mgOrUqZOMGDHC1uvHx8fLhg0b3F5fX0uXV69ebet4tGZMa9cAAEBgypHZBZg1a5ZpPktrwKF5TT///LM0a9bM1EhpkKPBzuTJk22X4dSpU6Zmq3jx4m7rdfnPP/90LuvrbNmyxTQPli5dWubMmSONGjWy/boAAMB/ZWoQdejQITNswI8//miSudPq1ltvlS+//FJatGgh5cqVk88//9wkjPvaTz/95PPXAAAA/iFTm/O0CU0Tt+vUqSM5cuQwP7/88otMnDjR/N8178mVJpD379/f9Li7ePGiDB069KbKUbRoUQkJCUmWmK7LJUqUuKnnBgAAgclWTdTBgwflwIEDJoApVqyY3H777ZI7d26vn6dNmzaybds2t3Wa2F2lShUZOXKkCWw8Nb3p46pWrWqa03bt2mXGb9LXf/fdd+0cjuTKlUvq1q0rS5cuNblVSvOtdPmZZ56x9ZwAACCwpTmI2r9/v8k70hymw4cPi2VZbkGI5ihp7dCDDz5okrLTQgeurFatmtu6fPnyyS233JJsvSOw0Z52ZcuWNUMSaG2V9oLT5kBNLi9VqpTHWint/bd7927n8r59+2Tz5s1SpEgR0zSodHiDnj17Sr169aRBgwYyYcIEk/ukQR0AAEBSaYp2Bg8ebMZN0uBDhwrQnmdnz541vdqOHz9uesw1bdpUXn75ZTPOk696pWlwNm7cOJk3b54J3By0bJqv9PDDD3t83Pr166V27drmxxEw6f+1vA5dunQxNVm6rlatWibI+uGHH5IlmwMAAKhslmuVUgpeeOEFGT58uKkhuhENPLSZr3PnzkF/hs+dOydhYWEm4CxYsGBmFwcAAKTj/TtNQVTSfKjw8HCvetMFK4IoAAAC9/7tVe88zUmqUKGCGZoAAADcmFZV/P23iM4ipr+9q7pAwPTO05ykihUrSmxsrPkNAABSdvKkzu0qcvSoyJUrItqRPSJCJCpKpFixzC4dMnycqDfffFOef/552b59+02/OAAAgRxArVwpsneviLYIlSmT+FuXdb1uh3/zOidKJwjWxPFr166ZHnJ58uRx23769On0LqPfIicKAIKT3llXrEgMmCIjRVwn1dBt+/eLlCsn0ry5+zb41/3b68E2dfwkAACQsrNnE5vwwsOTB0m6rOt1u+5XqFBmlRI3y+sgSgekBAAAKYuPT8yBSqkju67X5jzdD0E2d96ePXvkpZdekkcffdTMfae+//572bFjR3qXDwAAv6PjQWsS+eXLnrfret3uMm40giGI0gmCq1evLr///rvMnz/fTKmitmzZImPGjPFFGQEA8CthYYm98LSeIWnmsS7ret2u+yGIgqhRo0aZqV90vjrXqVd07ro1a9akd/kAAPA7mvekwxhokKRJ5HFxIgkJib91WdfrdpLKgywnatu2bTJz5sxk63UU81OnTqVXuQAA8Gs6DlSzZv8bJ0pzoLQJT3vlMU5UkAZRhQoVkmPHjsltt93mtn7Tpk1SqlSp9CwbAAB+TQMlHcZAe+FpErk24GgtFDVQQdqc17VrVxk5cqQcP35csmXLZqaCWbVqlZmguEePHr4pJQAAfkoDJh3GQIc10N8EUEEcRI0bN06qVKkiZcqUMUnlUVFR0rx5c2ncuLHpsQcAABAMvB6x3EEnIdb8KA2kateuzVx6HjBiOQAAgXv/9rom6tVXXzXTvmhNVIcOHeSRRx4xAdSlS5fMNgAAgGDgdU1USEiISSzX3niuYmNjzboE7cMJg5ooAAD8j89qojTm0oTypHSwzSJFinhfUgAAgEAe4qBw4cImeNKfSpUquQVSWvukuVFPPfWUr8oJAADgn0HUhAkTTC1U79695ZVXXjHVXA46cnlkZKQ0atTIV+UEAADwzyCqZ8+e5rcOstmkSRPJkcPrcToBAAAChtc5UTpH3unTp5Ot18RyTToHAAAIBrYSyz25cuWK24TEAAAAgSzNbXITJ040vzWh/F//+pfkz5/fLbF8xYoVZiRzAACAYJDmIOr999931kRNmTLFrenOkViu6wEAAIJBmoOoffv2md+tWrWS+fPnmyEPAAAAgpXXOVHLli0zAVR8fLzs3LlTrl275puSAQAABFIQpXPk9enTR/LmzSu33367HDx40KwfNGiQvPnmm74oIwAAgP8HUaNGjTJTvCxfvlxCQ0Od69u2bSuzZ89O7/IBAABkSV6PmLlgwQITLN1xxx1uU79ordSePXvSu3wAAACBURN18uRJCQ8PT7Y+Li7O48TEAAAAgcjrIKpevXqycOFC57IjcNKxo5g7DwAABAuvm/PGjRsn7du3l+joaNMz74MPPjD//+233+SXX37xTSkBAAD8vSaqadOmsnnzZhNAVa9eXZYsWWKa91avXi1169b1TSkBAACymGxWSpPh4aadO3dOwsLC5OzZs1KwYMHMLg4AAEjH+7fXzXmOufK++eYb+eOPP8xyVFSUdOzYUXLksPV0AAAAfsfrqGfHjh1y//33y/Hjx6Vy5cpm3VtvvSXFihWT//znP1KtWjVflBMAAMC/c6L69u1rxoQ6fPiwbNy40fwcOnRIatSoIf379/dNKQEAAPy9JkqTytevX+82AbH+f+zYsVK/fv30Lh8AAEBg1ERVqlRJTpw4kWx9TEyMVKhQIb3KBQAA4P9BlGapO37eeOMNGTx4sMydO9c06emP/v/ZZ581uVEAAADBIE1DHGTPnt1tShfHQxzrXJe15x4SMcQBAABBPsTBsmXL0rNsAAAAfi9NQVSLFi18XxIAAIBATiwHAAAAQRQAAIAtBFEAAAA2EEQBAABkRBB16dIluXjxonP5wIEDMmHCBFmyZImd1wcAAAiOIKpjx44yY8YM8/+///5bGjZsKO+9955ZP3nyZF+UEQAAwP+DKJ1wuFmzZub/OlJ58eLFTW2UBlYTJ070RRkBAAD8P4jSprwCBQqY/2sTXufOnc2I5nfccYcJpgAAAIKB10GUTjK8YMECOXTokCxevFjuuusu5wTETG0CAACChddB1MsvvyzDhw+XyMhIkw/VqFEjZ61U7dq1fVFGAAAA/5yAOKnjx4/LsWPHpGbNmqYpT61du9bURFWpUsUX5fRLTEAMAECQT0CcVIkSJcyPqwYNGth5KgAAAL+UpiBKk8enTZtmojH9f2rmz5+fXmUDAADw7yBKq7SyZcvm/D8AAECws5UThbQhJwoAgMC9fzN3HgAAgA0EUQAAADYQRAEAANhAEAUAAODrIOrq1avSpk0b+euvv+y8FgAAQHAGUTlz5pStW7f6rjQAAACB2pzXvXt3+fzzz31TGgAAAD/h9bQv165dk6lTp8pPP/0kdevWlXz58rltHz9+vASqBx54QJYvX26aNOfOnZvZxQEAAP4URG3fvl3q1Klj/r9r1y63bY5RzQPVkCFDpHfv3jJ9+vTMLgoAAPC3IGrZsmUSrFq2bGlqogAAAGwPcbB7925ZvHixXLp0ySzbnT1m8uTJUqNGDTOsuv40atRIvv/+e0lPK1askPvuu08iIiJMbdmCBQs87jdp0iSJjIyU0NBQadiwoaxduzZdywEAAII4iIqNjTU5QZUqVZIOHTrIsWPHzPo+ffrIc88953UBSpcuLW+++aZs2LBB1q9fL61bt5aOHTvKjh07PO6/atUqM9RCUtHR0XLixAmPj4mLi5OaNWuaICkls2fPlmHDhsmYMWNk48aNZv927dpJTEyM18cEAAACn9dB1NChQ81QBwcPHpS8efM613fp0kV++OEHrwugNUQajFWsWNEEZmPHjpX8+fPLmjVrku17/fp1GThwoHTr1k0SEhKc63fu3GmCr5Ryldq3by+vv/66SQxPiSbE9+vXT3r16iVRUVEyZcoUc3yaRO8tDdb0OerXr+/1YwEAQIAGUUuWLJG33nrL1CC50iDowIEDN1UYDYxmzZplao60WS9ZYbNnl0WLFsmmTZukR48eJqjas2ePCaA6deokI0aMsPW68fHxpiasbdu2bq+ly6tXr/b6+TTQ05qxdevW2SoPAAAIwMRyDXBca6AcTp8+Lblz57ZViG3btpmg6fLly6YW6ptvvjE1OZ5oXtPPP/8szZo1MzVSGuRosKO5VXadOnXKBHDFixd3W6/Lf/75p3NZX2fLli3mHGgQOWfOHI/BHgAACHxe10Rp8DJjxgznsiZqa43Q22+/La1atbJViMqVK8vmzZvl999/lwEDBkjPnj1NTU5Kbr31Vvnyyy9NHlOOHDnM4J8ZMbyCjo118uRJuXjxohw+fJgACgCAIOZ1TZQGS5pYrkng2gymTWiaBK41UZr0bUeuXLmkQoUK5v86gKc2g33wwQfyySefeNxfE8j79+9v8ql0X83T+vDDD8WuokWLSkhISLLEdF0uUaKE7ecFAACBy+uaqGrVqplBNps2bWp60WnTVufOnU2eUvny5dOlUFqzdeXKlRSb3jSIq1q1qsyfP1+WLl1qaqSGDx9u+/U0iNPgTZ/LtQy6TG0TAABIl5ooFRYWJqNHj5b08MILL5jec9pEd/78eZk5c6YZ0FLHoEpKAxvdt2zZss6mPM2d+vHHH01yealSpUytVFIXLlww41o57Nu3zzQfFilSxLyu0uENtBmxXr160qBBA5kwYYIJELW3HgAAgK0gauvWrZJWOnCmN3QcJu1pp+NNaXCmj9cA6s4770y2r/aYGzdunMnL0tojBx3TSfOVihUr5vE1tOnRNV9LAyalQdO0adOcQzRovtPLL78sx48fl1q1apkhG5ImmwMAAKhsVhqGGtfgRRO3b7Sr7uM6flOwO3funAkMz549a0ZjBwAAgXP/TlNNlDZ/AQAAwMsgSnOQAAAA4GUQ9d1330la3X///WneFwAAIKCDKJ1SJS3IiQIAAMEiTUGUDi0AAACAmxhsEwAAADYH29RBKH/55Rc5ePCgmfrF1eDBg9OrbAAAAIETROn0Lh06dDCT8GowpaN+61QsefPmlfDwcIIoAAAQFLxuztNpVXTi3zNnzkiePHlkzZo1cuDAATP33LvvvuubUgIAAPh7EKVzzj333HNmFPOQkBAzUXCZMmXk7bfflhdffNE3pQQAAPD3ICpnzpwmgFLafKd5UUqHRz906FD6lxAAACAQcqJq164t69atk4oVK0qLFi3MhL2aE/Xll19KtWrVfFNKAAAAf6+JGjdunJQsWdL8f+zYsVK4cGEZMGCAnDx5Uj799FNflBEAACDLyWZZlpXZhQj2WaABAID/3b8ZbBMAACAjcqJiY2NNHtSyZcskJiYm2ZQwp0+ftlMOAACAwA6iHn/8cdm9e7f06dNHihcvbiYdBgAACDZeB1ErV66UX3/9VWrWrOmbEgEAAPgBr3OiqlSpIpcuXfJNaQAAAAI1iPr4449l9OjRZgJizY/SDHbXHwAAgGDgdXNeoUKFTLDUunVrt/U6UoLmRyUkJKRn+QAAAAIjiHrsscfM1C8zZ84ksRwAAAQtr4Oo7du3y6ZNm6Ry5cq+KREAAEAg5kTVq1ePiYYBAEDQ87omatCgQTJkyBB5/vnnpXr16qZpz1WNGjXSs3wAAACBMXde9uzJK680L4rE8uSYOw8AgMC9f3tdE7Vv376bLRsAAIDf8zqIKlu2rG9KAgAAEMiJ5dOnT5eFCxc6l0eMGGHGjmrcuLEcOHAgvcsHAAAQGEHUuHHjJE+ePOb/q1evlo8++kjefvttKVq0qAwdOtQXZQQAAPD/5jwd3qBChQrm/wsWLJCHHnpI+vfvL02aNJGWLVv6oowAAAD+XxOVP39+M2eeWrJkidx5553m/6GhoUxMDAAAgobXNVEaNPXt21dq164tu3btkg4dOpj1O3bskMjISF+UEQAAwP9roiZNmiSNGjWSkydPyrx58+SWW24x6zds2CCPPvqoL8oIAADg/4NtIu0YbBMAgMC9f6epJurgwYNevfiRI0e82h8AAMDfpCmIql+/vjz55JOybt26FPfRaO2zzz6TatWqmWY+AAAACfbE8ujoaBk7dqxJKtdeeHXr1pWIiAjz/zNnzpjtmlhep04dM2aUI9kcAAAgUHmVE6VDGOho5b/++qsZnVyXdZBN7anXrl07UwuF/yEnCgCAwL1/k1juQwRRAAAEeWI5AAAA3BFEAQAA2EAQBQAAYANBFAAAQEYEUXFxcXZeBwAAILiDqOLFi0vv3r3NMAcAAADByusg6quvvpLTp09L69atpVKlSvLmm2/K0aNHfVM6AACAQAmiOnXqJAsWLDDz4z311FMyc+ZMKVu2rNx7770yf/58uXbtmm9KCgAAkIWky2CbH374oTz//PMSHx9vRjDX4GrUqFGSN29eCWYMtgkAQODev9M0d54nJ06ckOnTp8u0adPMFDAPPfSQ9OnTRw4fPixvvfWWrFmzRpYsWWL36QEAALI0r4MobbL74osvZPHixRIVFSVPP/20dO/eXQoVKuTcp3HjxlK1atX0LisAAID/BlG9evWSrl27yqpVq6R+/foe94mIiJDRo0enR/kAAAACIyfq4sWLQZ/rlFbkRAEA4H98NgFxgQIFJCYmJtn62NhYCQkJ8b6kAAAAfsjrICqliqsrV65Irly50qNMAAAAgZMTNXHiRPM7W7Zs8q9//Uvy58/v3JaQkCArVqyQKlWq+KaUAAAA/hpEvf/++86aqClTprg13WkNVGRkpFkPAAAQDNIcRO3bt8/8btWqlRnmoHDhwr4sFwAAQGANcbBs2TLflAQAACDQgqhhw4bJa6+9Jvny5TP/T8348ePTq2wAAAD+HURt2rRJrl696vx/SjTpHAAAIBikywTE8IzBNgEA8D8+G2zz5MmTKW7btm2bt08HAADgl7wOoqpXry4LFy5Mtv7dd9+VBg0apFe5AAAAAiuI0sTyBx98UAYMGCCXLl2SI0eOSJs2beTtt9+WmTNn+qaUAAAAgZATpcnljz/+uJnq5fTp09KwYUOZOnWqlChRwjel9FPkRAEA4H98lhOlKlSoINWqVZP9+/ebF+rSpQsBFAAACCpeB1GrVq2SGjVqyF9//SVbt26VyZMny6BBg0wgdebMGd+UEgAAwN+DqNatW5uAac2aNVK1alXp27evad47ePCgSToHAAAIBl5P+7JkyRJp0aKF27ry5cubGqqxY8emZ9kAAAACb7DN3bt3y549e6R58+aSJ08e0adhxHJ3JJYDAOB/fJZYHhsba4Y0qFSpknTo0EGOHTtm1vfp00eGDx9+c6UGAADwE14HUUOHDpWcOXOaHKi8efM612ue1Pfff5/e5QMAAAicnKjFixdL6dKl3dZXrFhRDhw4kJ5lAwCPNAnh7FmR+HiRXLlEwsJ0AvTMLhWAYON1EBUXF+dWA+Wgg27mzp07vcoFAB7p9J3R0SJHj4pcuSKiXzsRESJRUSLFimV26QAEE6+b85o1ayYzZsxwLmsy+fXr1820L61atUrv8gGAWwC1cqXI3r0imutZpkzib13W9anMjw4AmV8TpcGSJpavX79e4uPjZcSIEbJjxw5TE6XDHACAr5rwtAZKm/EiI//XfJcvX+Ly/v2J25s3p2kPQBatidLpXnbt2iVNmzaVjh07mua9zp07mwE3dbwoAPAFDZ60CS88PHmQpMu6XrfrfgCQJWuilI6dMHr06PQvDQCkQJPINQcqNNTzdl2vzXm6HwBkmSBK58hLK51XDwDSm/bC0yTyy5cTm/CS0vW6XfcDgCwTRNWqVcskkN9ocHPdJyEhIb3KBgBOOoyB9sLTJHLXnCilX00xMSLlyiXuBwBZJojat2+f70sCAKnQoEmHMYiNTUwi1xwobcLTGigNoDR40u0klQPIUkFU2bJlfV8SALgBHQeqWbP/jROlOVDahKc1UIwTBcAvEst37twpH374ofzxxx9muWrVqjJo0CCpXLlyepcPANxooKTDGDBiOQC/G+Jg3rx5ZpiDDRs2SM2aNc3Pxo0bzTrdBgC+pgFToUKJTXr6mwAKQGbIZt0oWzwJHQvqsccek1dffdVt/ZgxY+Srr76SPXv2pHcZ/da5c+fMcBBnz56VgjqsMgAACJj7t9c1UceOHZMePXokW9+9e3ezDQAAIBh4HUS1bNlSVuokVUn8+uuvZl49AACAYOB1Yvn9998vI0eONDlRd9xxh1m3Zs0amTNnjrzyyivy3Xffue0LAAAQiLzOicqePW2VVwy8SU4UAACBfP/2uibq+vXrN1s2AACA4MuJAgAAgM3BNtetWyfLli2TmJiYZDVT48ePT6+yAQAABE4QNW7cOHnppZfM6OTFixc3uU8Orv8HAAAIZF4HUR988IFMnTpVnnjiCd+UCAAAIBBzorR3XpMmTXxTGgAAgEANooYOHSqTJk3yTWkAAAACtTlv+PDhcs8995g59KKioiRnzpxu2+fPn5+e5QMAAAiMIGrw4MGmZ16rVq3klltuIZkcAAAEJa+DqOnTp8u8efNMbVSweeCBB2T58uXSpk0bmTt3bmYXBwAA+FNOVJEiRUxTXjAaMmSIzJgxI7OLAQAA/DGI+uc//yljxoyRixcvSrBp2bKlFChQILOLAQAA/DGImjhxonz//fdmoM3q1atLnTp13H689cYbb0j9+vVNcBIeHi6dOnWSnTt3SnpasWKF3HfffRIREWFyuBYsWOBxP+11GBkZKaGhodKwYUNZu3ZtupYDAAAEcU6UBjnp6ZdffpGBAweaQOratWvy4osvyl133SXR0dGSL1++ZPuvWrVKGjRokKxXoO6vie4a3CUVFxcnNWvWlN69e0vnzp09lmP27NkybNgwmTJligmgJkyYIO3atTMBnQZ3AAAArrJZlmVJFnLy5EkTtGhw1bx5c7dtOk+f1nZVrFhRZs2aJSEhIWa9BjotWrQwQdCIESNSfX6tifrmm2+SBYMaOGkg99FHHzlfq0yZMjJo0CAZNWqUcz9NLNd90pJYfu7cOQkLC5OzZ89KwYIFvToPAAAgc6T1/u11c57Dhg0b5KuvvjI/mzZtkvSiBXYksHsaLX3RokXm9Xr06GECnT179kjr1q1NUHSjACol8fHx5njatm3r9lq6vHr1aq+fT5sFdQwtDcoAAEBg8ro5LyYmRrp27WpqZAoVKmTW/f3332bcKK0dKlasmO3CaFD07LPPmmllqlWr5nEfzWv6+eefpVmzZtKtWzcT5GiwM3nyZNuve+rUKUlISEjWFKjLf/75p3NZX2fLli2mebB06dIyZ84cadSoUbLn0+ZJ/XFEsgAAIPB4XROlzVvnz5+XHTt2yOnTp83P9u3bTcCgA3HeDA089Lk0GEvNrbfeKl9++aXJY8qRI4d8/vnnGTLo508//WSaG7Vn4uHDhz0GUAAAIDh4HUT98MMP8vHHH0vVqlWd67TpSpuwtNeeXc8884z897//NaOhay1Pak6cOCH9+/c3Pe40oNH5/G5G0aJFTX6VPm/S1ylRosRNPTcAAAhM2e00uSXtGad0nW7zlua1awClyd7aTHfbbbfdsOlNRwzXIE7n6Vu6dKmpkdI5/ezKlSuX1K1b1zyXgx6LLlPbBAAA0iUnSpO4deTur7/+2uQnqSNHjpjaIA1u7DThzZw5U7799lszVtTx48fNes0lypMnj9u+Gti0b99eypYt62zK01qwH3/80ZSrVKlSHmulLly4ILt373Yu79u3TzZv3myS17VpUGnPvp49e0q9evXMEAo6xIHmPvXq1cvrYwIAAIHP6yEODh06JPfff7/JidIhABzrNBH8u+++u2FTXLICpJDL9MUXX8gTTzyRbL0GTJpUrgNiutIee5rU7un1NQleE9+T0qBp2rRpzmUduuCdd94xgVytWrXMwKI69IFdDHEAAID/Sev929Y4UfoQTbJ29FzTpjXX4QGQiCAKAAD/49MgCmlDEAUAgP9J98E2Nelb84/0iZPSF7n99ttl5cqV9ksMAADgR9IcRGmidb9+/TxGZBqtPfnkkzJ+/Pj0Lh8AAIB/B1E6Uvfdd9+d4nadNFinTgEAAAgGaQ6idOBJT+NDOehwAzqaNwAAQDBIcxClYzDplCwp2bp1q5QsWTK9ygUAABAYQVSHDh3kH//4h1y+fDnZtkuXLsmYMWPk3nvvTe/yAQAAZElpHuJAm/Pq1Klj5pjTaVoqV65s1utYUTpvXkJCgmzcuFGKFy/u6zL7DYY4AAAgcO/faZ72RYOj3377TQYMGCAvvPCCGXDTMeJ4u3btTCBFAAUAAIKFV3Pn6Zx1ixYtkjNnzpi56DSQqlixohQuXNh3JQQAAAiECYiVBk3169dP/9IAAAAEWmI5AAAA/ocgCgAAwAaCKAAAABsIogAAAGwgiAIAALCBIAoAAMAGgigAAAAbCKIAAABsIIgCAACwgSAKAADABoIoAAAAGwiiAAAAbCCIAgAAsIEgCgAAwAaCKAAAABsIogAAAGwgiAIAALCBIAoAAMAGgigAAAAbCKIAAABsIIgCAACwgSAKAADABoIoAAAAGwiiAAAAbCCIAgAAsIEgCgAAwAaCKAAAABsIogAAAGwgiAIAALCBIAoAAMAGgigAAAAbCKIAAABsIIgCAACwgSAKAADABoIoAAAAGwiiAAAAbCCIAgAAsIEgCgAAwIYcdh4EZCbLEjl7ViQ+XiRXLpGwMJFs2TK7VACAYEMQBb9y8qRIdLTI0aMiV66I5M4tEhEhEhUlUqxYZpcOABBMCKLgVwHUypWJtVDh4SKhoSKXL4vs3SsSGyvSrBmBFAAg45ATBb9pwtMaKA2gIiNF8uUTCQlJ/K3Lul63634AAGQEgij4BQ2StAlPa6CS5j/psq7X7bofAAAZgSAKfkGTyDUHSpvwPNH1ul33AwAgIxBEwS9oLzxNItccKE90vW7X/QAAyAgEUfALOoyB9sKLiUme96TLul63634AAGQEgij4Bc170mEMNEjav18kLk4kISHxty7ret3OeFEAgIzCEAfwGzp8gQ5j4BgnSoc80Ca8cuUYJwoAkPEIouBXNFBq3pwRywEAmY8gCn5HA6ZChTK7FACAYEdOFAAAgA0EUQAAADYQRAEAANhAEAUAAGADQRQAAIANBFEAAAA2MMSBH9JpThgnCQCAzEUQ5Wd0lG7HiN1XriSO2K1zxjFiNwAAGYsgys8CqJUrE2uhwsNFQkNFLl8W2btXJDY2cUoUAikAADIGOVF+1ISnNVAaQEVGiuTLJxISkvhbl3W9btf9AACA7xFE+QkNkrQJT2ugkuY/6bKu1+26HwAA8D2CKD+hSeSaA6VNeJ7oet2u+wEAAN8jiPIT2gtPk8g1B8oTXa/bdT8AAOB7BFF+Qocx0F54MTHJ8550Wdfrdt0PAAD4HkGUn9C8Jx3GQIOk/ftF4uJEEhISf+uyrtftjBcFAEDGYIgDP6LDF+gwBo5xonTIA23CK1eOcaIAAMhoBFF+RgOl5s0ZsRwAgMxGEOWHNGAqVCizSwEAQHAjJwoAAMAGgigAAAAbCKIAAABsIIgCAACwgSAKAADABoIoAAAAGwiiAAAAbCCIAgAAsIEgCgAAwAZGLPchy7LM73PnzmV2UQAAQBo57tuO+3hKCKJ86Pz58+Z3mTJlMrsoAADAxn08TCeoTUE260ZhFmy7fv26HD16VAoUKCDZ0nmGYI2SNTg7dOiQFCxYMF2fG+mLa+U/uFb+hevlP8752bXS0EgDqIiICMmePeXMJ2qifEhPfOnSpX36Gvpm9Ic3JLhW/oRr5V+4Xv6joB9dq9RqoBxILAcAALCBIAoAAMAGgig/lTt3bhkzZoz5jayNa+U/uFb+hevlP3IH6LUisRwAAMAGaqIAAABsIIgCAACwgSAKAADABoIoAAAAGwiisqhJkyZJZGSkhIaGSsOGDWXt2rUp7jtt2jQzIrrrjz4OWfN6qb///lsGDhwoJUuWNL1VKlWqJIsWLcqw8gYzb65Vy5Ytk3229Oeee+7J0DIHK28/VxMmTJDKlStLnjx5zOjYQ4cOlcuXL2dYeYPdJC+u19WrV+XVV1+V8uXLm/1r1qwpP/zwg/gd7Z2HrGXWrFlWrly5rKlTp1o7duyw+vXrZxUqVMg6ceKEx/2/+OILq2DBgtaxY8ecP8ePH8/wcgcrb6/XlStXrHr16lkdOnSwfv31V2vfvn3W8uXLrc2bN2d42YONt9cqNjbW7XO1fft2KyQkxHzmkLWu1b///W8rd+7c5rd+phYvXmyVLFnSGjp0aIaXPRjN8vJ6jRgxwoqIiLAWLlxo7dmzx/r444+t0NBQa+PGjZY/IYjKgho0aGANHDjQuZyQkGDebG+88YbH/fULPSwsLANLiJu5XpMnT7bKlStnxcfHZ2ApYedaJfX+++9bBQoUsC5cuODDUsLOtdJ9W7du7bZu2LBhVpMmTXxeVlheXy8NcD/66CO3dZ07d7Yee+wxy5/QnJfFxMfHy4YNG6Rt27Zuc/Dp8urVq1N83IULF6Rs2bKmCrtjx46yY8eODCpxcLNzvb777jtp1KiRac4rXry4VKtWTcaNGycJCQkZWPLgY/ez5erzzz+Xrl27Sr58+XxYUti5Vo0bNzaPcTQh7d271zSRd+jQIcPKHazibVyvK1euJEs70WbYX3/9VfwJQVQWc+rUKXMz1ZurK10+fvy4x8doDsDUqVPl22+/la+++kquX79uvlAOHz6cQaUOXnaul365z5071zxOv+T/8Y9/yHvvvSevv/56BpU6ONm5Vq705rx9+3bp27evD0sJu9eqW7duJsemadOmkjNnTpNrozltL774YgaVOnidsnG92rVrJ+PHj5e//vrL3LN+/PFHmT9/vhw7dkz8CUFUANBajR49ekitWrWkRYsW5o1YrFgx+eSTTzK7aPBAvzDCw8Pl008/lbp160qXLl1k9OjRMmXKlMwuGm5QC1W9enVp0KBBZhcFHixfvtzU6H788ceyceNG8z24cOFCee211zK7aPDggw8+kIoVK0qVKlUkV65c8swzz0ivXr1MDZY/yZHZBYC7okWLSkhIiJw4ccJtvS6XKFEiTc+hf4XVrl1bdu/e7aNS4maul/bI02ukj3OoWrWq+YtNq8X1CwVZ67MVFxcns2bNMjUdyJrXSmt0H3/8cWdNoQa8et369+9v/kjxt5tzoF+vYsWKyYIFC0zvydjYWImIiJBRo0ZJuXLlxJ/wrspi9AaqtRNLly51q7nQZa1xSgutVt22bZu5WSPrXa8mTZqYAFf3c9i1a5e5XgRQWfOzNWfOHJPD0b179wwoKexcq4sXLyYLlBx/qDBFbNb9bIWGhkqpUqXk2rVrMm/ePJPT61cyO7MdnruKalfdadOmWdHR0Vb//v1NV1HHsAWPP/64NWrUKOf+r7zyiunOq91EN2zYYHXt2tV0FdVupsh61+vgwYOmh9czzzxj7dy50/rvf/9rhYeHW6+//nomHkVw8PZaOTRt2tTq0qVLJpQ4eHl7rcaMGWM+V19//bW1d+9ea8mSJVb58uWtRx55JBOPInjM8vJ6rVmzxpo3b565b61YscL0rLztttusM2fOWP6E5rwsSHNkTp48KS+//LJp4tFcJx2EzJG0d/DgQbe/uM6cOSP9+vUz+xYuXNj8RfDbb79JVFRUJh5F8PD2emkPysWLF5uBAGvUqGH+ChsyZIiMHDkyE48iOHh7rdTOnTtNj6ElS5ZkUqmDk7fX6qWXXjIDoervI0eOmOai++67T8aOHZuJRxE8unh5vbQZT6+VdrTJnz+/6UX55ZdfSqFChcSfZNNIKrMLAQAA4G/IiQIAALCBIAoAAMAGgigAAAAbCKIAAABsIIgCAACwgSAKAADABoIoAAAAGwiiAAAAbCCIAoLEE088IZ06dXIut2zZUp599tlUHxMZGSkTJky46ddOr+fJ6ufUk+XLl5uRtP/++2+fl0cncg0PD5f9+/dLMEjL+c8K1+Vm6cS8gwYNyuxiwAOCKEiwf5kGq/nz58trr72Wrs85bdo0j9M2rFu3Tvr37y/+SoMSveFu3rzZbf0HH3xgjjm1wLRx48Zy7NgxCQsL83k5dYoTncBVg9asIC2B+s1Iev4zg6c/EFL6HNg1fPhwmT59upkiBVkLQRQQpIoUKSIFChTIkNfSeczy5s0r/ig+Pj7FbRoY3ehmqTPclyhRwgRhvnTx4kX5/PPPpU+fPjf1PAkJCXL9+nXxh2uQlvPvzxzXomjRotKuXTuZPHlyZhcJSRBEISj88ssv0qBBA8mdO7eULFnSVI9fu3bNuX3u3LlSvXp1yZMnj9xyyy3Stm1biYuLc1b762Pz5ctnvrCbNGkiBw4cSPG1tm3bJq1bt3Y+l9bAXLhwIVmt2bvvvmvKovsMHDhQrl696vH5du3aZW7Af/75p9v6999/X8qXL+/8stWb52233WZet3LlyuavdG9qCWJiYsyErfp4fZ5///vfyR4zfvx4c570XOhEyk8//bTz2PQ89erVS86ePWvKqz///Oc/Pf61rpORao2JTjxasGBBeeSRR+TEiRPO7fo4ncBUJyTVx+rNsmvXrnL+/PkUj8fx1/+CBQukYsWKEhoaam48hw4dcu6zZ88e87o6Kaq+dv369eWnn35yex59Pa2h69GjhymbXj89H6p27drmuPTcJa0B1f/r+0zPu+P4tQbLU7PRvHnz5PbbbzfvR3299957L1kZxo0bJ7179zaB7q233iqffvppqtdz0aJF5vnuuOMOt/Xfffed83y0atXK1Gi4lsdx3nQ/nbRcn0Ovz5UrV0wNiE6Qrde7YcOG5lhcmw4fffRRs10DZH1ffP31187tKZ0PtX37dmnfvr25BnotHn/8cTl16pTzsXp+n3nmGfP+dAQQaamBTu1znJJVq1aZicD1/Oi507K50smnmzVrZp5T3/ODBw92PqeWU78LdDJxxzGm9jm40TlN6Voo/WzOmjUr1WNBJtAJiAF/17NnT6tjx44etx0+fNjKmzev9fTTT1t//PGH9c0331hFixa1xowZY7YfPXrUypEjhzV+/Hhr37591tatW61JkyZZ58+ft65evWqFhYVZw4cPt3bv3m1FR0db06ZNsw4cOODxtS5cuGCVLFnS6ty5s7Vt2zZr6dKl1m233WbK51rWggULWk899ZQpz3/+8x9Tvk8//TTF46tXr5710ksvua2rW7euc118fLz18ssvW+vWrbP27t1rffXVV+Y5Z8+eneI5atGihTVkyBDncvv27a2aNWtaq1evttavX281btzYypMnj/X+++8799H///zzz+Y86bFVrlzZGjBggNl25coVa8KECebYjh07Zn70HKqyZcs6nychIcGqVauW1bRpU/M6a9asMcei5XHQa5M/f37neVyxYoVVokQJ68UXX0zxHH3xxRdWzpw5zbn67bffzHM3aNDAHIfD5s2brSlTppjn3LVrlzl/oaGhbtdTy6rH8O6775prrj9r167Vidqtn376yRxXbGxssnP6999/W40aNbL69evnPP5r165Zy5YtM489c+aM2U/LlT17duvVV1+1du7cacqt51l/u5ahSJEi5n34119/WW+88YZ5zJ9//pni8Q8ePNi6++673dbpe0HPib5/9bFff/21VapUKbfyOM6bnqdVq1aZ/eLi4qy+ffuadXru9Ry88847Vu7cuc15c3yudN2mTZusPXv2WBMnTrRCQkKs33//PdXzoa9brFgx64UXXjDv/40bN1p33nmn1apVK7f3pl7/559/3pQnpeN2Pf+pfY49cVyXqlWrWkuWLDH733vvvVZkZKT5PCk97nz58pn3rh63np/atWtbTzzxhNmu74PSpUuba+k4xtQ+Bzc6pyldC6XnSsurx4asgyAKAR9E6Y1Xb/bXr193rtMvV/2S1hv6hg0bzJfT/v37kz1WvyR12/Lly9NUDg2EChcubIIph4ULF5ob4PHjx51l1Zuk3lAcHn74YatLly4pPq9+iZcvX965rDdfLZd+saZk4MCB1oMPPpimIMrxfBosODi+tF2DqKTmzJlj3XLLLc5lvQlo0JmUaxClNyy92R48eNC5fceOHW6vr0GUBoHnzp1z7qM31IYNG6ZYFn1tfQ4NypIeg+PG7sntt99uffjhh25l7dSpk9s+euPS59GAwdWNAlOVNIjq1q2bCRpc6bFFRUW5laF79+7OZX3vhoeHW5MnT07xOLQcvXv3dls3cuRIq1q1am7rRo8enSyI0mUNMB00qNRrdOTIEbfHtmnTxgQ/Kbnnnnus5557LtXz8dprr1l33XWX27pDhw6ZMuj70PE4DVZuxPX8p/Y59sRxXWbNmuX2edeA1vHHR58+faz+/fu7PW7lypXm83zp0qVk7+3UPgdpOaeeroXD2bNnvfouQsagOQ8B748//pBGjRq55aRok5w2Qx0+fFhq1qwpbdq0Mc0ADz/8sHz22Wdy5swZZ96QNhloc4JWp2vThCYJp/Za+nxaVe/6WprXsHPnTuc6bcoJCQlxLmuznjanpUSbsrQpZM2aNWZZm9rq1KkjVapUce4zadIkqVu3rsk/0mYSbf5xNAWk5RzlyJHDPN5Bnztpvok2fem50uYIbWbSZhht1tF8nLTS19JmEf1x0KYLfS3d5tqk5ZqzdaNzpPQYtIku6TE4nlevuTanVK1a1azX86Tbkp6nevXqia/o6+l7wpUu//XXX6ZZ1kGbmBz0vat5Vakd/6VLl0yTlCt9z7meD6VN057ytlxfT5uktSyVKlUy58jxo81z2iSqdLs2e+rnRj8nun3x4sU3fM9t2bJFli1b5va8jvex47mV63sxLVL7HKdGvxsc9Di0KdzxftGyahOba1n1u0A/z/v27fOqfGk5p56uhYM2JypvPmvwvRwZ8BpAlqbBzI8//ii//fabLFmyRD788EMZPXq0/P777yYX5osvvjB5ED/88IPMnj1bXnrpJbN/0twTb+TMmdNtWW+SqSXz6g1U86xmzpxpXld/DxgwwLldcyU0ONDcGr0paPDxzjvvmGNILxrE3XvvveZ1tReY3nA0X0RzsTTxN70Tx709R2mh50ivneajVahQwdyYHnrooWSJy65BcGbx9vg1dygtQYMneh5c/8jQYFM/Fxs2bHAL9pXe+JW+v/SPCs11c+TJaQ5Taon4jufWP0jeeuutZNs0ULZ7DW70ObZDy/rkk0+az39Smqfm7XPd6Jx6uhYOp0+fNr/1jyRkHdREIeBprcPq1au16dotmVQDjdKlS5tl/dLS2oBXXnlFNm3aZP4a/Oabb5z7a0LxCy+8YL6gq1WrZoKYlF5L/3p1TWbV18qePbv5C/dmPPbYYyaI02PRrs5aO+X6GtqVXhO9tawaILj+dXsjWhOgifb6Be9ai+GaDK3b9CaugZoGcvoX9dGjR92eR8+ba21KSudIk71dE76jo6PNa2mN1M3QY1i/fn2yY9DXdJwnrVl84IEHzI1fg9O0jKmkx6VudGxpPX4thytd1vOZ9ObqDb3ueh5d6XvO9Xw4hptIy3PpcWjNl76XXH/0nDnKrEn63bt3N7VA5cqVM50gbnQ+tAZ1x44dpqYx6XPfbPB6o8+xJ47aXaVBqB6D4/2iZdVzmrSc+uN4T3g6Rk/r0nJOU6MJ7xpYay02sg6CKAQM7Q2j4/i4/uiNWgML/a2D1WkPt2+//VbGjBkjw4YNM8GN/qWqPaH0ZqNNETp+0smTJ80XqVbZa/CkgYv2wtG/cLXZxfEl6ynQ0SaVnj17mi89bbbQ19VmL+2FdDM6d+5seqdpTZD2soqIiHBu095XWn5tTtGbwD/+8Y803Sxdb7Z33323+atbz4cGTH379nU2ISj9stcehPoXvgZx2nNuypQpbs+jN0b9i3vp0qWmt5WnpgftMaUBjJ6rjRs3ytq1a01PuBYtWtx0M5reZPR8O45BAyYN+BxNWHqe9Prqe0OD3W7duqWpdksHsNRzobWR2otQ32ue6PHra2tgpsfv6bmfe+45c360KUyvlfaW++ijj0wt2c3QZiYNTlxro/R66nt+5MiR5rX+7//+zzmuUmpDLmhAp9dHr4ueL/0c6HV64403ZOHChc5z6aj50eYvfS3XHpYpnQ/tiaq1KtqzT9+jGuzr+1Z7tN0oAE1Nap/j1Lz66qvmeujnVd8vWqPn6PGn502PT3sK6ntGP/v6/aHLrse4YsUKOXLkiLOHoafPQVrOaWpWrlzp7CWILCSDcq8An9IEU307J/3RxFClyZj169e3cuXKZXp5acKt9rxT2uOuXbt2pseQ9pSpVKmSM9FYk8E1yVh73OljNYlUe8FpQnpKtJeP9jTSXl/aw0p7J7n2EPKUBK/Jt66901LyyCOPmOOaOnWq2/rLly+bHkOazFqoUCHTY27UqFGmt11Kr5s06Vd7EWlisJ6DW2+91ZoxY0aypFnt+aTnQpNv9ZzpPq5Jykp7HWqyua539IBM+jyaZHv//febnk8FChQwifWOxHulj3Mtu9LH6/OkxJHMO2/ePKtcuXLmONq2bevW804TxPXaaPnLlCljffTRR8nOg6dEYfXZZ5+Zx2hSseNaJT2nmhh9xx13mOd39KRKmliu5s6daxLJtSeWnmvtpeXKUxn0fDjOZ0q0N6L2PnT17bffWhUqVDDno2XLliY5XcvjSIxOqTOAo8en9lbTcup1f+CBB8z725GErceuHTQ06V17Ovbo0eOG50NpbzR9Ln2v6rYqVapYzz77rLPzh6eEdE9cz39qn2NPHNdFe8dq5wL9fOv527Jli9t+2tlBOwLocer7tUaNGtbYsWOd27U3q67T13S9pXr6HNzonKZ0LZR2jtHelchasuk/mR3IAcDN0hoWzcnxh2k8fEVrNJ5//nlTq6K1rJ5oPpvWILo2pyJr+/77700N5tatW03nCWQdXA0ACBD33HOPaXLSpiVH78ePP/7Y9NDTwSc1j0kTwl2bo5D1aY6ldnAhgMp6uCIAEECSzlWnQdXrr79u8pC0R5nWaGieH/yH9iBF1kRzHgAAgA30zgMAALCBIAoAAMAGgigAAAAbCKIAAABsIIgCAACwgSAKAADABoIoAAAAGwiiAAAAxHv/D1nQ8BPMTCreAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xs, ys = [], []\n",
    "for ind in est.archive_:\n",
    "    # We should look at the same objectives to get a valid pareto front\n",
    "    xs.append(ind['fitness']['loss'])\n",
    "    ys.append(ind['fitness']['linear_complexity'])\n",
    "\n",
    "print(len(xs))\n",
    "plt.scatter(xs, ys, alpha=0.25, c='b', linewidth=1.0)\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Loss on validation partition (greater is better)\")\n",
    "plt.ylabel(\"Complexity (smaller is better)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the population (unique individuals)\n",
    "\n",
    "If not using archive, then the unique individuals from the final population will be stored. Notice that, while the archive contains only the Pareto front (when `use_arch=True`), this will contain all individuals, even dominated ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100% [====================]\n",
      "Best model: Logistic(Sum(7.07,-8.07*Cos(Mean(0.02*Max(-173.56*Sin(6.31*AIDS),Abs(0.01*AIDS),35.87,-183.85*Cos(0.04*Max(28.76,1.00,-19.92,-134.24*Sin(6.31*AIDS)))),-0.83))))\n",
      "score: 0.8\n"
     ]
    }
   ],
   "source": [
    "est = BrushClassifier(\n",
    "    # functions=['SplitBest','Add','Mul','Sin','Cos','Exp','Logabs'],\n",
    "    use_arch=True,\n",
    "    objectives=[\"scorer\", \"linear_complexity\"],\n",
    "    max_depth=10,\n",
    "    max_size=100,\n",
    "    max_gens=100,\n",
    "    pop_size=200,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "est.fit(X,y)\n",
    "\n",
    "print(\"Best model:\", est.best_estimator_.get_model())\n",
    "print('score:', est.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Complexity (smaller is better)')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs, ys = [], []\n",
    "for ind in est.archive_:\n",
    "    # use the same as the objectives\n",
    "    xs.append(ind['fitness']['loss'])\n",
    "    ys.append(ind['fitness']['linear_complexity'])\n",
    "\n",
    "print(len(xs))\n",
    "plt.scatter(xs, ys, alpha=0.25, c='b', linewidth=1.0)\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Loss on validation partition (smaller is better)\")\n",
    "plt.ylabel(\"Complexity (smaller is better)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brush",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
