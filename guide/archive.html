

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>The archive &mdash; Brush 0.1.dev1+ga5affc5fe documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />

  
    <link rel="shortcut icon" href="../_static/paint-brush-solid.svg"/>
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=f69ed792"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Using Deap" href="deap.html" />
    <link rel="prev" title="Saving and loading populations" href="saving_loading_populations.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Brush
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics.html">Basic Usage</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Cookbook</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="data.html">Working with Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="search_space.html">The Search Space</a></li>
<li class="toctree-l2"><a class="reference internal" href="working_with_programs.html">Working with Programs</a></li>
<li class="toctree-l2"><a class="reference internal" href="json.html">JSON Interoperability</a></li>
<li class="toctree-l2"><a class="reference internal" href="saving_loading_populations.html">Saving and loading populations</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">The archive</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#loading-a-specific-model-from-archive">Loading a specific model from archive</a></li>
<li class="toctree-l3"><a class="reference internal" href="#visualizing-the-pareto-front-of-the-archive">Visualizing the Pareto front of the archive</a></li>
<li class="toctree-l3"><a class="reference internal" href="#storing-the-population-unique-individuals">Storing the population (unique individuals)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="deap.html">Using Deap</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="development.html">Development</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpp_api/index.html">C++ API</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Brush</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Cookbook</a></li>
      <li class="breadcrumb-item active">The archive</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/guide/archive.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="the-archive">
<h1>The archive<a class="headerlink" href="#the-archive" title="Link to this heading">ÔÉÅ</a></h1>
<p>When you fit a brush estimator, two new attributes are created: <code class="docutils literal notranslate"><span class="pre">best_estimator_</span></code> and <code class="docutils literal notranslate"><span class="pre">archive_</span></code>.</p>
<p>If you set <code class="docutils literal notranslate"><span class="pre">use_arch</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code> when instantiating the estimator, then it will store the pareto front as a list in <code class="docutils literal notranslate"><span class="pre">archive_</span></code>. This pareto front is always created with individuals from the final population that are not dominated in objectives <strong>scorer</strong> and <strong>complexity</strong>. Setting <code class="docutils literal notranslate"><span class="pre">scorer</span></code> as an objective means optimizing the metric set as <code class="docutils literal notranslate"><span class="pre">scorer:</span> <span class="pre">str</span></code>.</p>
<p>In case you need more flexibility, the archive will contain the entire final population if <code class="docutils literal notranslate"><span class="pre">use_arch</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, and you can iterate through this list to select individuals with different criteria. It is also good to remind that Brush supports different optimization objectives using the argument <code class="docutils literal notranslate"><span class="pre">objectives</span></code>.</p>
<p>Each element from the archive is a serialized individual (JSON object).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pybrush</span><span class="w"> </span><span class="kn">import</span> <span class="n">BrushClassifier</span>

<span class="c1"># load data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../examples/datasets/d_analcatdata_aids.csv&#39;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">est</span> <span class="o">=</span> <span class="n">BrushClassifier</span><span class="p">(</span>
    <span class="c1"># functions=[&#39;Logistic&#39;, &#39;OffsetSum&#39;, &#39;SplitBest&#39;,&#39;Add&#39;,&#39;Mul&#39;,&#39;Sin&#39;,&#39;Cos&#39;,&#39;Exp&#39;,&#39;Logabs&#39;],</span>
    <span class="n">functions</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;SplitBest&#39;</span><span class="p">,</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;Mul&#39;</span><span class="p">,</span><span class="s1">&#39;Sin&#39;</span><span class="p">,</span><span class="s1">&#39;Cos&#39;</span><span class="p">,</span><span class="s1">&#39;Exp&#39;</span><span class="p">,</span><span class="s1">&#39;Logabs&#39;</span><span class="p">],</span>
    <span class="n">use_arch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">objectives</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;scorer&quot;</span><span class="p">,</span> <span class="s2">&quot;linear_complexity&quot;</span><span class="p">],</span>
    <span class="n">scorer</span><span class="o">=</span><span class="s1">&#39;balanced_accuracy&#39;</span><span class="p">,</span> <span class="c1"># brush implements several metrics for clf and reg!</span>
    <span class="n">max_gens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">pop_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">max_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">verbosity</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best model:&quot;</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">get_model</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;score:&#39;</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Generation 1/100 [/                                                 ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;15890.50,1.00*Exp(1.00*Logabs(1.00*Add(1.00*Add(AIDS,AIDS),AIDS))),1.00*Mul(AIDS,1.00*Cos(If(Total&gt;1572255.50,1.00*Exp(1.00*Cos(1.00*Cos(1.00*Mul(AIDS,AIDS)))),1.00*Logabs(1.00*Sin(AIDS))))))))
Train Loss (Med): 0.74000 (0.50000)
Val Loss (Med): 0.74000 (0.50000)
Median Size (Max): 7 (73)
Median complexity (Max): 992 (1780983200)
Time (s): 0.18365

Generation 2/100 [//                                                ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,If(AIDS&gt;18390.00,12.99,AIDS),1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.50000)
Val Loss (Med): 0.76000 (0.50000)
Median Size (Max): 7 (73)
Median complexity (Max): 176 (1330371488)
Time (s): 0.27951

Generation 3/100 [//                                                ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,If(AIDS&gt;18390.00,12.99,AIDS),1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.50000)
Val Loss (Med): 0.76000 (0.50000)
Median Size (Max): 5 (33)
Median complexity (Max): 176 (9277856)
Time (s): 0.41748

Generation 4/100 [///                                               ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,If(AIDS&gt;18390.00,12.99,AIDS),1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.50000)
Val Loss (Med): 0.76000 (0.50000)
Median Size (Max): 5 (29)
Median complexity (Max): 128 (9068960)
Time (s): 0.59669

Generation 5/100 [///                                               ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,AIDS,1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.50000)
Val Loss (Med): 0.76000 (0.50000)
Median Size (Max): 5 (22)
Median complexity (Max): 128 (9003680)
Time (s): 0.69763

Generation 6/100 [////                                              ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,AIDS,1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.50000)
Val Loss (Med): 0.76000 (0.50000)
Median Size (Max): 5 (22)
Median complexity (Max): 128 (9003680)
Time (s): 0.75402

Generation 7/100 [////                                              ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,AIDS,1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.50000)
Val Loss (Med): 0.76000 (0.50000)
Median Size (Max): 5 (22)
Median complexity (Max): 128 (9003680)
Time (s): 0.82012

Generation 8/100 [/////                                             ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,AIDS,1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.56000)
Val Loss (Med): 0.76000 (0.56000)
Median Size (Max): 5 (22)
Median complexity (Max): 176 (9003680)
Time (s): 0.89256

Generation 9/100 [/////                                             ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,AIDS,1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.53000)
Val Loss (Med): 0.76000 (0.53000)
Median Size (Max): 5 (22)
Median complexity (Max): 152 (9003680)
Time (s): 0.98055

Generation 10/100 [//////                                            ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,AIDS,1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.53000)
Val Loss (Med): 0.76000 (0.53000)
Median Size (Max): 5 (22)
Median complexity (Max): 152 (9003680)
Time (s): 1.06166

Generation 11/100 [//////                                            ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,AIDS,1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.56000)
Val Loss (Med): 0.76000 (0.56000)
Median Size (Max): 5 (22)
Median complexity (Max): 176 (9003680)
Time (s): 1.17131

Generation 12/100 [///////                                           ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,AIDS,1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.56000)
Val Loss (Med): 0.76000 (0.56000)
Median Size (Max): 5 (22)
Median complexity (Max): 176 (9003680)
Time (s): 1.27139

Generation 13/100 [///////                                           ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,AIDS,1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.56000)
Val Loss (Med): 0.76000 (0.56000)
Median Size (Max): 5 (22)
Median complexity (Max): 176 (9003680)
Time (s): 1.39425

Generation 14/100 [////////                                          ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,AIDS,1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.56000)
Val Loss (Med): 0.76000 (0.56000)
Median Size (Max): 5 (22)
Median complexity (Max): 176 (9003680)
Time (s): 1.48988

Generation 15/100 [////////                                          ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,AIDS,1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.56000)
Val Loss (Med): 0.76000 (0.56000)
Median Size (Max): 5 (22)
Median complexity (Max): 176 (9003680)
Time (s): 1.62569

Generation 16/100 [/////////                                         ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,1.00,1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.56000)
Val Loss (Med): 0.76000 (0.56000)
Median Size (Max): 5 (20)
Median complexity (Max): 176 (9002912)
Time (s): 1.72896

Generation 17/100 [/////////                                         ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,1.00,1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.53000)
Val Loss (Med): 0.76000 (0.53000)
Median Size (Max): 5 (20)
Median complexity (Max): 152 (9002912)
Time (s): 1.83223

Generation 18/100 [//////////                                        ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,1.00,1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.50000)
Val Loss (Med): 0.76000 (0.50000)
Median Size (Max): 5 (20)
Median complexity (Max): 128 (9002912)
Time (s): 1.93055

Generation 19/100 [//////////                                        ]
Best model on Val:Logistic(Sum(-0.93,If(AIDS&gt;15890.50,1.00,1.46*Cos(18390.82*Cos(18390.00*Total)))))
Train Loss (Med): 0.76000 (0.56000)
Val Loss (Med): 0.76000 (0.56000)
Median Size (Max): 5 (20)
Median complexity (Max): 176 (9002912)
Time (s): 2.04937

Generation 20/100 [///////////                                       ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(123.00*Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,1.00*Sin(AIDS),1.00*Exp(1.00)),If(AIDS&gt;123.00,1.00*Mul(2320.50*Total,1.00*Total),1.00*Add(1.00*Total,1.00*AIDS))))))))))
Train Loss (Med): 0.86000 (0.56000)
Val Loss (Med): 0.86000 (0.56000)
Median Size (Max): 5 (67)
Median complexity (Max): 176 (9002912)
Time (s): 2.14543

Generation 21/100 [///////////                                       ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,1.00*Mul(Cos(1572255.62*Logabs(123.00*Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,1.00*Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00*Mul(2320.50*Total,1.00*Total),1.00*Add(1.00*Total,1.00*AIDS))))))),1.00))))
Train Loss (Med): 0.86000 (0.56000)
Val Loss (Med): 0.86000 (0.56000)
Median Size (Max): 5 (68)
Median complexity (Max): 176 (9002912)
Time (s): 2.30199

Generation 22/100 [////////////                                      ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,1.46*Cos(1572255.62*Logabs(123.00*Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,1.00*Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00*Mul(2320.50*Total,1.00*Total),1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.86000 (0.56000)
Val Loss (Med): 0.86000 (0.56000)
Median Size (Max): 5 (66)
Median complexity (Max): 176 (9002912)
Time (s): 2.40210

Generation 23/100 [////////////                                      ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,1.46*Cos(1572255.62*Logabs(123.00*Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,1.00*Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00*Mul(2320.50*Total,1.00*Total),1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.86000 (0.56000)
Val Loss (Med): 0.86000 (0.56000)
Median Size (Max): 5 (66)
Median complexity (Max): 176 (9002912)
Time (s): 2.54415

Generation 24/100 [/////////////                                     ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,1.46*Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,1.00*Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00*Mul(2320.50*Total,1.00*Total),1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.56000)
Val Loss (Med): 0.88000 (0.56000)
Median Size (Max): 5 (64)
Median complexity (Max): 176 (9002912)
Time (s): 2.64172

Generation 25/100 [/////////////                                     ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,1.46*Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,1.00*Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00*Mul(2320.50*Total,1.00*Total),1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.56000)
Val Loss (Med): 0.88000 (0.56000)
Median Size (Max): 5 (64)
Median complexity (Max): 176 (9002912)
Time (s): 2.79817

Generation 26/100 [//////////////                                    ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,1.46*Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,1.00*Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00*Mul(2320.50*Total,1.00*Total),1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.56000)
Val Loss (Med): 0.88000 (0.56000)
Median Size (Max): 5 (64)
Median complexity (Max): 176 (9002912)
Time (s): 2.90021

Generation 27/100 [//////////////                                    ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00*Mul(2320.50*Total,1.00*Total),1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.56000)
Val Loss (Med): 0.88000 (0.56000)
Median Size (Max): 5 (60)
Median complexity (Max): 176 (9002912)
Time (s): 3.11338

Generation 28/100 [///////////////                                   ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00*Mul(2320.50*Total,1.00*Total),1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.56000)
Val Loss (Med): 0.88000 (0.56000)
Median Size (Max): 5 (62)
Median complexity (Max): 176 (9002912)
Time (s): 3.22705

Generation 29/100 [///////////////                                   ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00*Mul(2320.50*Total,1.00*Total),1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.56000)
Val Loss (Med): 0.88000 (0.56000)
Median Size (Max): 5 (62)
Median complexity (Max): 176 (9002912)
Time (s): 3.43963

Generation 30/100 [////////////////                                  ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00*Mul(2320.50*Total,1.00*Total),1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.56000)
Val Loss (Med): 0.88000 (0.56000)
Median Size (Max): 5 (62)
Median complexity (Max): 176 (9002912)
Time (s): 3.56886

Generation 31/100 [////////////////                                  ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.56000)
Val Loss (Med): 0.88000 (0.56000)
Median Size (Max): 5 (50)
Median complexity (Max): 176 (9002912)
Time (s): 3.81566

Generation 32/100 [/////////////////                                 ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.56000)
Val Loss (Med): 0.88000 (0.56000)
Median Size (Max): 5 (50)
Median complexity (Max): 176 (9002912)
Time (s): 3.90975

Generation 33/100 [/////////////////                                 ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.56000)
Val Loss (Med): 0.88000 (0.56000)
Median Size (Max): 5 (50)
Median complexity (Max): 176 (9002912)
Time (s): 4.06391

Generation 34/100 [//////////////////                                ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.62000)
Val Loss (Med): 0.88000 (0.62000)
Median Size (Max): 6 (50)
Median complexity (Max): 176 (9002912)
Time (s): 4.17403

Generation 35/100 [//////////////////                                ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.70000)
Val Loss (Med): 0.88000 (0.70000)
Median Size (Max): 15 (50)
Median complexity (Max): 176 (454203296)
Time (s): 4.33815

Generation 36/100 [///////////////////                               ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.70000)
Val Loss (Med): 0.88000 (0.70000)
Median Size (Max): 15 (50)
Median complexity (Max): 176 (454203296)
Time (s): 4.46991

Generation 37/100 [///////////////////                               ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.70000)
Val Loss (Med): 0.88000 (0.70000)
Median Size (Max): 15 (50)
Median complexity (Max): 176 (454203296)
Time (s): 4.68430

Generation 38/100 [////////////////////                              ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.70000)
Val Loss (Med): 0.88000 (0.70000)
Median Size (Max): 16 (52)
Median complexity (Max): 584 (454203296)
Time (s): 4.80943

Generation 39/100 [////////////////////                              ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.70000)
Val Loss (Med): 0.88000 (0.70000)
Median Size (Max): 16 (52)
Median complexity (Max): 1088 (454203296)
Time (s): 5.02899

Generation 40/100 [/////////////////////                             ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.71000)
Val Loss (Med): 0.88000 (0.71000)
Median Size (Max): 16 (52)
Median complexity (Max): 63392 (1142069152)
Time (s): 5.16680

Generation 41/100 [/////////////////////                             ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.70000)
Val Loss (Med): 0.88000 (0.70000)
Median Size (Max): 16 (52)
Median complexity (Max): 63392 (47224736)
Time (s): 5.44718

Generation 42/100 [//////////////////////                            ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.69000)
Val Loss (Med): 0.88000 (0.69000)
Median Size (Max): 15 (54)
Median complexity (Max): 176 (135698336)
Time (s): 5.60524

Generation 43/100 [//////////////////////                            ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.69000)
Val Loss (Med): 0.88000 (0.69000)
Median Size (Max): 11 (52)
Median complexity (Max): 176 (31889312)
Time (s): 5.90069

Generation 44/100 [///////////////////////                           ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.70000)
Val Loss (Med): 0.88000 (0.70000)
Median Size (Max): 15 (52)
Median complexity (Max): 992 (31889312)
Time (s): 6.10233

Generation 45/100 [///////////////////////                           ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.70000)
Val Loss (Med): 0.88000 (0.70000)
Median Size (Max): 15 (52)
Median complexity (Max): 992 (31889312)
Time (s): 6.57095

Generation 46/100 [////////////////////////                          ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Sin(AIDS),2.72),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.88000 (0.70000)
Val Loss (Med): 0.88000 (0.70000)
Median Size (Max): 15 (52)
Median complexity (Max): 992 (31889312)
Time (s): 6.79213

Generation 47/100 [////////////////////////                          ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,Sin(AIDS),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (55)
Median complexity (Max): 1184 (31889312)
Time (s): 7.15034

Generation 48/100 [/////////////////////////                         ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,Sin(AIDS),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (55)
Median complexity (Max): 1184 (31889312)
Time (s): 7.30973

Generation 49/100 [/////////////////////////                         ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,Sin(AIDS),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (55)
Median complexity (Max): 1184 (31889312)
Time (s): 7.62883

Generation 50/100 [//////////////////////////                        ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,Sin(AIDS),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (57)
Median complexity (Max): 1184 (10213280)
Time (s): 7.78313

Generation 51/100 [//////////////////////////                        ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,Sin(AIDS),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (57)
Median complexity (Max): 1184 (10213280)
Time (s): 8.10936

Generation 52/100 [///////////////////////////                       ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,Sin(AIDS),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (57)
Median complexity (Max): 1184 (10213280)
Time (s): 8.25937

Generation 53/100 [///////////////////////////                       ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,Sin(AIDS),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (57)
Median complexity (Max): 63392 (14194592)
Time (s): 8.49307

Generation 54/100 [////////////////////////////                      ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,Sin(AIDS),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 16 (59)
Median complexity (Max): 63392 (14194592)
Time (s): 8.62757

Generation 55/100 [////////////////////////////                      ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,Sin(AIDS),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (59)
Median complexity (Max): 63392 (6821792)
Time (s): 8.95665

Generation 56/100 [/////////////////////////////                     ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,Sin(AIDS),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (59)
Median complexity (Max): 63392 (6821792)
Time (s): 9.09154

Generation 57/100 [/////////////////////////////                     ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,Sin(AIDS),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (59)
Median complexity (Max): 63392 (6821792)
Time (s): 9.33874

Generation 58/100 [//////////////////////////////                    ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (59)
Median complexity (Max): 63392 (6821792)
Time (s): 9.46578

Generation 59/100 [//////////////////////////////                    ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 9.70810

Generation 60/100 [///////////////////////////////                   ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 9.83397

Generation 61/100 [///////////////////////////////                   ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 16 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 10.11486

Generation 62/100 [////////////////////////////////                  ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 16 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 10.30578

Generation 63/100 [////////////////////////////////                  ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 10.58340

Generation 64/100 [/////////////////////////////////                 ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 10.73584

Generation 65/100 [/////////////////////////////////                 ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 10.98930

Generation 66/100 [//////////////////////////////////                ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 11.17944

Generation 67/100 [//////////////////////////////////                ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 15 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 11.40828

Generation 68/100 [///////////////////////////////////               ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 16 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 11.58104

Generation 69/100 [///////////////////////////////////               ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 16 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 11.87500

Generation 70/100 [////////////////////////////////////              ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 16 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 12.05814

Generation 71/100 [////////////////////////////////////              ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.71000)
Val Loss (Med): 0.90000 (0.71000)
Median Size (Max): 16 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 12.45736

Generation 72/100 [/////////////////////////////////////             ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.72000)
Val Loss (Med): 0.90000 (0.72000)
Median Size (Max): 16 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 12.61265

Generation 73/100 [/////////////////////////////////////             ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.72000)
Val Loss (Med): 0.90000 (0.72000)
Median Size (Max): 16 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 13.01105

Generation 74/100 [//////////////////////////////////////            ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.72000)
Val Loss (Med): 0.90000 (0.72000)
Median Size (Max): 16 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 13.18676

Generation 75/100 [//////////////////////////////////////            ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.72000)
Val Loss (Med): 0.90000 (0.72000)
Median Size (Max): 16 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 13.50740

Generation 76/100 [///////////////////////////////////////           ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.72000)
Val Loss (Med): 0.90000 (0.72000)
Median Size (Max): 16 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 13.66485

Generation 77/100 [///////////////////////////////////////           ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.72000)
Val Loss (Med): 0.90000 (0.72000)
Median Size (Max): 16 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 13.99095

Generation 78/100 [////////////////////////////////////////          ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.72000)
Val Loss (Med): 0.90000 (0.72000)
Median Size (Max): 16 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 14.15626

Generation 79/100 [////////////////////////////////////////          ]
Best model on Val:Logistic(Sum(-0.08,If(AIDS&gt;15890.50,8.28,Cos(1572255.62*Logabs(Sin(1.00*Logabs(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,If(Age&gt;0.00,1.00*Sin(1.00),2.72),1.00),If(AIDS&gt;123.00,1.00,1.00*Add(1.00*Total,AIDS))))))))))
Train Loss (Med): 0.90000 (0.72000)
Val Loss (Med): 0.90000 (0.72000)
Median Size (Max): 16 (60)
Median complexity (Max): 63392 (6821792)
Time (s): 14.54490

Generation 80/100 [/////////////////////////////////////////         ]
Best model on Val:Logistic(Sum(-0.40,If(AIDS&gt;15890.50,3.93,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-2.56),If(AIDS&gt;123.00,2318.55,2642.91))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 16 (36)
Median complexity (Max): 63392 (31889312)
Time (s): 14.73274

Generation 81/100 [/////////////////////////////////////////         ]
Best model on Val:Logistic(Sum(-0.40,If(AIDS&gt;15890.50,3.93,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-2.56),If(AIDS&gt;123.00,2318.55,2642.91))))))
Train Loss (Med): 0.90000 (0.70000)
Val Loss (Med): 0.90000 (0.70000)
Median Size (Max): 16 (36)
Median complexity (Max): 63392 (31889312)
Time (s): 14.93427

Generation 82/100 [//////////////////////////////////////////        ]
Best model on Val:Logistic(Sum(-0.40,If(AIDS&gt;15890.50,3.93,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-2.56),If(AIDS&gt;123.00,2318.55,2642.91))))))
Train Loss (Med): 0.90000 (0.72000)
Val Loss (Med): 0.90000 (0.72000)
Median Size (Max): 18 (38)
Median complexity (Max): 278432 (112105376)
Time (s): 15.07023

Generation 83/100 [//////////////////////////////////////////        ]
Best model on Val:Logistic(Sum(-0.40,If(AIDS&gt;15890.50,3.93,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-2.56),If(AIDS&gt;123.00,2318.55,2642.91))))))
Train Loss (Med): 0.90000 (0.74000)
Val Loss (Med): 0.90000 (0.74000)
Median Size (Max): 19 (38)
Median complexity (Max): 324512 (127557536)
Time (s): 15.28743

Generation 84/100 [///////////////////////////////////////////       ]
Best model on Val:Logistic(Sum(-0.40,If(AIDS&gt;15890.50,3.93,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-2.56),If(AIDS&gt;123.00,2318.55,2642.91))))))
Train Loss (Med): 0.90000 (0.84000)
Val Loss (Med): 0.90000 (0.84000)
Median Size (Max): 27 (38)
Median complexity (Max): 5494688 (31889312)
Time (s): 15.43426

Generation 85/100 [///////////////////////////////////////////       ]
Best model on Val:Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
Train Loss (Med): 0.94000 (0.84000)
Val Loss (Med): 0.94000 (0.84000)
Median Size (Max): 27 (46)
Median complexity (Max): 5494688 (454203296)
Time (s): 15.70847

Generation 86/100 [////////////////////////////////////////////      ]
Best model on Val:Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
Train Loss (Med): 0.94000 (0.84000)
Val Loss (Med): 0.94000 (0.84000)
Median Size (Max): 27 (46)
Median complexity (Max): 5494688 (454203296)
Time (s): 15.86697

Generation 87/100 [////////////////////////////////////////////      ]
Best model on Val:Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
Train Loss (Med): 0.94000 (0.84000)
Val Loss (Med): 0.94000 (0.84000)
Median Size (Max): 27 (46)
Median complexity (Max): 5494688 (454203296)
Time (s): 16.20231

Generation 88/100 [/////////////////////////////////////////////     ]
Best model on Val:Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
Train Loss (Med): 0.94000 (0.79000)
Val Loss (Med): 0.94000 (0.79000)
Median Size (Max): 23 (46)
Median complexity (Max): 2794400 (454203296)
Time (s): 16.37100

Generation 89/100 [/////////////////////////////////////////////     ]
Best model on Val:Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
Train Loss (Med): 0.94000 (0.72000)
Val Loss (Med): 0.94000 (0.72000)
Median Size (Max): 19 (46)
Median complexity (Max): 75680 (454203296)
Time (s): 16.70405

Generation 90/100 [//////////////////////////////////////////////    ]
Best model on Val:Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
Train Loss (Med): 0.94000 (0.79000)
Val Loss (Med): 0.94000 (0.79000)
Median Size (Max): 23 (46)
Median complexity (Max): 2794400 (454203296)
Time (s): 16.89562

Generation 91/100 [//////////////////////////////////////////////    ]
Best model on Val:Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
Train Loss (Med): 0.94000 (0.72000)
Val Loss (Med): 0.94000 (0.72000)
Median Size (Max): 19 (46)
Median complexity (Max): 75680 (454203296)
Time (s): 17.37115

Generation 92/100 [///////////////////////////////////////////////   ]
Best model on Val:Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
Train Loss (Med): 0.94000 (0.79000)
Val Loss (Med): 0.94000 (0.79000)
Median Size (Max): 23 (46)
Median complexity (Max): 2794400 (454203296)
Time (s): 17.56058

Generation 93/100 [///////////////////////////////////////////////   ]
Best model on Val:Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
Train Loss (Med): 0.94000 (0.79000)
Val Loss (Med): 0.94000 (0.79000)
Median Size (Max): 23 (46)
Median complexity (Max): 2794400 (454203296)
Time (s): 18.07318

Generation 94/100 [////////////////////////////////////////////////  ]
Best model on Val:Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
Train Loss (Med): 0.94000 (0.74000)
Val Loss (Med): 0.94000 (0.74000)
Median Size (Max): 19 (46)
Median complexity (Max): 94112 (454203296)
Time (s): 18.30026

Generation 95/100 [////////////////////////////////////////////////  ]
Best model on Val:Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
Train Loss (Med): 0.94000 (0.70000)
Val Loss (Med): 0.94000 (0.70000)
Median Size (Max): 19 (46)
Median complexity (Max): 57248 (454203296)
Time (s): 18.68901

Generation 96/100 [///////////////////////////////////////////////// ]
Best model on Val:Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
Train Loss (Med): 0.94000 (0.70000)
Val Loss (Med): 0.94000 (0.70000)
Median Size (Max): 19 (46)
Median complexity (Max): 57248 (454203296)
Time (s): 18.86318

Generation 97/100 [///////////////////////////////////////////////// ]
Best model on Val:Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
Train Loss (Med): 0.94000 (0.70000)
Val Loss (Med): 0.94000 (0.70000)
Median Size (Max): 19 (48)
Median complexity (Max): 57248 (454203296)
Time (s): 19.25050

Generation 98/100 [//////////////////////////////////////////////////]
Best model on Val:Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
Train Loss (Med): 0.94000 (0.70000)
Val Loss (Med): 0.94000 (0.70000)
Median Size (Max): 19 (48)
Median complexity (Max): 57248 (454203296)
Time (s): 19.44083

Generation 99/100 [//////////////////////////////////////////////////]
Best model on Val:Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
Train Loss (Med): 0.94000 (0.70000)
Val Loss (Med): 0.94000 (0.70000)
Median Size (Max): 19 (48)
Median complexity (Max): 57248 (454203296)
Time (s): 19.90857

Generation 100/100 [//////////////////////////////////////////////////]
Best model on Val:Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
Train Loss (Med): 0.94000 (0.72000)
Val Loss (Med): 0.94000 (0.72000)
Median Size (Max): 19 (48)
Median complexity (Max): 75680 (454203296)
Time (s): 20.10856

Best model: Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
score: 0.94
</pre></div>
</div>
</div>
</div>
<p>You can see individuals from archive using the index:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">archive_</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<span class="n">est</span><span class="o">.</span><span class="n">archive_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>7
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;fitness&#39;: {&#39;complexity&#39;: 128,
  &#39;crowding_dist&#39;: 0.0,
  &#39;dcounter&#39;: 0,
  &#39;depth&#39;: 3,
  &#39;dominated&#39;: [],
  &#39;linear_complexity&#39;: 15,
  &#39;loss&#39;: 0.5,
  &#39;loss_v&#39;: 0.5,
  &#39;prev_complexity&#39;: 128,
  &#39;prev_depth&#39;: 3,
  &#39;prev_linear_complexity&#39;: 15,
  &#39;prev_loss&#39;: 0.5,
  &#39;prev_loss_v&#39;: 0.5,
  &#39;prev_size&#39;: 5,
  &#39;rank&#39;: 1,
  &#39;size&#39;: 5,
  &#39;values&#39;: [0.5, 15.0],
  &#39;weights&#39;: [1.0, -1.0],
  &#39;wvalues&#39;: [0.5, -15.0]},
 &#39;id&#39;: 223,
 &#39;is_fitted_&#39;: False,
 &#39;objectives&#39;: [&#39;balanced_accuracy&#39;, &#39;linear_complexity&#39;],
 &#39;parent_id&#39;: [210],
 &#39;program&#39;: {&#39;Tree&#39;: [{&#39;W&#39;: 1.0,
    &#39;arg_types&#39;: [&#39;ArrayF&#39;],
    &#39;center_op&#39;: True,
    &#39;feature&#39;: &#39;&#39;,
    &#39;feature_type&#39;: &#39;ArrayF&#39;,
    &#39;fixed&#39;: True,
    &#39;is_weighted&#39;: False,
    &#39;name&#39;: &#39;Logistic&#39;,
    &#39;node_type&#39;: &#39;Logistic&#39;,
    &#39;prob_change&#39;: 0.0,
    &#39;ret_type&#39;: &#39;ArrayF&#39;,
    &#39;sig_dual_hash&#39;: 13056393536346412951,
    &#39;sig_hash&#39;: 14128685871577087634},
   {&#39;W&#39;: -21.10409164428711,
    &#39;arg_types&#39;: [&#39;ArrayF&#39;],
    &#39;center_op&#39;: True,
    &#39;feature&#39;: &#39;&#39;,
    &#39;feature_type&#39;: &#39;ArrayF&#39;,
    &#39;fixed&#39;: True,
    &#39;is_weighted&#39;: True,
    &#39;name&#39;: &#39;OffsetSum&#39;,
    &#39;node_type&#39;: &#39;OffsetSum&#39;,
    &#39;prob_change&#39;: 0.0,
    &#39;ret_type&#39;: &#39;ArrayF&#39;,
    &#39;sig_dual_hash&#39;: 13056393536346412951,
    &#39;sig_hash&#39;: 14128685871577087634},
   {&#39;W&#39;: 1.0,
    &#39;arg_types&#39;: [],
    &#39;center_op&#39;: True,
    &#39;feature&#39;: &#39;constF&#39;,
    &#39;feature_type&#39;: &#39;ArrayF&#39;,
    &#39;fixed&#39;: False,
    &#39;is_weighted&#39;: True,
    &#39;name&#39;: &#39;Constant&#39;,
    &#39;node_type&#39;: &#39;Constant&#39;,
    &#39;prob_change&#39;: 0.19857122004032135,
    &#39;ret_type&#39;: &#39;ArrayF&#39;,
    &#39;sig_dual_hash&#39;: 7018942542468397869,
    &#39;sig_hash&#39;: 14162902253047951597}],
  &#39;is_fitted_&#39;: True},
 &#39;variation&#39;: &#39;subtree&#39;}
</pre></div>
</div>
</div>
</div>
<p>And you can call <code class="docutils literal notranslate"><span class="pre">predict</span></code> (or <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>, if your <code class="docutils literal notranslate"><span class="pre">est</span></code> is an instance of <code class="docutils literal notranslate"><span class="pre">BrushClassifier</span></code>) with the entire archive:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">est</span><span class="o">.</span><span class="n">predict_archive</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[{&#39;id&#39;: 223,
  &#39;y_pred&#39;: array([False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,
         False, False, False, False, False])},
 {&#39;id&#39;: 255,
  &#39;y_pred&#39;: array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True, False,  True,  True,  True,  True,
         False,  True,  True,  True, False])},
 {&#39;id&#39;: 223,
  &#39;y_pred&#39;: array([False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,
         False, False, False, False, False])},
 {&#39;id&#39;: 285,
  &#39;y_pred&#39;: array([False,  True,  True,  True,  True, False,  True,  True,  True,
         False,  True,  True,  True,  True, False,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True, False, False,
         False, False, False, False, False, False, False, False, False,
         False, False,  True, False,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True])},
 {&#39;id&#39;: 285,
  &#39;y_pred&#39;: array([False,  True,  True,  True,  True, False,  True,  True,  True,
         False,  True,  True,  True,  True, False,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True, False, False,
         False, False, False, False, False, False, False, False, False,
         False, False,  True, False,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True])},
 {&#39;id&#39;: 274,
  &#39;y_pred&#39;: array([False,  True,  True,  True,  True,  True,  True,  True,  True,
         False, False,  True,  True,  True,  True, False,  True, False,
          True, False, False,  True,  True, False, False, False, False,
         False, False, False, False,  True, False,  True, False, False,
         False, False, False, False, False, False,  True, False, False,
         False, False, False, False, False])},
 {&#39;id&#39;: 221,
  &#39;y_pred&#39;: array([False,  True,  True,  True,  True, False,  True,  True,  True,
         False,  True,  True,  True,  True, False, False,  True,  True,
          True,  True, False,  True,  True,  True, False, False, False,
         False, False, False, False, False, False, False, False, False,
         False, False,  True, False, False, False, False, False, False,
         False, False, False, False, False])},
 {&#39;id&#39;: 272,
  &#39;y_pred&#39;: array([False,  True,  True,  True,  True, False,  True,  True,  True,
         False,  True,  True,  True,  True, False,  True,  True,  True,
          True,  True, False,  True,  True,  True, False, False, False,
         False, False, False, False, False, False, False, False, False,
         False, False,  True, False, False, False, False, False, False,
         False, False, False, False, False])},
 {&#39;id&#39;: 239,
  &#39;y_pred&#39;: array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True, False, False,  True,  True,
          True,  True, False,  True,  True,  True, False, False, False,
         False, False, False, False, False, False, False, False, False,
         False, False,  True,  True, False, False, False, False, False,
         False, False, False, False, False])},
 {&#39;id&#39;: 236,
  &#39;y_pred&#39;: array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True, False, False,  True,  True,
          True,  True, False,  True,  True,  True, False, False, False,
         False, False, False, False, False, False, False, False, False,
         False, False,  True, False, False, False, False, False, False,
         False, False, False, False, False])},
 {&#39;id&#39;: 278,
  &#39;y_pred&#39;: array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True, False,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True, False, False,
         False, False, False, False, False, False, False, False, False,
         False, False,  True,  True, False, False, False, False, False,
         False, False, False, False,  True])},
 {&#39;id&#39;: 200,
  &#39;y_pred&#39;: array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True, False,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True, False, False,
         False, False, False, False, False, False, False, False, False,
         False, False,  True, False, False, False, False, False, False,
         False, False, False, False,  True])}]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">est</span><span class="o">.</span><span class="n">predict_proba_archive</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[{&#39;id&#39;: 223,
  &#39;y_pred&#39;: array([1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573936e-09, 1.8573936e-09], dtype=float32)},
 {&#39;id&#39;: 255,
  &#39;y_pred&#39;: array([1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
         1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
         1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
         1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
         1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
         9.9257833e-01, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
         1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
         1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
         1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
         1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
         2.7566156e-07, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
         1.0000000e+00, 1.3724385e-08, 1.0000000e+00, 1.0000000e+00,
         9.9994957e-01, 8.2106108e-04], dtype=float32)},
 {&#39;id&#39;: 223,
  &#39;y_pred&#39;: array([1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573938e-09, 1.8573938e-09, 1.8573938e-09, 1.8573938e-09,
         1.8573936e-09, 1.8573936e-09], dtype=float32)},
 {&#39;id&#39;: 285,
  &#39;y_pred&#39;: array([0.47076803, 0.51036537, 0.51036537, 0.51036537, 0.51036537,
         0.47076803, 0.51036537, 0.51036537, 0.51036537, 0.47076803,
         0.9999993 , 0.51036537, 0.51036537, 0.9999993 , 0.47076803,
         0.9999993 , 0.9999993 , 0.9999993 , 0.9999993 , 0.9999993 ,
         0.9999993 , 0.9999993 , 0.9999993 , 0.9999993 , 0.9999993 ,
         0.47076803, 0.47076803, 0.47076803, 0.47076803, 0.47076803,
         0.47076803, 0.47076803, 0.47076803, 0.47076803, 0.47076803,
         0.47076803, 0.47076803, 0.47076803, 0.9999993 , 0.47076803,
         0.9999993 , 0.9999993 , 0.9999993 , 0.9999993 , 0.9999993 ,
         0.9999993 , 0.9999993 , 0.9999993 , 0.9999993 , 0.9999993 ],
        dtype=float32)},
 {&#39;id&#39;: 285,
  &#39;y_pred&#39;: array([0.47076803, 0.51036537, 0.51036537, 0.51036537, 0.51036537,
         0.47076803, 0.51036537, 0.51036537, 0.51036537, 0.47076803,
         0.9999993 , 0.51036537, 0.51036537, 0.9999993 , 0.47076803,
         0.9999993 , 0.9999993 , 0.9999993 , 0.9999993 , 0.9999993 ,
         0.9999993 , 0.9999993 , 0.9999993 , 0.9999993 , 0.9999993 ,
         0.47076803, 0.47076803, 0.47076803, 0.47076803, 0.47076803,
         0.47076803, 0.47076803, 0.47076803, 0.47076803, 0.47076803,
         0.47076803, 0.47076803, 0.47076803, 0.9999993 , 0.47076803,
         0.9999993 , 0.9999993 , 0.9999993 , 0.9999993 , 0.9999993 ,
         0.9999993 , 0.9999993 , 0.9999993 , 0.9999993 , 0.9999993 ],
        dtype=float32)},
 {&#39;id&#39;: 274,
  &#39;y_pred&#39;: array([0.22078463, 0.9992943 , 0.9992943 , 0.9992943 , 0.9992943 ,
         0.6344058 , 0.9992943 , 0.9992943 , 0.9992943 , 0.20277868,
         0.27959597, 0.9992943 , 0.9992943 , 0.5544949 , 0.5330731 ,
         0.241057  , 0.6292696 , 0.29684842, 0.6433534 , 0.22639535,
         0.21853629, 0.51127195, 0.61393803, 0.39996338, 0.23879772,
         0.24733631, 0.43363965, 0.19904314, 0.33172768, 0.3894886 ,
         0.47258943, 0.6089025 , 0.19756831, 0.6233104 , 0.34609637,
         0.42297646, 0.2998753 , 0.47208527, 0.23798501, 0.1987097 ,
         0.25890952, 0.20208882, 0.6450495 , 0.24025731, 0.26688117,
         0.21143621, 0.42287534, 0.21421689, 0.19780532, 0.30269516],
        dtype=float32)},
 {&#39;id&#39;: 221,
  &#39;y_pred&#39;: array([0.39694032, 0.51036537, 0.51036537, 0.51036537, 0.51036537,
         0.39694032, 0.51036537, 0.51036537, 0.51036537, 0.39694032,
         0.51036215, 0.51036537, 0.51036537, 0.51036215, 0.39694032,
         0.4890932 , 0.51036215, 0.51036215, 0.51036215, 0.51036215,
         0.4890932 , 0.51036215, 0.51036215, 0.51036215, 0.4890932 ,
         0.39694032, 0.39694032, 0.39694032, 0.39694032, 0.39694032,
         0.39694032, 0.39694032, 0.39694032, 0.39694032, 0.39694032,
         0.39694032, 0.39694032, 0.39694032, 0.51036215, 0.39694032,
         0.4890932 , 0.4890932 , 0.4890932 , 0.4890932 , 0.4890932 ,
         0.4890932 , 0.4890932 , 0.4890932 , 0.4890932 , 0.4890932 ],
        dtype=float32)},
 {&#39;id&#39;: 272,
  &#39;y_pred&#39;: array([0.39694032, 0.51036537, 0.51036537, 0.51036537, 0.51036537,
         0.39694032, 0.51036537, 0.51036537, 0.51036537, 0.39694032,
         0.51036215, 0.51036537, 0.51036537, 0.51036215, 0.39694032,
         0.5087247 , 0.51036215, 0.51036215, 0.51036215, 0.51036215,
         0.4852957 , 0.51036215, 0.51036215, 0.51036215, 0.13536516,
         0.39694032, 0.39694032, 0.39694032, 0.39694032, 0.39694032,
         0.39694032, 0.39694032, 0.39694032, 0.39694032, 0.39694032,
         0.39694032, 0.39694032, 0.39694032, 0.51036215, 0.39694032,
         0.45193142, 0.4159763 , 0.34887105, 0.4760136 , 0.20720221,
         0.1409639 , 0.17713964, 0.35815552, 0.42929202, 0.39328158],
        dtype=float32)},
 {&#39;id&#39;: 239,
  &#39;y_pred&#39;: array([0.5785229 , 0.9999362 , 0.9999362 , 0.9999362 , 0.9999362 ,
         0.5055826 , 0.9999362 , 0.9999362 , 0.9999362 , 0.5466553 ,
         0.55092424, 0.9999362 , 0.9999362 , 0.55092424, 0.17046632,
         0.464316  , 0.55092424, 0.55092424, 0.55092424, 0.55092424,
         0.464316  , 0.55092424, 0.55092424, 0.55092424, 0.464316  ,
         0.24375606, 0.42224756, 0.2000557 , 0.164838  , 0.4683254 ,
         0.24800968, 0.35139441, 0.15822724, 0.33005065, 0.17509437,
         0.3915668 , 0.17795096, 0.15703292, 0.55092424, 0.5484897 ,
         0.464316  , 0.464316  , 0.464316  , 0.464316  , 0.464316  ,
         0.464316  , 0.464316  , 0.464316  , 0.46431595, 0.46431595],
        dtype=float32)},
 {&#39;id&#39;: 236,
  &#39;y_pred&#39;: array([0.5341366 , 0.97149706, 0.97149706, 0.97149706, 0.97149706,
         0.595743  , 0.97149706, 0.97149706, 0.97149706, 0.6374889 ,
         0.6451214 , 0.97149706, 0.97149706, 0.6451214 , 0.20631014,
         0.25465378, 0.6451214 , 0.6451214 , 0.6451214 , 0.6451214 ,
         0.25465378, 0.6451214 , 0.6451214 , 0.6451214 , 0.25465378,
         0.22488779, 0.27234203, 0.45471945, 0.22488779, 0.22488779,
         0.22488779, 0.35909244, 0.21077366, 0.3659081 , 0.21971035,
         0.22488779, 0.23598474, 0.20088616, 0.6451214 , 0.22488779,
         0.25465378, 0.25465378, 0.25465378, 0.25465378, 0.25465378,
         0.25465378, 0.25465378, 0.25465378, 0.25465378, 0.25465378],
        dtype=float32)},
 {&#39;id&#39;: 278,
  &#39;y_pred&#39;: array([0.5785229 , 0.9999362 , 0.9999362 , 0.9999362 , 0.9999362 ,
         0.5055826 , 0.9999362 , 0.9999362 , 0.9999362 , 0.5466553 ,
         0.55092424, 0.9999362 , 0.9999362 , 0.55092424, 0.17046632,
         0.54496455, 0.55092424, 0.55092424, 0.55092424, 0.55092424,
         0.55631787, 0.55092424, 0.55092424, 0.55092424, 0.57406765,
         0.24375606, 0.42224756, 0.2000557 , 0.164838  , 0.4683254 ,
         0.24800968, 0.35139441, 0.15822724, 0.33005065, 0.17509437,
         0.3915668 , 0.17795096, 0.15703292, 0.55092424, 0.5484897 ,
         0.36465532, 0.20978333, 0.3414585 , 0.16395786, 0.1567926 ,
         0.16825083, 0.4635296 , 0.37926087, 0.18373597, 0.5086016 ],
        dtype=float32)},
 {&#39;id&#39;: 200,
  &#39;y_pred&#39;: array([0.5785229 , 0.9999362 , 0.9999362 , 0.9999362 , 0.9999362 ,
         0.5055826 , 0.9999362 , 0.9999362 , 0.9999362 , 0.5466553 ,
         0.55092424, 0.9999362 , 0.9999362 , 0.55092424, 0.17046632,
         0.54496455, 0.55092424, 0.55092424, 0.55092424, 0.55092424,
         0.55631787, 0.55092424, 0.55092424, 0.55092424, 0.57406765,
         0.16120362, 0.42224756, 0.2000557 , 0.16120362, 0.16120362,
         0.16120362, 0.35139441, 0.15822724, 0.33005065, 0.17509437,
         0.16120362, 0.17795096, 0.15703292, 0.55092424, 0.16120362,
         0.36465532, 0.20978333, 0.3414585 , 0.16395786, 0.1567926 ,
         0.16825083, 0.4635296 , 0.37926087, 0.18373597, 0.5086016 ],
        dtype=float32)}]
</pre></div>
</div>
</div>
</div>
<section id="loading-a-specific-model-from-archive">
<h2>Loading a specific model from archive<a class="headerlink" href="#loading-a-specific-model-from-archive" title="Link to this heading">ÔÉÅ</a></h2>
<p>We have a static class method called <code class="docutils literal notranslate"><span class="pre">from_json</span></code> which let‚Äôs you easily the string representation of the json from the archive to load an individual.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pybrush</span><span class="w"> </span><span class="kn">import</span> <span class="n">individual</span>

<span class="n">loaded_from_arch</span> <span class="o">=</span> <span class="n">individual</span><span class="o">.</span><span class="n">ClassifierIndividual</span><span class="o">.</span><span class="n">from_json</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">archive_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">loaded_from_arch</span><span class="o">.</span><span class="n">get_model</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loaded_from_arch</span><span class="o">.</span><span class="n">fitness</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Logistic(Sum(-0.68,If(AIDS&gt;15890.50,10.34,Cos(If(Total&gt;1572255.50,If(AIDS&gt;2320.50,Mul(Total,0.84),-3.40),If(AIDS&gt;123.00,2318.97,1.00*Mul(51.50*Mul(Total,-0.74),7.39)))))))
Fitness(0.940000 95.000000 )
</pre></div>
</div>
</div>
</div>
<p>To use this loaded model to do predictions, you need to wrap the data into a Dataset:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pybrush</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>

<span class="n">loaded_from_arch</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Dataset</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">ref_dataset</span><span class="o">=</span><span class="n">est</span><span class="o">.</span><span class="n">data_</span><span class="p">,</span> 
                              <span class="n">feature_names</span><span class="o">=</span><span class="n">est</span><span class="o">.</span><span class="n">feature_names_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True, False,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True, False, False,
       False, False, False, False, False, False, False, False, False,
       False, False,  True, False, False, False, False, False, False,
       False, False, False, False,  True])
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualizing-the-pareto-front-of-the-archive">
<h2>Visualizing the Pareto front of the archive<a class="headerlink" href="#visualizing-the-pareto-front-of-the-archive" title="Link to this heading">ÔÉÅ</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">xs</span><span class="p">,</span> <span class="n">ys</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">est</span><span class="o">.</span><span class="n">archive_</span><span class="p">:</span>
    <span class="c1"># We should look at the same objectives to get a valid pareto front</span>
    <span class="n">xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ind</span><span class="p">[</span><span class="s1">&#39;fitness&#39;</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
    <span class="n">ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ind</span><span class="p">[</span><span class="s1">&#39;fitness&#39;</span><span class="p">][</span><span class="s1">&#39;linear_complexity&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xs</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Loss on validation partition (greater is better)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Complexity (smaller is better)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>12
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Complexity (smaller is better)&#39;)
</pre></div>
</div>
<img alt="../_images/f249e790dbd9b1e4983695724d8ce5c601960ec959c1c49c13469fb50fe4cfd5.png" src="../_images/f249e790dbd9b1e4983695724d8ce5c601960ec959c1c49c13469fb50fe4cfd5.png" />
</div>
</div>
</section>
<section id="storing-the-population-unique-individuals">
<h2>Storing the population (unique individuals)<a class="headerlink" href="#storing-the-population-unique-individuals" title="Link to this heading">ÔÉÅ</a></h2>
<p>If not using archive, then the unique individuals from the final population will be stored. Notice that, while the archive contains only the Pareto front (when <code class="docutils literal notranslate"><span class="pre">use_arch=True</span></code>), this will contain all individuals, even dominated ones.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">est</span> <span class="o">=</span> <span class="n">BrushClassifier</span><span class="p">(</span>
    <span class="c1"># functions=[&#39;SplitBest&#39;,&#39;Add&#39;,&#39;Mul&#39;,&#39;Sin&#39;,&#39;Cos&#39;,&#39;Exp&#39;,&#39;Logabs&#39;],</span>
    <span class="n">use_arch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">objectives</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;scorer&quot;</span><span class="p">,</span> <span class="s2">&quot;linear_complexity&quot;</span><span class="p">],</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
    <span class="n">max_size</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span>
    <span class="n">max_gens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">pop_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
    <span class="n">verbosity</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best model:&quot;</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">get_model</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;score:&#39;</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 100% [====================]
Best model: Logistic(Sum(-0.28,463.85*Prod(21.86*Div(If(AIDS&gt;15890.50,AIDS,-0.82),15897.31*AIDS),21.86)))
score: 0.68
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">est</span><span class="o">.</span><span class="n">archive_</span><span class="p">:</span>
    <span class="c1"># use the same as the objectives</span>
    <span class="n">xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ind</span><span class="p">[</span><span class="s1">&#39;fitness&#39;</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
    <span class="n">ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ind</span><span class="p">[</span><span class="s1">&#39;fitness&#39;</span><span class="p">][</span><span class="s1">&#39;linear_complexity&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xs</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Loss on validation partition (smaller is better)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Complexity (smaller is better)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>8
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Complexity (smaller is better)&#39;)
</pre></div>
</div>
<img alt="../_images/ec0287a6b722052db558318878c647091ed038d749897767d376bda27bc742c7.png" src="../_images/ec0287a6b722052db558318878c647091ed038d749897767d376bda27bc742c7.png" />
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="saving_loading_populations.html" class="btn btn-neutral float-left" title="Saving and loading populations" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="deap.html" class="btn btn-neutral float-right" title="Using Deap" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, William La Cava and Joseph D. Romano.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>