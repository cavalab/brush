{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading populations\n",
    "\n",
    "Another feature Brush implements is the ability to save and load entire populations.\n",
    "We use JSON notation to store the population into a file that is human readable. The same way, we can feed an estimator a previous population file to serve as starting point for the evolution.\n",
    "\n",
    "In this notebook, we will walk through how to use the `save_population` and `load_population` parameters. \n",
    "\n",
    "We start by getting a sample dataset and splitting it into `X` and `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pybrush import BrushRegressor\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('../examples/datasets/d_enc.csv')\n",
    "X = df.drop(columns='label')\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the population after finishing the evolution, you nee to set `save_population` parameter to a value different than an empty string. Then, the final population is going to be stored in that specific file.\n",
    "\n",
    "In this example, we create a temporary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1/10 [//////                                            ]\n",
      "Train Loss (Med): 14.45158 (74.37033)\n",
      "Val Loss (Med): 14.45158 (74.37033)\n",
      "Median Size (Max): 3 (24)\n",
      "Median complexity (Max): 9 (3315)\n",
      "Time (s): 0.13028\n",
      "\n",
      "Generation 2/10 [///////////                                       ]\n",
      "Train Loss (Med): 14.15208 (20.54475)\n",
      "Val Loss (Med): 14.15208 (20.54475)\n",
      "Median Size (Max): 3 (19)\n",
      "Median complexity (Max): 9 (1671)\n",
      "Time (s): 0.20999\n",
      "\n",
      "Generation 3/10 [////////////////                                  ]\n",
      "Train Loss (Med): 11.74184 (17.94969)\n",
      "Val Loss (Med): 11.74184 (17.94969)\n",
      "Median Size (Max): 3 (19)\n",
      "Median complexity (Max): 9 (1671)\n",
      "Time (s): 0.30145\n",
      "\n",
      "Generation 4/10 [/////////////////////                             ]\n",
      "Train Loss (Med): 11.33994 (17.94969)\n",
      "Val Loss (Med): 11.33994 (17.94969)\n",
      "Median Size (Max): 3 (19)\n",
      "Median complexity (Max): 9 (975)\n",
      "Time (s): 0.41635\n",
      "\n",
      "Generation 5/10 [//////////////////////////                        ]\n",
      "Train Loss (Med): 10.79139 (90.38514)\n",
      "Val Loss (Med): 10.79139 (90.38514)\n",
      "Median Size (Max): 1 (19)\n",
      "Median complexity (Max): 2 (975)\n",
      "Time (s): 0.51077\n",
      "\n",
      "Generation 6/10 [///////////////////////////////                   ]\n",
      "Train Loss (Med): 10.40925 (90.38514)\n",
      "Val Loss (Med): 10.40925 (90.38514)\n",
      "Median Size (Max): 1 (19)\n",
      "Median complexity (Max): 1 (975)\n",
      "Time (s): 0.60354\n",
      "\n",
      "Generation 7/10 [////////////////////////////////////              ]\n",
      "Train Loss (Med): 10.26326 (90.38514)\n",
      "Val Loss (Med): 10.26326 (90.38514)\n",
      "Median Size (Max): 1 (19)\n",
      "Median complexity (Max): 1 (975)\n",
      "Time (s): 0.71462\n",
      "\n",
      "Generation 8/10 [/////////////////////////////////////////         ]\n",
      "Train Loss (Med): 10.26326 (90.38514)\n",
      "Val Loss (Med): 10.26326 (90.38514)\n",
      "Median Size (Max): 1 (19)\n",
      "Median complexity (Max): 1 (975)\n",
      "Time (s): 0.81340\n",
      "\n",
      "Generation 9/10 [//////////////////////////////////////////////    ]\n",
      "Train Loss (Med): 10.26326 (90.38514)\n",
      "Val Loss (Med): 10.26326 (90.38514)\n",
      "Median Size (Max): 1 (19)\n",
      "Median complexity (Max): 1 (975)\n",
      "Time (s): 0.93026\n",
      "\n",
      "Generation 10/10 [//////////////////////////////////////////////////]\n",
      "Train Loss (Med): 10.26326 (90.38514)\n",
      "Val Loss (Med): 10.26326 (90.38514)\n",
      "Median Size (Max): 1 (19)\n",
      "Median complexity (Max): 1 (975)\n",
      "Time (s): 1.02575\n",
      "\n",
      "Saved population to file /tmp/tmpcu8hqpq3/population.json\n",
      "score: 0.8864496413943795\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os, tempfile\n",
    "\n",
    "pop_file = os.path.join(tempfile.mkdtemp(), 'population.json')\n",
    "\n",
    "# set verbosity==2 to see the full report\n",
    "est = BrushRegressor(\n",
    "    functions=['SplitBest','Add','Mul','Sin','Cos','Exp','Logabs'],\n",
    "    max_gens=10,\n",
    "    objectives=[\"error\", \"complexity\"],\n",
    "    save_population=pop_file,\n",
    "    use_arch=True, # Only the pareto front of last gen will be stored in archive\n",
    "    verbosity=2\n",
    ")\n",
    "\n",
    "est.fit(X,y)\n",
    "y_pred = est.predict(X)\n",
    "print('score:', est.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a previous population is done providing `load_population` a string value corresponding to a JSON file generated by Brush. In our case, we will use the same file from the previous code block.\n",
    "\n",
    "After loading the population, we run the evolution for 10 more generations, and we can see that the first generation started from the previous population. This means that the population was successfully saved and loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded population from /tmp/tmphau_4iem/population.json of size = 200\n",
      "Completed 100% [====================]\n",
      "saving final population as archive...\n",
      "score: 0.8864496413943844\n"
     ]
    }
   ],
   "source": [
    "est = BrushRegressor(\n",
    "    functions=['SplitBest','Add','Mul','Sin','Cos','Exp','Logabs'],\n",
    "    load_population=pop_file,\n",
    "    max_gens=10,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "est.fit(X,y)\n",
    "y_pred = est.predict(X)\n",
    "print('score:', est.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving just the archive\n",
    "\n",
    "In case you want to use another expression rather than the final `best_estimator_`, brush provides the archive option.\n",
    "\n",
    "The archive is just the pareto front from the population. You can use `predict_archive` (and `predict_proba_archive` if using a `BrushClassifier`) to call the prediction methods for the entire archive, instead of the selected best individual.\n",
    "\n",
    "But first, you need to enable this option with `use_arch=True`. When set to False, it will store the entire final population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded population from /tmp/tmphau_4iem/population.json of size = 200\n",
      "Completed 100% [====================]\n",
      "{'complexity': 164, 'crowding_dist': 3.4028234663852886e+38, 'dcounter': 0, 'depth': 3, 'dominated': [], 'linear_complexity': 16, 'loss': 10.66516399383545, 'loss_v': 10.66516399383545, 'rank': 1, 'size': 13, 'values': [10.66516399383545, 13.0], 'weights': [-1.0, -1.0], 'wvalues': [-10.66516399383545, -13.0]}\n"
     ]
    }
   ],
   "source": [
    "est = BrushRegressor(\n",
    "    functions=['SplitBest','Add','Mul','Sin','Cos','Exp','Logabs'],\n",
    "    load_population=pop_file,\n",
    "    use_arch=True,\n",
    "    max_gens=10,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "est.fit(X,y)\n",
    "\n",
    "# accessing first expression from the archive. It is serialized as a dict\n",
    "print(est.archive_[0]['fitness'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can open the serialized file and change individuals' programs manually.\n",
    "\n",
    "This also allow us to have checkpoints in the execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using population files with classification\n",
    "\n",
    "To give another example, we do a two-step fit in the cells below.\n",
    "\n",
    "First, we run the evolution and save the population to a file; then, we load it and keep evolving the individuals.\n",
    "\n",
    "What is different though is that the first run is optimizing `error` and `complexity`, and the second run is optimizing `average_precision_score` and `linear_complexity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1/10 [//////                                            ]\n",
      "Train Loss (Med): 0.62865 (0.69315)\n",
      "Val Loss (Med): 0.62865 (0.69315)\n",
      "Median Size (Max): 7 (12)\n",
      "Median complexity (Max): 21 (5889)\n",
      "Time (s): 1.23444\n",
      "\n",
      "Generation 2/10 [///////////                                       ]\n",
      "Train Loss (Med): 0.62321 (0.69315)\n",
      "Val Loss (Med): 0.62321 (0.69315)\n",
      "Median Size (Max): 7 (12)\n",
      "Median complexity (Max): 21 (5889)\n",
      "Time (s): 2.44751\n",
      "\n",
      "Generation 3/10 [////////////////                                  ]\n",
      "Train Loss (Med): 0.62114 (0.69315)\n",
      "Val Loss (Med): 0.62114 (0.69315)\n",
      "Median Size (Max): 7 (12)\n",
      "Median complexity (Max): 21 (5889)\n",
      "Time (s): 3.66024\n",
      "\n",
      "Generation 4/10 [/////////////////////                             ]\n",
      "Train Loss (Med): 0.62022 (0.69315)\n",
      "Val Loss (Med): 0.62022 (0.69315)\n",
      "Median Size (Max): 7 (12)\n",
      "Median complexity (Max): 21 (5889)\n",
      "Time (s): 4.99399\n",
      "\n",
      "Generation 5/10 [//////////////////////////                        ]\n",
      "Train Loss (Med): 0.61990 (0.69315)\n",
      "Val Loss (Med): 0.61990 (0.69315)\n",
      "Median Size (Max): 7 (12)\n",
      "Median complexity (Max): 21 (5889)\n",
      "Time (s): 6.49968\n",
      "\n",
      "Generation 6/10 [///////////////////////////////                   ]\n",
      "Train Loss (Med): 0.61968 (0.69315)\n",
      "Val Loss (Med): 0.61968 (0.69315)\n",
      "Median Size (Max): 7 (12)\n",
      "Median complexity (Max): 21 (5889)\n",
      "Time (s): 7.72971\n",
      "\n",
      "Generation 7/10 [////////////////////////////////////              ]\n",
      "Train Loss (Med): 0.61962 (0.69315)\n",
      "Val Loss (Med): 0.61962 (0.69315)\n",
      "Median Size (Max): 7 (12)\n",
      "Median complexity (Max): 21 (5889)\n",
      "Time (s): 8.94153\n",
      "\n",
      "Generation 8/10 [/////////////////////////////////////////         ]\n",
      "Train Loss (Med): 0.61955 (0.69315)\n",
      "Val Loss (Med): 0.61955 (0.69315)\n",
      "Median Size (Max): 7 (12)\n",
      "Median complexity (Max): 21 (5889)\n",
      "Time (s): 10.19942\n",
      "\n",
      "Generation 9/10 [//////////////////////////////////////////////    ]\n",
      "Train Loss (Med): 0.61950 (0.69315)\n",
      "Val Loss (Med): 0.61950 (0.69315)\n",
      "Median Size (Max): 7 (12)\n",
      "Median complexity (Max): 21 (5889)\n",
      "Time (s): 11.42022\n",
      "\n",
      "Generation 10/10 [//////////////////////////////////////////////////]\n",
      "Train Loss (Med): 0.61947 (0.69315)\n",
      "Val Loss (Med): 0.61947 (0.69315)\n",
      "Median Size (Max): 7 (12)\n",
      "Median complexity (Max): 21 (5889)\n",
      "Time (s): 12.98263\n",
      "\n",
      "Saved population to file /tmp/tmp6z9ftnp3/population.json\n",
      "saving final population as archive...\n",
      "Best model: 155.24*Logistic(Sum(-3.6533294,0.16*Logabs(0.00*AIDS)))\n",
      "score: 0.6\n"
     ]
    }
   ],
   "source": [
    "from pybrush import BrushClassifier\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('../examples/datasets/d_analcatdata_aids.csv')\n",
    "X = df.drop(columns='target')\n",
    "y = df['target']\n",
    "\n",
    "pop_file = os.path.join(tempfile.mkdtemp(), 'population.json')\n",
    "\n",
    "est = BrushClassifier(\n",
    "    functions=['SplitBest','Add','Mul','Sin','Cos','Exp','Logabs'],\n",
    "    max_gens=10,\n",
    "    objectives=[\"error\", \"complexity\"],\n",
    "    scorer=\"log\",\n",
    "    save_population=pop_file,\n",
    "    pop_size=1000,\n",
    "    verbosity=2\n",
    ")\n",
    "\n",
    "est.fit(X,y)\n",
    "\n",
    "print(\"Best model:\", est.best_estimator_.get_model())\n",
    "print('score:', est.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y, est.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded population from /tmp/tmp6z9ftnp3/population.json of size = 2000\n",
      "Completed 100% [====================]\n",
      "Best model: 1.00*Logistic(Sum(0.49994996,If(AIDS>15890.50,1.00*MeanLabel,0.00*MeanLabel)))\n",
      "score: 0.5\n"
     ]
    }
   ],
   "source": [
    "est = BrushClassifier(\n",
    "    functions=['SplitBest','Add','Mul','Sin','Cos','Exp','Logabs'],\n",
    "    load_population=pop_file,\n",
    "    objectives=[\"error\", \"complexity\"],\n",
    "    scorer=\"average_precision_score\",\n",
    "    max_gens=10,\n",
    "    validation_size=0.0,\n",
    "    pop_size=1000, # make sure this is the same as loaded pop\n",
    "    use_arch=True,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "est.fit(X,y)\n",
    "\n",
    "print(\"Best model:\", est.best_estimator_.get_model())\n",
    "print('score:', est.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the fitness object, and that the error now matches the average precision score metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness(0.680010 489.000000 )\n"
     ]
    }
   ],
   "source": [
    "# Fitness is (error, linear complexity)\n",
    "print(est.best_estimator_.fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6799999999999999"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# takes y_true as first argument, and y_pred as second argument.\n",
    "average_precision_score(y, est.predict_proba(X)[:, 1]) #, average='weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brush",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
