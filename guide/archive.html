

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>The archive &mdash; Brush 0.1.dev1+gb285298b0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />

  
    <link rel="shortcut icon" href="../_static/paint-brush-solid.svg"/>
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=27f31e90"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Using Deap" href="deap.html" />
    <link rel="prev" title="Saving and loading populations" href="saving_loading_populations.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Brush
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Quickstart</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics.html">Basic Usage</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Cookbook</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="data.html">Working with Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="search_space.html">The Search Space</a></li>
<li class="toctree-l2"><a class="reference internal" href="working_with_programs.html">Working with Programs</a></li>
<li class="toctree-l2"><a class="reference internal" href="json.html">JSON Interoperability</a></li>
<li class="toctree-l2"><a class="reference internal" href="saving_loading_populations.html">Saving and loading populations</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">The archive</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#loading-a-specific-model-from-archive">Loading a specific model from archive</a></li>
<li class="toctree-l3"><a class="reference internal" href="#visualizing-the-pareto-front-of-the-archive">Visualizing the Pareto front of the archive</a></li>
<li class="toctree-l3"><a class="reference internal" href="#acessing-the-entire-population-unique-individuals">Acessing the entire population (unique individuals)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="deap.html">Using Deap</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="development.html">Development</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cpp_api/index.html">C++ API</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Brush</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Cookbook</a></li>
      <li class="breadcrumb-item active">The archive</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/guide/archive.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="the-archive">
<h1>The archive<a class="headerlink" href="#the-archive" title="Link to this heading">ÔÉÅ</a></h1>
<p>When you fit a brush estimator, three new attributes are created: <code class="docutils literal notranslate"><span class="pre">best_estimator_</span></code>, <code class="docutils literal notranslate"><span class="pre">population_</span></code>, and <code class="docutils literal notranslate"><span class="pre">archive_</span></code>.</p>
<p>Brush will store the pareto front using validation loss as a list in <code class="docutils literal notranslate"><span class="pre">archive_</span></code>. This pareto front is always created with individuals from the final population that are not dominated in objectives <strong>scorer</strong> and <strong>complexity</strong>. Setting <code class="docutils literal notranslate"><span class="pre">scorer</span></code> as an objective means optimizing the metric set as <code class="docutils literal notranslate"><span class="pre">scorer:</span> <span class="pre">str</span></code>.</p>
<p>In case you need more flexibility, the <code class="docutils literal notranslate"><span class="pre">population_</span></code> will contain the entire final population, and you can iterate through this list to select individuals with different criteria. It is also good to remind that Brush supports different optimization objectives using the argument <code class="docutils literal notranslate"><span class="pre">objectives</span></code>.</p>
<p>Each element from the archive is a Brush individual that can be serialized (JSON object).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pybrush</span><span class="w"> </span><span class="kn">import</span> <span class="n">BrushClassifier</span>

<span class="c1"># load data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../examples/datasets/d_analcatdata_aids.csv&#39;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">est</span> <span class="o">=</span> <span class="n">BrushClassifier</span><span class="p">(</span>
    <span class="n">functions</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;SplitBest&#39;</span><span class="p">,</span><span class="s1">&#39;Add&#39;</span><span class="p">,</span><span class="s1">&#39;Mul&#39;</span><span class="p">,</span><span class="s1">&#39;Sin&#39;</span><span class="p">,</span><span class="s1">&#39;Cos&#39;</span><span class="p">,</span><span class="s1">&#39;Exp&#39;</span><span class="p">,</span><span class="s1">&#39;Logabs&#39;</span><span class="p">],</span>
    <span class="n">objectives</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;scorer&quot;</span><span class="p">,</span> <span class="s2">&quot;linear_complexity&quot;</span><span class="p">],</span>
    <span class="n">scorer</span><span class="o">=</span><span class="s1">&#39;balanced_accuracy&#39;</span><span class="p">,</span> <span class="c1"># brush implements several metrics for clf and reg!</span>
    <span class="n">max_gens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">pop_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">max_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">verbosity</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best model:&quot;</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">get_model</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;score:&#39;</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Generation 1/100 [/                                                 ]
Best model on Val:Logistic(Sum(-0.32,If(AIDS&gt;=16068.00,If(AIDS&gt;=20712.00,1.00*Add(1.00,AIDS),1.00*Mul(1.00,AIDS)),If(Total&gt;=1601948.00,1.00*Mul(20712.00*AIDS,AIDS),If(AIDS&gt;=258.00,AIDS,-0.32)))))
Train Loss (Med): 0.77500 (0.56250)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 7 (95)
Median complexity (Max): 992 (921596320)
Time (s): 0.10080

Generation 2/100 [//                                                ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 7 (98)
Median complexity (Max): 176 (1657696672)
Time (s): 0.14870

Generation 3/100 [//                                                ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (93)
Median complexity (Max): 176 (1304140832)
Time (s): 0.19549

Generation 4/100 [///                                               ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (54)
Median complexity (Max): 176 (12044960)
Time (s): 0.23452

Generation 5/100 [///                                               ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (54)
Median complexity (Max): 176 (12044960)
Time (s): 0.26943

Generation 6/100 [////                                              ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (52)
Median complexity (Max): 176 (12044960)
Time (s): 0.30666

Generation 7/100 [////                                              ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (52)
Median complexity (Max): 176 (12044960)
Time (s): 0.34096

Generation 8/100 [/////                                             ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (52)
Median complexity (Max): 176 (11307680)
Time (s): 0.37853

Generation 9/100 [/////                                             ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (54)
Median complexity (Max): 176 (11307680)
Time (s): 0.41267

Generation 10/100 [//////                                            ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (54)
Median complexity (Max): 176 (11307680)
Time (s): 0.45000

Generation 11/100 [//////                                            ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (52)
Median complexity (Max): 176 (10717856)
Time (s): 0.48708

Generation 12/100 [///////                                           ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (50)
Median complexity (Max): 176 (10422944)
Time (s): 0.52469

Generation 13/100 [///////                                           ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (50)
Median complexity (Max): 176 (10422944)
Time (s): 0.55745

Generation 14/100 [////////                                          ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (50)
Median complexity (Max): 176 (10422944)
Time (s): 0.59163

Generation 15/100 [////////                                          ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (49)
Median complexity (Max): 176 (10078880)
Time (s): 0.62577

Generation 16/100 [/////////                                         ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (49)
Median complexity (Max): 176 (10078880)
Time (s): 0.65858

Generation 17/100 [/////////                                         ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (49)
Median complexity (Max): 176 (10078880)
Time (s): 0.69383

Generation 18/100 [//////////                                        ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (49)
Median complexity (Max): 176 (10078880)
Time (s): 0.72813

Generation 19/100 [//////////                                        ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (49)
Median complexity (Max): 176 (10078880)
Time (s): 0.76378

Generation 20/100 [///////////                                       ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (49)
Median complexity (Max): 176 (10078880)
Time (s): 0.80245

Generation 21/100 [///////////                                       ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (49)
Median complexity (Max): 176 (10078880)
Time (s): 0.83974

Generation 22/100 [////////////                                      ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (47)
Median complexity (Max): 176 (10078112)
Time (s): 0.88074

Generation 23/100 [////////////                                      ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (47)
Median complexity (Max): 176 (10078112)
Time (s): 0.92155

Generation 24/100 [/////////////                                     ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (47)
Median complexity (Max): 176 (10078112)
Time (s): 0.95491

Generation 25/100 [/////////////                                     ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (47)
Median complexity (Max): 176 (10078112)
Time (s): 0.99640

Generation 26/100 [//////////////                                    ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (47)
Median complexity (Max): 176 (5654432)
Time (s): 1.03516

Generation 27/100 [//////////////                                    ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (47)
Median complexity (Max): 176 (5654432)
Time (s): 1.07259

Generation 28/100 [///////////////                                   ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (47)
Median complexity (Max): 176 (5654432)
Time (s): 1.11719

Generation 29/100 [///////////////                                   ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (47)
Median complexity (Max): 176 (5654432)
Time (s): 1.15723

Generation 30/100 [////////////////                                  ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (47)
Median complexity (Max): 176 (5654432)
Time (s): 1.19967

Generation 31/100 [////////////////                                  ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (47)
Median complexity (Max): 176 (5654432)
Time (s): 1.24691

Generation 32/100 [/////////////////                                 ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.50000)
Median Size (Max): 5 (47)
Median complexity (Max): 176 (5654432)
Time (s): 1.30097

Generation 33/100 [/////////////////                                 ]
Best model on Val:Logistic(Sum(-8.68,0.52*AIDS))
Train Loss (Med): 0.77500 (0.52500)
Val Loss (Med): 0.70000 (0.60000)
Median Size (Max): 5 (47)
Median complexity (Max): 176 (5654432)
Time (s): 1.34932

Generation 34/100 [//////////////////                                ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,1.00*Cos(1.00*Exp(Total)),Total),If(Total&gt;=1601948.00,AIDS,If(AIDS&gt;=258.00,AIDS,1.00*Cos(Total)))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (56)
Median complexity (Max): 176 (21677984)
Time (s): 1.40049

Generation 35/100 [//////////////////                                ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,1.00*Cos(1.00*Exp(Total)),Total),If(Total&gt;=1601948.00,AIDS,If(AIDS&gt;=258.00,AIDS,1.00*Cos(Total)))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.55000)
Median Size (Max): 5 (56)
Median complexity (Max): 176 (21677984)
Time (s): 1.45974

Generation 36/100 [///////////////////                               ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,1.00*Cos(1.00*Exp(Total)),Total),If(Total&gt;=1601948.00,AIDS,If(AIDS&gt;=258.00,AIDS,1.00*Cos(Total)))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (56)
Median complexity (Max): 176 (21677984)
Time (s): 1.52614

Generation 37/100 [///////////////////                               ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,1.00*Cos(1.00*Exp(Total)),Total),If(Total&gt;=1601948.00,AIDS,If(AIDS&gt;=258.00,1.00,1.00*Cos(Total)))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (111)
Median complexity (Max): 176 (1343408032)
Time (s): 1.58717

Generation 38/100 [////////////////////                              ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,1.00*Cos(1.00*Exp(Total)),Total),If(Total&gt;=1601948.00,AIDS,If(AIDS&gt;=258.00,1.00,1.00*Cos(Total)))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (104)
Median complexity (Max): 176 (20891552)
Time (s): 1.64133

Generation 39/100 [////////////////////                              ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,1.00*Cos(1.00*Exp(Total)),Total),If(Total&gt;=1601948.00,AIDS,If(AIDS&gt;=258.00,1.00,1.00*Cos(Total)))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (106)
Median complexity (Max): 176 (20891552)
Time (s): 1.69622

Generation 40/100 [/////////////////////                             ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,1.00*Cos(1.00*Exp(Total)),Total),If(Total&gt;=1601948.00,AIDS,If(AIDS&gt;=258.00,1.00,1.00*Cos(Total)))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (106)
Median complexity (Max): 176 (20891552)
Time (s): 1.75234

Generation 41/100 [/////////////////////                             ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,1.00*Cos(1.00*Exp(Total)),Total),If(Total&gt;=1601948.00,AIDS,If(AIDS&gt;=258.00,1.00,1.00*Cos(Total)))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (106)
Median complexity (Max): 176 (20891552)
Time (s): 1.80336

Generation 42/100 [//////////////////////                            ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,1.00*Cos(1.00*Exp(Total)),Total),If(Total&gt;=1601948.00,AIDS,If(AIDS&gt;=258.00,1.00,1.00*Cos(Total)))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (72)
Median complexity (Max): 176 (20891552)
Time (s): 1.86306

Generation 43/100 [//////////////////////                            ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,1.00*Cos(1.00*Exp(Total)),Total),If(Total&gt;=1601948.00,AIDS,If(AIDS&gt;=258.00,1.00,1.00*Cos(Total)))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (74)
Median complexity (Max): 176 (20891552)
Time (s): 1.90866

Generation 44/100 [///////////////////////                           ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,1.00*Cos(1.00*Exp(Total)),Total),If(Total&gt;=1601948.00,AIDS,If(AIDS&gt;=258.00,1.00,1.00*Cos(Total)))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (74)
Median complexity (Max): 176 (20891552)
Time (s): 1.95261

Generation 45/100 [///////////////////////                           ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,1.00*Cos(1.00*Exp(Total)),Total),If(Total&gt;=1601948.00,AIDS,If(AIDS&gt;=258.00,1.00,1.00*Cos(Total)))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (72)
Median complexity (Max): 176 (20891552)
Time (s): 2.01117

Generation 46/100 [////////////////////////                          ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,1.00*Cos(1.00*Exp(Total)),Total),If(Total&gt;=1601948.00,AIDS,If(AIDS&gt;=258.00,1.00,1.00*Cos(Total)))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (60)
Median complexity (Max): 176 (73582496)
Time (s): 2.06181

Generation 47/100 [////////////////////////                          ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,1.00*Cos(1.00*Exp(Total)),Total),If(Total&gt;=1601948.00,AIDS,If(AIDS&gt;=258.00,1.00,1.00*Cos(Total)))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (60)
Median complexity (Max): 176 (73582496)
Time (s): 2.13684

Generation 48/100 [/////////////////////////                         ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,1.00*Cos(1.00*Exp(Total)),Total),If(Total&gt;=1601948.00,AIDS,If(AIDS&gt;=258.00,1.00,1.00*Cos(Total)))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (58)
Median complexity (Max): 176 (31115168)
Time (s): 2.18129

Generation 49/100 [/////////////////////////                         ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,1.00*Cos(1.00*Exp(Total)),Total),If(Total&gt;=1601948.00,AIDS,If(AIDS&gt;=258.00,1.00,1.00*Cos(Total)))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (58)
Median complexity (Max): 176 (31115168)
Time (s): 2.22840

Generation 50/100 [//////////////////////////                        ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,1.00*Cos(1.00*Exp(Total)),Total),If(Total&gt;=1601948.00,1.00,If(AIDS&gt;=258.00,1.00,1.00*Cos(Total)))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (60)
Median complexity (Max): 176 (31115168)
Time (s): 2.28667

Generation 51/100 [//////////////////////////                        ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,Cos(Exp(1.00)),Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (50)
Median complexity (Max): 176 (29640608)
Time (s): 2.46638

Generation 52/100 [///////////////////////////                       ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,Cos(Exp(1.00)),Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (36)
Median complexity (Max): 176 (4652960)
Time (s): 2.56978

Generation 53/100 [///////////////////////////                       ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,Cos(Exp(1.00)),Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (36)
Median complexity (Max): 176 (4652960)
Time (s): 2.66823

Generation 54/100 [////////////////////////////                      ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,Cos(Exp(1.00)),Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (36)
Median complexity (Max): 176 (4652960)
Time (s): 2.78801

Generation 55/100 [////////////////////////////                      ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,Cos(Exp(1.00)),Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.60000)
Median Size (Max): 5 (36)
Median complexity (Max): 176 (4652960)
Time (s): 2.91201

Generation 56/100 [/////////////////////////////                     ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (31)
Median complexity (Max): 176 (2760608)
Time (s): 3.02868

Generation 57/100 [/////////////////////////////                     ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (31)
Median complexity (Max): 176 (2760608)
Time (s): 3.08023

Generation 58/100 [//////////////////////////////                    ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (31)
Median complexity (Max): 176 (2760608)
Time (s): 3.12875

Generation 59/100 [//////////////////////////////                    ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (31)
Median complexity (Max): 176 (2760608)
Time (s): 3.17882

Generation 60/100 [///////////////////////////////                   ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (31)
Median complexity (Max): 176 (2760608)
Time (s): 3.22413

Generation 61/100 [///////////////////////////////                   ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (31)
Median complexity (Max): 176 (2760608)
Time (s): 3.27697

Generation 62/100 [////////////////////////////////                  ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (31)
Median complexity (Max): 176 (1279904)
Time (s): 3.32183

Generation 63/100 [////////////////////////////////                  ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (31)
Median complexity (Max): 176 (1279904)
Time (s): 3.37218

Generation 64/100 [/////////////////////////////////                 ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (31)
Median complexity (Max): 176 (1279904)
Time (s): 3.42008

Generation 65/100 [/////////////////////////////////                 ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (31)
Median complexity (Max): 176 (1279904)
Time (s): 3.46696

Generation 66/100 [//////////////////////////////////                ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (31)
Median complexity (Max): 176 (1279904)
Time (s): 3.51688

Generation 67/100 [//////////////////////////////////                ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (31)
Median complexity (Max): 176 (1279904)
Time (s): 3.56779

Generation 68/100 [///////////////////////////////////               ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (31)
Median complexity (Max): 176 (1279904)
Time (s): 3.61874

Generation 69/100 [///////////////////////////////////               ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.82500 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (31)
Median complexity (Max): 176 (1279904)
Time (s): 3.66529

Generation 70/100 [////////////////////////////////////              ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.75000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (19)
Median complexity (Max): 176 (69536)
Time (s): 3.71265

Generation 71/100 [////////////////////////////////////              ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.75000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (19)
Median complexity (Max): 176 (69536)
Time (s): 3.75228

Generation 72/100 [/////////////////////////////////////             ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.75000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (19)
Median complexity (Max): 176 (69536)
Time (s): 3.80158

Generation 73/100 [/////////////////////////////////////             ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.75000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (19)
Median complexity (Max): 176 (69536)
Time (s): 3.84654

Generation 74/100 [//////////////////////////////////////            ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (41)
Median complexity (Max): 176 (69536)
Time (s): 3.89059

Generation 75/100 [//////////////////////////////////////            ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (41)
Median complexity (Max): 176 (473464736)
Time (s): 3.95229

Generation 76/100 [///////////////////////////////////////           ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (41)
Median complexity (Max): 176 (473464736)
Time (s): 4.02272

Generation 77/100 [///////////////////////////////////////           ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (41)
Median complexity (Max): 176 (473464736)
Time (s): 4.08319

Generation 78/100 [////////////////////////////////////////          ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (41)
Median complexity (Max): 176 (473464736)
Time (s): 4.13113

Generation 79/100 [////////////////////////////////////////          ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (41)
Median complexity (Max): 176 (473464736)
Time (s): 4.18934

Generation 80/100 [/////////////////////////////////////////         ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (41)
Median complexity (Max): 176 (473464736)
Time (s): 4.24344

Generation 81/100 [/////////////////////////////////////////         ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (41)
Median complexity (Max): 176 (473464736)
Time (s): 4.30500

Generation 82/100 [//////////////////////////////////////////        ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (41)
Median complexity (Max): 176 (473464736)
Time (s): 4.39221

Generation 83/100 [//////////////////////////////////////////        ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (41)
Median complexity (Max): 176 (473464736)
Time (s): 4.43939

Generation 84/100 [///////////////////////////////////////////       ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (41)
Median complexity (Max): 176 (473464736)
Time (s): 4.48879

Generation 85/100 [///////////////////////////////////////////       ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (40)
Median complexity (Max): 176 (1178785696)
Time (s): 4.54237

Generation 86/100 [////////////////////////////////////////////      ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (40)
Median complexity (Max): 176 (1178785696)
Time (s): 4.61088

Generation 87/100 [////////////////////////////////////////////      ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (35)
Median complexity (Max): 176 (321050528)
Time (s): 4.69097

Generation 88/100 [/////////////////////////////////////////////     ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (35)
Median complexity (Max): 176 (321050528)
Time (s): 4.75119

Generation 89/100 [/////////////////////////////////////////////     ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (35)
Median complexity (Max): 176 (321050528)
Time (s): 4.80611

Generation 90/100 [//////////////////////////////////////////////    ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (35)
Median complexity (Max): 176 (321050528)
Time (s): 4.86054

Generation 91/100 [//////////////////////////////////////////////    ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (33)
Median complexity (Max): 176 (66246560)
Time (s): 4.92291

Generation 92/100 [///////////////////////////////////////////////   ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (33)
Median complexity (Max): 176 (66246560)
Time (s): 4.97706

Generation 93/100 [///////////////////////////////////////////////   ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (30)
Median complexity (Max): 176 (11042720)
Time (s): 5.03965

Generation 94/100 [////////////////////////////////////////////////  ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (30)
Median complexity (Max): 176 (11042720)
Time (s): 5.08854

Generation 95/100 [////////////////////////////////////////////////  ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (30)
Median complexity (Max): 176 (11042720)
Time (s): 5.14694

Generation 96/100 [///////////////////////////////////////////////// ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (30)
Median complexity (Max): 176 (11042720)
Time (s): 5.18979

Generation 97/100 [///////////////////////////////////////////////// ]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (30)
Median complexity (Max): 176 (11042720)
Time (s): 5.23257

Generation 98/100 [//////////////////////////////////////////////////]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (30)
Median complexity (Max): 176 (11042720)
Time (s): 5.27898

Generation 99/100 [//////////////////////////////////////////////////]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (30)
Median complexity (Max): 176 (11042720)
Time (s): 5.34219

Generation 100/100 [//////////////////////////////////////////////////]
Best model on Val:Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
Train Loss (Med): 0.85000 (0.52500)
Val Loss (Med): 0.90000 (0.50000)
Median Size (Max): 5 (30)
Median complexity (Max): 176 (11042720)
Time (s): 5.39780

Best model: Logistic(Sum(0.00,If(AIDS&gt;=16068.00,1.00,1.00*Mul(If(Total&gt;=1601948.00,-0.91,Total),If(AIDS&gt;=258.00,1.00,Cos(Total))))))
score: 0.84
</pre></div>
</div>
</div>
</div>
<p>You can see individuals from archive using the index:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">archive_</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span> <span class="n">est</span><span class="o">.</span><span class="n">archive_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2
Logistic(Sum(-11.58,AIDS))
</pre></div>
</div>
</div>
</div>
<p>And you can call <code class="docutils literal notranslate"><span class="pre">predict</span></code> (or <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>, if your <code class="docutils literal notranslate"><span class="pre">est</span></code> is an instance of <code class="docutils literal notranslate"><span class="pre">BrushClassifier</span></code>) with individuals from the archive or population. But first you need to wrap the data in a Brush dataset to make feature names match:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pybrush</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">ref_dataset</span><span class="o">=</span><span class="n">est</span><span class="o">.</span><span class="n">data_</span><span class="p">,</span> 
               <span class="n">feature_names</span><span class="o">=</span><span class="n">est</span><span class="o">.</span><span class="n">feature_names_</span><span class="p">)</span>

<span class="n">est</span><span class="o">.</span><span class="n">archive_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True, False,  True,  True,  True,  True,
       False,  True,  True,  True,  True])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">est</span><span class="o">.</span><span class="n">archive_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
       9.9999940e-01, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
       3.7768183e-03, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,
       1.0000000e+00, 1.8871395e-04, 1.0000000e+00, 1.0000000e+00,
       1.0000000e+00, 9.1870719e-01], dtype=float32)
</pre></div>
</div>
</div>
</div>
<section id="loading-a-specific-model-from-archive">
<h2>Loading a specific model from archive<a class="headerlink" href="#loading-a-specific-model-from-archive" title="Link to this heading">ÔÉÅ</a></h2>
<p>Use it as if it is a compatible sklearn estimator!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ind_from_arch</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">archive_</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">ind_from_arch</span><span class="o">.</span><span class="n">get_model</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ind_from_arch</span><span class="o">.</span><span class="n">fitness</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Logistic(Sum(-11.58,AIDS))
Fitness(0.600000 16.000000 )
</pre></div>
</div>
</div>
</div>
<p>To use this loaded model to do predictions, you need to wrap the data into a Dataset:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pybrush</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">ref_dataset</span><span class="o">=</span><span class="n">est</span><span class="o">.</span><span class="n">data_</span><span class="p">,</span> 
               <span class="n">feature_names</span><span class="o">=</span><span class="n">est</span><span class="o">.</span><span class="n">feature_names_</span><span class="p">)</span>
<span class="n">ind_from_arch</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True, False,  True,  True,  True,  True,
       False,  True,  True,  True,  True])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ind_from_arch</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True, False,  True,  True,  True,  True,
       False,  True,  True,  True,  True])
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualizing-the-pareto-front-of-the-archive">
<h2>Visualizing the Pareto front of the archive<a class="headerlink" href="#visualizing-the-pareto-front-of-the-archive" title="Link to this heading">ÔÉÅ</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">xs</span><span class="p">,</span> <span class="n">ys</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">est</span><span class="o">.</span><span class="n">archive_</span><span class="p">:</span>
    <span class="n">xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">fitness</span><span class="o">.</span><span class="n">loss_v</span><span class="p">)</span>
    <span class="n">ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">fitness</span><span class="o">.</span><span class="n">linear_complexity</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xs</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Loss on validation partition (greater is better)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Complexity (smaller is better)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Complexity (smaller is better)&#39;)
</pre></div>
</div>
<img alt="../_images/d25f405c7b64e9a889758d3fcb595e3329f5c6a8b7c17bdce6a75d0fd20dd270.png" src="../_images/d25f405c7b64e9a889758d3fcb595e3329f5c6a8b7c17bdce6a75d0fd20dd270.png" />
</div>
</div>
</section>
<section id="acessing-the-entire-population-unique-individuals">
<h2>Acessing the entire population (unique individuals)<a class="headerlink" href="#acessing-the-entire-population-unique-individuals" title="Link to this heading">ÔÉÅ</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">est</span> <span class="o">=</span> <span class="n">BrushClassifier</span><span class="p">(</span>
    <span class="c1"># functions=[&#39;SplitBest&#39;,&#39;Add&#39;,&#39;Mul&#39;,&#39;Sin&#39;,&#39;Cos&#39;,&#39;Exp&#39;,&#39;Logabs&#39;],</span>
    <span class="n">objectives</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;scorer&quot;</span><span class="p">,</span> <span class="s2">&quot;linear_complexity&quot;</span><span class="p">],</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">max_size</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span>
    <span class="n">max_gens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">pop_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
    <span class="n">verbosity</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best model:&quot;</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">get_model</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;score:&#39;</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 100% [====================]
Best model: Logistic(Sum(-0.91,0.04*Max(0.39*AIDS,0.43*AIDS,0.43*AIDS,0.52*AIDS)))
score: 0.54
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

<span class="n">xs</span><span class="p">,</span> <span class="n">ys</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">est</span><span class="o">.</span><span class="n">population_</span><span class="p">:</span>
    <span class="c1"># use the same as the objectives</span>
    <span class="n">xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">fitness</span><span class="o">.</span><span class="n">loss_v</span><span class="p">)</span>
    <span class="n">ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">fitness</span><span class="o">.</span><span class="n">linear_complexity</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;+&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">xs</span><span class="p">,</span> <span class="n">ys</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">est</span><span class="o">.</span><span class="n">archive_</span><span class="p">:</span>
    <span class="n">xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">fitness</span><span class="o">.</span><span class="n">loss_v</span><span class="p">)</span>
    <span class="n">ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ind</span><span class="o">.</span><span class="n">fitness</span><span class="o">.</span><span class="n">linear_complexity</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Loss on validation partition (smaller is better)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Complexity (smaller is better)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/eda94ab77d789e1abae6e1f8ad01da748baa86fd0fb3bd83f1c9ab6266274451.png" src="../_images/eda94ab77d789e1abae6e1f8ad01da748baa86fd0fb3bd83f1c9ab6266274451.png" />
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="saving_loading_populations.html" class="btn btn-neutral float-left" title="Saving and loading populations" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="deap.html" class="btn btn-neutral float-right" title="Using Deap" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, William La Cava and Joseph D. Romano.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>